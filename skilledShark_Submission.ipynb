{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "import shap\n",
    "# from ydata_profiling import ProfileReport\n",
    "import sweetviz as sv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:16.059657Z",
     "start_time": "2024-01-28T18:28:14.688682Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reproducibility:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4e58ef72dfbe19d"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:16.842365Z",
     "start_time": "2024-01-28T18:28:16.813797Z"
    }
   },
   "id": "1046a21be556037"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "data": {
      "text/plain": "         AuthorId        Diet  Age\n0       10000120E  Vegetarian   46\n1        1000014D       Vegan   18\n2        1000015A  Vegetarian   58\n3        1000016E  Vegetarian   32\n4        1000027E       Vegan   61\n...           ...         ...  ...\n271902    999917E  Vegetarian   28\n271903    999936C    Omnivore   22\n271904     99993D  Vegetarian   58\n271905     99994A  Vegetarian   18\n271906    999991A  Vegetarian   21\n\n[271907 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000120E</td>\n      <td>Vegetarian</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000014D</td>\n      <td>Vegan</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000015A</td>\n      <td>Vegetarian</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000016E</td>\n      <td>Vegetarian</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000027E</td>\n      <td>Vegan</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271902</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>271903</th>\n      <td>999936C</td>\n      <td>Omnivore</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>271904</th>\n      <td>99993D</td>\n      <td>Vegetarian</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>271905</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>271906</th>\n      <td>999991A</td>\n      <td>Vegetarian</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>271907 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet = pd.read_csv('diet.csv', low_memory=False)\n",
    "diet['Diet'] = diet['Diet'].astype('category')\n",
    "diet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:17.687091Z",
     "start_time": "2024-01-28T18:28:17.498530Z"
    }
   },
   "id": "945414f010f9c610"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Understanding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e110bb2f216c3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# user_count= diet['AuthorId']\n",
    "# print(f'The number of author ids is: {user_count.size}')\n",
    "# print(f'The number of unique author ids is: {user_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:19.611675Z",
     "start_time": "2024-01-28T18:28:19.566085Z"
    }
   },
   "id": "94617de5539d6697",
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "source": [
    "Different Graphs of Diet.csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18fb5bbc6a2f6bf2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Histogram of Ages\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(diet['Age'], bins=20, color='skyblue', edgecolor='black')\n",
    "# plt.title('Distribution of Ages')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:20.409028Z",
     "start_time": "2024-01-28T18:28:20.339348Z"
    }
   },
   "id": "1f921f7de9376fa6",
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Box Plot of Ages by Diet: Explore relationships between numerical variables (Age) using a pair plot.\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.boxplot(x='Diet', y='Age', data=diet, palette='pastel')\n",
    "# plt.title('Box Plot of Ages by Diet')\n",
    "# plt.xlabel('Diet')\n",
    "# plt.ylabel('Age')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:20.798340Z",
     "start_time": "2024-01-28T18:28:20.746358Z"
    }
   },
   "id": "996d3a7dd0ba77e7",
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Count Plot of Diets: Show the count of each diet category using a count plot.\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.countplot(x='Diet', data=diet, palette='viridis')\n",
    "# plt.title('Count of Diets')\n",
    "# plt.xlabel('Diet')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:21.133268Z",
     "start_time": "2024-01-28T18:28:21.092363Z"
    }
   },
   "id": "61aafe5aac5297f0",
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId          Time  HighCalories  HighProtein  \\\n0       2001012259B     73440   1799.950949           0.0  Indifferent   \n1           437641B    365718   4201.820980           0.0          Yes   \n2       1803340263D    141757   6299.861496           0.0  Indifferent   \n3           854048B    280351  19801.365796           0.0          Yes   \n4          2277685E    180505   5400.093457           0.0  Indifferent   \n...             ...       ...           ...           ...          ...   \n140190      163793B     78171   1560.649725           0.0  Indifferent   \n140191       33888B    333262   1502.011466           1.0  Indifferent   \n140192      401942C     49200   5999.274269           0.0  Indifferent   \n140193      346866B    214815    899.523513           0.0          Yes   \n140194     1786859E    117923   7199.637837           1.0  Indifferent   \n\n        LowFat     LowSugar  HighFiber  \n0            0            0          0  \n1            0  Indifferent          1  \n2            1  Indifferent          0  \n3            1            0          1  \n4            0            0          0  \n...        ...          ...        ...  \n140190       0            0          1  \n140191       1            0          0  \n140192       0            0          1  \n140193       1  Indifferent          1  \n140194       0            0          1  \n\n[140195 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001012259B</td>\n      <td>73440</td>\n      <td>1799.950949</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>437641B</td>\n      <td>365718</td>\n      <td>4201.820980</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1803340263D</td>\n      <td>141757</td>\n      <td>6299.861496</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>854048B</td>\n      <td>280351</td>\n      <td>19801.365796</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2277685E</td>\n      <td>180505</td>\n      <td>5400.093457</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>163793B</td>\n      <td>78171</td>\n      <td>1560.649725</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>33888B</td>\n      <td>333262</td>\n      <td>1502.011466</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>401942C</td>\n      <td>49200</td>\n      <td>5999.274269</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>346866B</td>\n      <td>214815</td>\n      <td>899.523513</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>1786859E</td>\n      <td>117923</td>\n      <td>7199.637837</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = pd.read_csv('requests.csv', low_memory=False)\n",
    "requests['HighProtein'] = requests['HighProtein'].astype('category')\n",
    "requests['LowSugar'] = requests['LowSugar'].astype('category')\n",
    "requests"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:21.450204Z",
     "start_time": "2024-01-28T18:28:21.313429Z"
    }
   },
   "id": "fc76e88ae8ccd753",
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "# user_count= requests['AuthorId']\n",
    "# print(\"Author Id \")\n",
    "# print(f'The number of author ids is: {user_count.size}')\n",
    "# print(f'The number of unique author ids is: {user_count.unique().size}')\n",
    "# print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "# recipe_count= requests['RecipeId']\n",
    "# print(\"Recipe Id \")\n",
    "# print(f'The number of recipe ids is: {recipe_count.size}')\n",
    "# print(f'The number of unique recipe ids is: {recipe_count.unique().size}')\n",
    "# print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:23.951539Z",
     "start_time": "2024-01-28T18:28:23.907313Z"
    }
   },
   "id": "5c77ab769db421af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Correlation Heatmap: Visualize the correlation between numerical variables.\n",
    "# # Exclude non-numeric columns\n",
    "# numeric_columns = requests[['Time', 'HighCalories', 'LowFat', 'HighFiber']]\n",
    "# correlation_matrix = numeric_columns.corr()\n",
    "# \n",
    "# # Plot the heatmap\n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "# plt.title('Correlation Heatmap for Request Variables')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:24.431147Z",
     "start_time": "2024-01-28T18:28:24.415577Z"
    }
   },
   "id": "4d0d1773c42484e",
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Bar Plot of HighProtein Requests: Visualize the count of HighProtein requests.\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.countplot(x='HighProtein', data=requests, palette='Set2')\n",
    "# plt.title('Count of HighProtein Requests')\n",
    "# plt.xlabel('HighProtein')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:24.598815Z",
     "start_time": "2024-01-28T18:28:24.585728Z"
    }
   },
   "id": "9ebc67dff1ce7cca",
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Bar Plot of LowSugar Requests: Visualize the count of LowSugar requests.\n",
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.countplot(x='LowSugar', data=requests, palette='pastel')\n",
    "# plt.title('Count of LowSugar Requests')\n",
    "# plt.xlabel('LowSugar')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:24.804425Z",
     "start_time": "2024-01-28T18:28:24.791177Z"
    }
   },
   "id": "cf37bff55cb522ff",
   "execution_count": 12
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating   Like  TestSetId\n0          2492191A     33671     2.0    NaN        1.0\n1       2002019979A     92647     2.0    NaN        2.0\n2           408594E    161770     NaN    NaN        3.0\n3       2001625557E    108231     2.0    NaN        4.0\n4       2001427116E     71109     NaN    NaN        5.0\n...             ...       ...     ...    ...        ...\n140190      999595E    338070     2.0  False        NaN\n140191      999774A     29002     2.0  False        NaN\n140192      999774A    159252     NaN  False        NaN\n140193      999774A      1171     2.0   True        NaN\n140194      999917E    169413     2.0  False        NaN\n\n[140195 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2492191A</td>\n      <td>33671</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2002019979A</td>\n      <td>92647</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408594E</td>\n      <td>161770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001625557E</td>\n      <td>108231</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001427116E</td>\n      <td>71109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('reviews.csv', low_memory=False)\n",
    "reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:25.450766Z",
     "start_time": "2024-01-28T18:28:25.355228Z"
    }
   },
   "id": "bec20eb4f25cd1d0",
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "# user1_count= reviews['AuthorId']\n",
    "# print(\"Author Id \")\n",
    "# print(f'The number of author ids is: {user1_count.size}')\n",
    "# print(f'The number of unique author ids is: {user1_count.unique().size}')\n",
    "# print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "# recipe1_count= reviews['RecipeId']\n",
    "# print(\"Recipe Id \")\n",
    "# print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "# print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')\n",
    "# print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:27.253016Z",
     "start_time": "2024-01-28T18:28:27.225360Z"
    }
   },
   "id": "5c37873ec50ba36f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Scatter Plot of Rating vs Like:Investigate the relationship between ratings and likes using a scatter plot\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.scatter(reviews['Rating'], reviews['Like'], alpha=0.5, color='green')\n",
    "# plt.title('Scatter Plot of Rating vs Like')\n",
    "# plt.xlabel('Rating')\n",
    "# plt.ylabel('Like')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:27.724600Z",
     "start_time": "2024-01-28T18:28:27.709262Z"
    }
   },
   "id": "f659099f3e911f4b",
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       RecipeId                                      RecipeName  CookTime  \\\n0         73440                    Bow Ties With Broccoli Pesto         0   \n1        365718                             Cashew-chutney Rice      3600   \n2        141757        Copycat Taco Bell Nacho Fries BellGrande      3600   \n3        280351        Slow Cooker Jalapeno Cheddar Cheese Soup     18000   \n4        180505                 Cool & Crisp Citrus Chiffon Pie      3600   \n...         ...                                             ...       ...   \n75599    253577  Frijoles Negros- Crock Pot Mexican Black Beans     43200   \n75600    267827                                  Moose Moussaka      3600   \n75601    266983        Cantonese Pepper Steak for Two (Or More)      1800   \n75602    253739                            Coconut Cream Cooler       300   \n75603     78171                                 Cheater Risotto       960   \n\n       PrepTime RecipeCategory  \\\n0          1800          Other   \n1           600          Other   \n2          2700          Other   \n3          1800          Other   \n4          1800          Other   \n...         ...            ...   \n75599     28800          Other   \n75600      2700          Other   \n75601       900          Other   \n75602       120          Other   \n75603       600          Other   \n\n                              RecipeIngredientQuantities  \\\n0      c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...   \n1      c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...   \n2      c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...   \n3      c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...   \n4      c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...   \n...                                                  ...   \n75599  c(\"\\\"2\\\"\", \"\\\"6 -8\\\"\", \"\\\"5\\\"\", \"\\\"1/2\\\"\", \"\\\"...   \n75600  c(\"\\\"1\\\"\", \"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1/2\\\"...   \n75601  c(\"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1/8\\\"\", \"\\\"1/8\\\"\", \"\\...   \n75602  c(\"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"7 1/2\\\"\", \"\\\"1...   \n75603  c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"4\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"...   \n\n                                   RecipeIngredientParts  Calories  \\\n0      c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...     241.3   \n1      c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...     370.8   \n2      c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...     377.6   \n3      c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...     282.8   \n4      c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...     257.5   \n...                                                  ...       ...   \n75599  c(\"\\\"black beans\\\"\", \"\\\"water\\\"\", \"\\\"bay leave...     121.5   \n75600  c(\"\\\"onion\\\"\", \"\\\"garlic cloves\\\"\", \"\\\"olive o...     652.2   \n75601  c(\"\\\"top round steak\\\"\", \"\\\"cornstarch\\\"\", \"\\\"...     223.9   \n75602             c(\"\\\"cream of coconut\\\"\", \"\\\"water\\\"\")    2229.8   \n75603  c(\"\\\"arborio rice\\\"\", \"\\\"white wine\\\"\", \"\\\"gar...     654.1   \n\n       FatContent  SaturatedFatContent  CholesterolContent  SodiumContent  \\\n0            10.1                  1.2                 0.0           13.1   \n1            17.5                  7.2                22.9          553.3   \n2            20.9                 10.5                45.7         1501.8   \n3            16.5                 10.3                50.5          630.2   \n4             8.6                  2.4               110.7          160.9   \n...           ...                  ...                 ...            ...   \n75599         0.5                  0.1                 0.0         1175.1   \n75600        25.8                 10.7               197.9          435.5   \n75601         9.2                  3.6                78.3          725.9   \n75602        80.3                 69.3                 0.0          294.7   \n75603        13.8                  6.9                34.6         1114.0   \n\n       CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n0                     31.8           2.3           1.4             6.7   \n1                     44.3           1.6           2.2             9.4   \n2                     36.6           3.8           6.1            12.9   \n3                     22.8           2.3           2.7            11.7   \n4                     39.8           0.4          30.2             6.3   \n...                    ...           ...           ...             ...   \n75599                 22.2           7.8           0.6             7.9   \n75600                 51.9           7.5           7.2            50.1   \n75601                  7.3           1.1           1.7            26.7   \n75602                369.0          15.7         317.9            26.7   \n75603                 92.2           3.9           4.2            21.8   \n\n       RecipeServings RecipeYield  \n0                 9.0         NaN  \n1                 8.0         NaN  \n2                 8.0         NaN  \n3                 6.0         NaN  \n4                 6.0         NaN  \n...               ...         ...  \n75599             NaN         NaN  \n75600             NaN         NaN  \n75601             2.0         NaN  \n75602             NaN    1 gallon  \n75603             NaN  2 1/2 cups  \n\n[75604 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecipeId</th>\n      <th>RecipeName</th>\n      <th>CookTime</th>\n      <th>PrepTime</th>\n      <th>RecipeCategory</th>\n      <th>RecipeIngredientQuantities</th>\n      <th>RecipeIngredientParts</th>\n      <th>Calories</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73440</td>\n      <td>Bow Ties With Broccoli Pesto</td>\n      <td>0</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...</td>\n      <td>c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...</td>\n      <td>241.3</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>365718</td>\n      <td>Cashew-chutney Rice</td>\n      <td>3600</td>\n      <td>600</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...</td>\n      <td>c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...</td>\n      <td>370.8</td>\n      <td>17.5</td>\n      <td>7.2</td>\n      <td>22.9</td>\n      <td>553.3</td>\n      <td>44.3</td>\n      <td>1.6</td>\n      <td>2.2</td>\n      <td>9.4</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>141757</td>\n      <td>Copycat Taco Bell Nacho Fries BellGrande</td>\n      <td>3600</td>\n      <td>2700</td>\n      <td>Other</td>\n      <td>c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...</td>\n      <td>c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...</td>\n      <td>377.6</td>\n      <td>20.9</td>\n      <td>10.5</td>\n      <td>45.7</td>\n      <td>1501.8</td>\n      <td>36.6</td>\n      <td>3.8</td>\n      <td>6.1</td>\n      <td>12.9</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>280351</td>\n      <td>Slow Cooker Jalapeno Cheddar Cheese Soup</td>\n      <td>18000</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...</td>\n      <td>c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...</td>\n      <td>282.8</td>\n      <td>16.5</td>\n      <td>10.3</td>\n      <td>50.5</td>\n      <td>630.2</td>\n      <td>22.8</td>\n      <td>2.3</td>\n      <td>2.7</td>\n      <td>11.7</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180505</td>\n      <td>Cool &amp; Crisp Citrus Chiffon Pie</td>\n      <td>3600</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...</td>\n      <td>c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...</td>\n      <td>257.5</td>\n      <td>8.6</td>\n      <td>2.4</td>\n      <td>110.7</td>\n      <td>160.9</td>\n      <td>39.8</td>\n      <td>0.4</td>\n      <td>30.2</td>\n      <td>6.3</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75599</th>\n      <td>253577</td>\n      <td>Frijoles Negros- Crock Pot Mexican Black Beans</td>\n      <td>43200</td>\n      <td>28800</td>\n      <td>Other</td>\n      <td>c(\"\\\"2\\\"\", \"\\\"6 -8\\\"\", \"\\\"5\\\"\", \"\\\"1/2\\\"\", \"\\\"...</td>\n      <td>c(\"\\\"black beans\\\"\", \"\\\"water\\\"\", \"\\\"bay leave...</td>\n      <td>121.5</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1175.1</td>\n      <td>22.2</td>\n      <td>7.8</td>\n      <td>0.6</td>\n      <td>7.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75600</th>\n      <td>267827</td>\n      <td>Moose Moussaka</td>\n      <td>3600</td>\n      <td>2700</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1/2\\\"...</td>\n      <td>c(\"\\\"onion\\\"\", \"\\\"garlic cloves\\\"\", \"\\\"olive o...</td>\n      <td>652.2</td>\n      <td>25.8</td>\n      <td>10.7</td>\n      <td>197.9</td>\n      <td>435.5</td>\n      <td>51.9</td>\n      <td>7.5</td>\n      <td>7.2</td>\n      <td>50.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75601</th>\n      <td>266983</td>\n      <td>Cantonese Pepper Steak for Two (Or More)</td>\n      <td>1800</td>\n      <td>900</td>\n      <td>Other</td>\n      <td>c(\"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1/8\\\"\", \"\\\"1/8\\\"\", \"\\...</td>\n      <td>c(\"\\\"top round steak\\\"\", \"\\\"cornstarch\\\"\", \"\\\"...</td>\n      <td>223.9</td>\n      <td>9.2</td>\n      <td>3.6</td>\n      <td>78.3</td>\n      <td>725.9</td>\n      <td>7.3</td>\n      <td>1.1</td>\n      <td>1.7</td>\n      <td>26.7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75602</th>\n      <td>253739</td>\n      <td>Coconut Cream Cooler</td>\n      <td>300</td>\n      <td>120</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"7 1/2\\\"\", \"\\\"1...</td>\n      <td>c(\"\\\"cream of coconut\\\"\", \"\\\"water\\\"\")</td>\n      <td>2229.8</td>\n      <td>80.3</td>\n      <td>69.3</td>\n      <td>0.0</td>\n      <td>294.7</td>\n      <td>369.0</td>\n      <td>15.7</td>\n      <td>317.9</td>\n      <td>26.7</td>\n      <td>NaN</td>\n      <td>1 gallon</td>\n    </tr>\n    <tr>\n      <th>75603</th>\n      <td>78171</td>\n      <td>Cheater Risotto</td>\n      <td>960</td>\n      <td>600</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"4\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"...</td>\n      <td>c(\"\\\"arborio rice\\\"\", \"\\\"white wine\\\"\", \"\\\"gar...</td>\n      <td>654.1</td>\n      <td>13.8</td>\n      <td>6.9</td>\n      <td>34.6</td>\n      <td>1114.0</td>\n      <td>92.2</td>\n      <td>3.9</td>\n      <td>4.2</td>\n      <td>21.8</td>\n      <td>NaN</td>\n      <td>2 1/2 cups</td>\n    </tr>\n  </tbody>\n</table>\n<p>75604 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('recipes.csv', low_memory=False)\n",
    "recipes.rename(columns={\n",
    "    'Name': 'RecipeName'\n",
    "}, inplace=True)\n",
    "recipes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:28.653847Z",
     "start_time": "2024-01-28T18:28:28.036984Z"
    }
   },
   "id": "2b093a7364ade8b9",
   "execution_count": 16
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "# recipe1_count= recipes['RecipeId']\n",
    "# print(\"Recipe Id \")\n",
    "# print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "# print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:30.762262Z",
     "start_time": "2024-01-28T18:28:30.729991Z"
    }
   },
   "id": "df4ba00a84909f35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Pair Plot for Nutritional Content:Explore relationships between nutritional content variables using a pair plot.\n",
    "# nutritional_content = recipes[['Calories', 'FatContent', 'CarbohydrateContent', 'ProteinContent']]\n",
    "# sns.pairplot(nutritional_content)\n",
    "# plt.suptitle('Pair Plot of Nutritional Content', y=1.02)\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:31.062366Z",
     "start_time": "2024-01-28T18:28:30.998466Z"
    }
   },
   "id": "6ed6bee69604e265",
   "execution_count": 18
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Histogram for Calories:Explore the distribution of calories in recipes using a histogram.\n",
    "# custom_bins = np.arange(0, 5100, 200)  # Adjust the range and interval as needed\n",
    "# \n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(recipes['Calories'], bins=custom_bins, color='skyblue', edgecolor='black')\n",
    "# plt.title('Distribution of Calories in Recipes')\n",
    "# plt.xlabel('Calories')\n",
    "# plt.ylabel('Frequency')\n",
    "# \n",
    "# # Set x-axis labels\n",
    "# plt.xticks(custom_bins)\n",
    "# \n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:31.380155Z",
     "start_time": "2024-01-28T18:28:31.358821Z"
    }
   },
   "id": "9df39c8c2f993cc5",
   "execution_count": 19
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Bar Plot for Recipe Categories: Visualize the distribution of recipes across different categories using a bar plot.\n",
    "# plt.figure(figsize=(14, 8))\n",
    "# sns.boxplot(x='RecipeCategory', y='CookTime', data=recipes, palette='Set2')\n",
    "# plt.title('Box Plot of Cook Time by Recipe Category')\n",
    "# plt.xlabel('Recipe Category')\n",
    "# plt.ylabel('Cook Time')\n",
    "# plt.xticks(rotation=45, ha='right')\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:31.688709Z",
     "start_time": "2024-01-28T18:28:31.676287Z"
    }
   },
   "id": "e11c74d0824455cf",
   "execution_count": 20
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.countplot(x='RecipeCategory', data=recipes, palette='viridis', order=recipes['RecipeCategory'].value_counts().index)\n",
    "# plt.title('Distribution of Recipes across Categories')\n",
    "# plt.xlabel('Recipe Category')\n",
    "# plt.ylabel('Count')\n",
    "# plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:32.078563Z",
     "start_time": "2024-01-28T18:28:32.016426Z"
    }
   },
   "id": "438ceb8863a29b9a",
   "execution_count": 21
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating   Like  TestSetId         Time  \\\n0          2492191A     33671     2.0    NaN        1.0  2698.714376   \n1       2002019979A     92647     2.0    NaN        2.0  2399.694583   \n2           408594E    161770     NaN    NaN        3.0  2099.113170   \n3       2001625557E    108231     2.0    NaN        4.0  1199.645575   \n4       2001427116E     71109     NaN    NaN        5.0  2341.181827   \n...             ...       ...     ...    ...        ...          ...   \n140190      999595E    338070     2.0  False        NaN  3899.421310   \n140191      999774A     29002     2.0  False        NaN  2402.372535   \n140192      999774A    159252     NaN  False        NaN  5999.598903   \n140193      999774A      1171     2.0   True        NaN   480.233207   \n140194      999917E    169413     2.0  False        NaN  3600.387748   \n\n        HighCalories  HighProtein  LowFat     LowSugar  HighFiber  \n0                0.0  Indifferent       1            0          1  \n1                1.0  Indifferent       0  Indifferent          1  \n2                1.0  Indifferent       0            0          1  \n3                1.0          Yes       0            0          1  \n4                1.0  Indifferent       0            0          1  \n...              ...          ...     ...          ...        ...  \n140190           0.0  Indifferent       1  Indifferent          0  \n140191           0.0  Indifferent       0  Indifferent          0  \n140192           0.0          Yes       0            0          0  \n140193           1.0          Yes       0            0          0  \n140194           0.0  Indifferent       0  Indifferent          0  \n\n[140195 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2492191A</td>\n      <td>33671</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2698.714376</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2002019979A</td>\n      <td>92647</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2399.694583</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408594E</td>\n      <td>161770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>2099.113170</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001625557E</td>\n      <td>108231</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1199.645575</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001427116E</td>\n      <td>71109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2341.181827</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.421310</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_request_review = pd.merge(reviews,requests,on=['AuthorId','RecipeId'])\n",
    "merged_request_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:32.683153Z",
     "start_time": "2024-01-28T18:28:32.524801Z"
    }
   },
   "id": "ae2ed40a9bf4da80",
   "execution_count": 22
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# user1_count= merged_request_review['AuthorId']\n",
    "# print(\"Author Id \")\n",
    "# print(f'The number of author ids is: {user1_count.size}')\n",
    "# print(f'The number of unique author ids is: {user1_count.unique().size}')\n",
    "# print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "# recipe1_count= merged_request_review['RecipeId']\n",
    "# print(\"Recipe Id \")\n",
    "# print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "# print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')\n",
    "# print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:39.113786Z",
     "start_time": "2024-01-28T18:28:39.091777Z"
    }
   },
   "id": "40fe2c30f2a496a5",
   "execution_count": 23
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #eatmap for Correlation: Visualize the correlation between numerical variables.\n",
    "# correlation_matrix = merged_request_review[['Rating', 'Like', 'Time', 'HighCalories', 'LowFat', 'HighFiber']].corr()\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "# plt.title('Correlation Heatmap for Merged Data')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:39.355633Z",
     "start_time": "2024-01-28T18:28:39.295285Z"
    }
   },
   "id": "f54f70b1a088f1fe",
   "execution_count": 24
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(8, 5))\n",
    "# sns.barplot(x='HighProtein', y='Rating', data=merged_request_review, palette='Set2')\n",
    "# plt.title('Average Rating for Recipes with and without High Protein')\n",
    "# plt.xlabel('HighProtein')\n",
    "# plt.ylabel('Average Rating')\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:39.510352Z",
     "start_time": "2024-01-28T18:28:39.455437Z"
    }
   },
   "id": "249933b68ff314eb",
   "execution_count": 25
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.boxplot(x='HighCalories', y='Like', data=merged_request_review, palette='pastel')\n",
    "# plt.title('Box Plot of Likes for Recipes with and without High Calories')\n",
    "# plt.xlabel('HighCalories')\n",
    "# plt.ylabel('Like')\n",
    "# plt.show() \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:40.040889Z",
     "start_time": "2024-01-28T18:28:39.885428Z"
    }
   },
   "id": "683a1e26a75c70bd",
   "execution_count": 26
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# sns.pairplot(merged_request_review[['Like', 'Time', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar', 'HighFiber']])\n",
    "# plt.suptitle('Pair Plot of Merged Data', y=1.02)\n",
    "# plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:40.826293Z",
     "start_time": "2024-01-28T18:28:40.758614Z"
    }
   },
   "id": "ab723ac6ab1b8e0",
   "execution_count": 27
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CHECK** If a following recipe id exists and how many times and if the Recipe Id is mapped to the unique AuthorId "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2170603a82612"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# recipe_id_to_check = merged_request_review['RecipeId'].value_counts().idxmax()\n",
    "# \n",
    "# # Display the result\n",
    "# recipe_exists = merged_request_review['RecipeId'].isin([recipe_id_to_check])\n",
    "# \n",
    "# # Display the result\n",
    "# if recipe_exists.any():\n",
    "#     # print(f\"Recipe with RecipeId {recipe_id_to_check} exists.\")\n",
    "#     recipe_count = merged_request_review['RecipeId'].value_counts().get(recipe_id_to_check, 0)\n",
    "#     print(f\"Recipe with RecipeId {recipe_id_to_check} repeats {recipe_count} times.\")\n",
    "#     # Get the table of corresponding AuthorId values for the given RecipeId\n",
    "#     author_id_table = merged_request_review.loc[merged_request_review['RecipeId'] == recipe_id_to_check, ['AuthorId','RecipeId']]\n",
    "#     print(\"Table of AuthorId values for RecipeId\", recipe_id_to_check)\n",
    "#     print()\n",
    "#     \n",
    "# else:\n",
    "#     print(f\"Recipe with RecipeId {recipe_id_to_check} does not exist.\")\n",
    "# \n",
    "# author_id_table    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:41.623230Z",
     "start_time": "2024-01-28T18:28:41.547630Z"
    }
   },
   "id": "4563c515c8335bba",
   "execution_count": 28
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# unique_recipe_ids_from_merge = merged_request_review['RecipeId'].unique()\n",
    "# unique_recipe_ids_from_recipes = recipes['RecipeId'].unique()\n",
    "# are_ids_equal = set(unique_recipe_ids_from_recipes) == set(unique_recipe_ids_from_merge)\n",
    "# \n",
    "# if are_ids_equal:\n",
    "#     print(\"The unique RecipeId values are the same in both DataFrames.\")\n",
    "# else:\n",
    "#     print(\"The unique RecipeId values are not the same in both DataFrames.\")\n",
    "# \n",
    "# # # Assuming merged_request_review is the result of merging reviews and requests DataFrames\n",
    "# # # using pd.merge(reviews, requests, on=['AuthorId', 'RecipeId'])\n",
    "# # \n",
    "# # # Get the unique RecipeId values\n",
    "# # unique_recipe_ids = merged_request_review['RecipeId'].unique()\n",
    "# # \n",
    "# # # Initialize a list to store the uniqueness result for each RecipeId\n",
    "# # uniqueness_results = []\n",
    "# # \n",
    "# # # Iterate over unique RecipeId values\n",
    "# # for recipe_id in unique_recipe_ids:\n",
    "# #     # Get the table of corresponding AuthorId values for the given RecipeId\n",
    "# #     author_id_table = merged_request_review.loc[merged_request_review['RecipeId'] == recipe_id, ['AuthorId', 'RecipeId']]\n",
    "# # \n",
    "# #     # Check if the mapped AuthorId values are unique\n",
    "# #     is_author_id_unique = ~author_id_table['AuthorId'].duplicated().any()\n",
    "# # \n",
    "# #     uniqueness_results.append((recipe_id, is_author_id_unique))\n",
    "# # \n",
    "# # # Create a DataFrame from the results\n",
    "# # uniqueness_df = pd.DataFrame(uniqueness_results, columns=['RecipeId', 'IsAuthorIdUnique'])\n",
    "# # \n",
    "# # # Display the DataFrame\n",
    "# # print(uniqueness_df)\n",
    "# # # \n",
    "# # # Visualization: Bar plot of unique AuthorId counts for each RecipeId\n",
    "# # uniqueness_df.set_index('RecipeId')['IsAuthorIdUnique'].astype(int).plot(kind='bar', xlabel='RecipeId', ylabel='IsAuthorIdUnique (1: True, 0: False)', title='Uniqueness of AuthorId for Each RecipeId')\n",
    "# # plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:42.469311Z",
     "start_time": "2024-01-28T18:28:42.309851Z"
    }
   },
   "id": "d305ac55a6901072",
   "execution_count": 29
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating  Like  TestSetId          Time  \\\n0           914496A     73440     NaN   NaN     1548.0   1800.709345   \n1          2668181C     73440     2.0   NaN     2069.0   1797.825626   \n2       2000237272A     73440     2.0   NaN     2152.0   1800.440504   \n3       2001895110E     73440     NaN   NaN     3293.0   1799.437007   \n4       1800347124D     73440     NaN   NaN     4621.0   1801.007172   \n...             ...       ...     ...   ...        ...           ...   \n140190     1677720D    253577     2.0  True        NaN  71998.977353   \n140191      853126B    267827     NaN   NaN     7148.0   6299.278484   \n140192  2000154789A    266983     2.0  True        NaN   2700.812133   \n140193      499207A    253739     2.0  True        NaN    419.558713   \n140194      163793B     78171     NaN  True        NaN   1560.649725   \n\n        HighCalories  HighProtein  LowFat     LowSugar  ...  FatContent  \\\n0                0.0  Indifferent       0            0  ...        10.1   \n1                0.0          Yes       0  Indifferent  ...        10.1   \n2                1.0  Indifferent       0            0  ...        10.1   \n3                0.0  Indifferent       0            0  ...        10.1   \n4                1.0          Yes       0            0  ...        10.1   \n...              ...          ...     ...          ...  ...         ...   \n140190           0.0  Indifferent       1  Indifferent  ...         0.5   \n140191           0.0          Yes       1            0  ...        25.8   \n140192           0.0          Yes       0            0  ...         9.2   \n140193           1.0  Indifferent       0  Indifferent  ...        80.3   \n140194           0.0  Indifferent       0            0  ...        13.8   \n\n       SaturatedFatContent  CholesterolContent  SodiumContent  \\\n0                      1.2                 0.0           13.1   \n1                      1.2                 0.0           13.1   \n2                      1.2                 0.0           13.1   \n3                      1.2                 0.0           13.1   \n4                      1.2                 0.0           13.1   \n...                    ...                 ...            ...   \n140190                 0.1                 0.0         1175.1   \n140191                10.7               197.9          435.5   \n140192                 3.6                78.3          725.9   \n140193                69.3                 0.0          294.7   \n140194                 6.9                34.6         1114.0   \n\n       CarbohydrateContent FiberContent SugarContent  ProteinContent  \\\n0                     31.8          2.3          1.4             6.7   \n1                     31.8          2.3          1.4             6.7   \n2                     31.8          2.3          1.4             6.7   \n3                     31.8          2.3          1.4             6.7   \n4                     31.8          2.3          1.4             6.7   \n...                    ...          ...          ...             ...   \n140190                22.2          7.8          0.6             7.9   \n140191                51.9          7.5          7.2            50.1   \n140192                 7.3          1.1          1.7            26.7   \n140193               369.0         15.7        317.9            26.7   \n140194                92.2          3.9          4.2            21.8   \n\n        RecipeServings  RecipeYield  \n0                  9.0          NaN  \n1                  9.0          NaN  \n2                  9.0          NaN  \n3                  9.0          NaN  \n4                  9.0          NaN  \n...                ...          ...  \n140190             NaN          NaN  \n140191             NaN          NaN  \n140192             2.0          NaN  \n140193             NaN     1 gallon  \n140194             NaN   2 1/2 cups  \n\n[140195 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>914496A</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1548.0</td>\n      <td>1800.709345</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2668181C</td>\n      <td>73440</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2069.0</td>\n      <td>1797.825626</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000237272A</td>\n      <td>73440</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2152.0</td>\n      <td>1800.440504</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001895110E</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3293.0</td>\n      <td>1799.437007</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800347124D</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4621.0</td>\n      <td>1801.007172</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>1677720D</td>\n      <td>253577</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>71998.977353</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1175.1</td>\n      <td>22.2</td>\n      <td>7.8</td>\n      <td>0.6</td>\n      <td>7.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>853126B</td>\n      <td>267827</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7148.0</td>\n      <td>6299.278484</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>25.8</td>\n      <td>10.7</td>\n      <td>197.9</td>\n      <td>435.5</td>\n      <td>51.9</td>\n      <td>7.5</td>\n      <td>7.2</td>\n      <td>50.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>2000154789A</td>\n      <td>266983</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>2700.812133</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9.2</td>\n      <td>3.6</td>\n      <td>78.3</td>\n      <td>725.9</td>\n      <td>7.3</td>\n      <td>1.1</td>\n      <td>1.7</td>\n      <td>26.7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>499207A</td>\n      <td>253739</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>419.558713</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>80.3</td>\n      <td>69.3</td>\n      <td>0.0</td>\n      <td>294.7</td>\n      <td>369.0</td>\n      <td>15.7</td>\n      <td>317.9</td>\n      <td>26.7</td>\n      <td>NaN</td>\n      <td>1 gallon</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>163793B</td>\n      <td>78171</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>1560.649725</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13.8</td>\n      <td>6.9</td>\n      <td>34.6</td>\n      <td>1114.0</td>\n      <td>92.2</td>\n      <td>3.9</td>\n      <td>4.2</td>\n      <td>21.8</td>\n      <td>NaN</td>\n      <td>2 1/2 cups</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_recipes_req_review= pd.merge(merged_request_review,recipes,on=['RecipeId'],how='right')\n",
    "merged_recipes_req_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:44.352144Z",
     "start_time": "2024-01-28T18:28:44.036960Z"
    }
   },
   "id": "a09bd1c03e12ce80",
   "execution_count": 30
  },
  {
   "cell_type": "markdown",
   "source": [
    "Changing the object data types"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f8738647b7b81bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Joining using common attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de61709106b4c884"
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.386790           0.0          Yes  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2402.372535           0.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5999.598903           0.0          Yes  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.386790</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_ID = 'AuthorId'\n",
    "merged_diet_all = pd.merge(diet, merged_recipes_req_review, on=author_ID)\n",
    "# merged_request_recipes = pd.merge(requests, recipes, on='RecipeId', how='left')\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:48.146438Z",
     "start_time": "2024-01-28T18:28:47.872228Z"
    }
   },
   "id": "b4f7cfcbad4cda38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot graphs of the data frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1caafd20b94c3350"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:50.029636Z",
     "start_time": "2024-01-28T18:28:49.962615Z"
    }
   },
   "id": "689761e3058a5d67",
   "execution_count": 31
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "a04953e769786134"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "e95fb1b44bf32b76"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute the missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9062a6a8aa6efd46"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "outputs": [],
   "source": [
    "\n",
    "# 1 value missing in diet column. Filled with most occuring value.\n",
    "merged_diet_all['Diet'] = merged_diet_all['Diet'].fillna('Vegetarian')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:53.086220Z",
     "start_time": "2024-01-28T18:28:53.029417Z"
    }
   },
   "id": "c3518f9894f574d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.386790           0.0          Yes  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2402.372535           0.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5999.598903           0.0          Yes  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.386790</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impute the values for all dietary preferences for all ages with the most frequent RecipeId for that age in that category\n",
    "helper_df = merged_diet_all.groupby(['Age', 'Diet'])['RecipeId'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "helper_df.columns = ['Age', 'Diet', 'Most Common Recipe']\n",
    "def impute_recipe(row):\n",
    "    if pd.isnull(row['RecipeId']):\n",
    "        return helper_df[(helper_df['Age'] == row['Age']) & (helper_df['Diet'] == row['Diet'])]['Most Common Recipe'].values[0]\n",
    "    else:\n",
    "        return row['RecipeId']\n",
    "merged_diet_all['RecipeId'] = merged_diet_all.apply(impute_recipe, axis=1)\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:54.446060Z",
     "start_time": "2024-01-28T18:28:53.456424Z"
    }
   },
   "id": "d11e460c388617a3",
   "execution_count": 33
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.549763           1.0  Indifferent  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2400.009731           1.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5998.670408           1.0  Indifferent  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the rest of the missing values in the merged_diet_all by mapping them from requests.csv with RecipeId as key \n",
    "# Create mapping DataFrames from `requests`\n",
    "map_time = requests.set_index('RecipeId')['Time'].to_dict()\n",
    "map_calories = requests.set_index('RecipeId')['HighCalories'].to_dict()\n",
    "map_protein = requests.set_index('RecipeId')['HighProtein'].to_dict()\n",
    "map_fat = requests.set_index('RecipeId')['LowFat'].to_dict()\n",
    "map_sugar = requests.set_index('RecipeId')['LowSugar'].to_dict()\n",
    "map_fiber = requests.set_index('RecipeId')['HighFiber'].to_dict()\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['Time'] = merged_diet_all['RecipeId'].map(map_time)\n",
    "merged_diet_all['HighCalories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['HighProtein'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['LowFat'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['LowSugar'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['HighFiber'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:28:55.628204Z",
     "start_time": "2024-01-28T18:28:54.369810Z"
    }
   },
   "id": "dfc5cbaa679201ad",
   "execution_count": 34
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute value from recipe.csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c0a1c86901f370"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "map_name = recipes.set_index('RecipeId')['RecipeName'].to_dict()\n",
    "map_cook_time = recipes.set_index('RecipeId')['CookTime'].to_dict()\n",
    "map_prep_time = recipes.set_index('RecipeId')['PrepTime'].to_dict()\n",
    "map_category = recipes.set_index('RecipeId')['RecipeCategory'].to_dict()\n",
    "map_quantities = recipes.set_index('RecipeId')['RecipeIngredientQuantities'].to_dict()\n",
    "map_parts = recipes.set_index('RecipeId')['RecipeIngredientParts'].to_dict()\n",
    "map_calories = recipes.set_index('RecipeId')['Calories'].to_dict()\n",
    "map_fat_content = recipes.set_index('RecipeId')['FatContent'].to_dict()\n",
    "map_saturated_content = recipes.set_index('RecipeId')['SaturatedFatContent'].to_dict()\n",
    "map_cholesterol = recipes.set_index('RecipeId')['CholesterolContent'].to_dict()\n",
    "map_sodium = recipes.set_index('RecipeId')['SodiumContent'].to_dict()\n",
    "map_carbohydrate = recipes.set_index('RecipeId')['CarbohydrateContent'].to_dict()\n",
    "map_fiber = recipes.set_index('RecipeId')['FiberContent'].to_dict()\n",
    "map_sugar = recipes.set_index('RecipeId')['SugarContent'].to_dict()\n",
    "map_protein = recipes.set_index('RecipeId')['ProteinContent'].to_dict()\n",
    "map_servings = recipes.set_index('RecipeId')['RecipeServings'].to_dict()\n",
    "map_yield = recipes.set_index('RecipeId')['RecipeYield'].to_dict()\n",
    "\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['RecipeName'] = merged_diet_all['RecipeId'].map(map_name)\n",
    "merged_diet_all['CookTime'] = merged_diet_all['RecipeId'].map(map_cook_time)\n",
    "merged_diet_all['PrepTime'] = merged_diet_all['RecipeId'].map(map_prep_time)\n",
    "merged_diet_all['RecipeCategory'] = merged_diet_all['RecipeId'].map(map_category)\n",
    "merged_diet_all['RecipeIngredientQuantities'] = merged_diet_all['RecipeId'].map(map_quantities)\n",
    "merged_diet_all['RecipeIngredientParts'] = merged_diet_all['RecipeId'].map(map_parts)\n",
    "merged_diet_all['Calories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['FatContent'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['SaturatedFatContent'] = merged_diet_all['RecipeId'].map(map_saturated_content)\n",
    "merged_diet_all['CholesterolContent'] = merged_diet_all['RecipeId'].map(map_cholesterol)\n",
    "merged_diet_all['SodiumContent'] = merged_diet_all['RecipeId'].map(map_sodium)\n",
    "merged_diet_all['CarbohydrateContent'] = merged_diet_all['RecipeId'].map(map_carbohydrate)\n",
    "merged_diet_all['FiberContent'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all['SugarContent'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['ProteinContent'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['RecipeServings'] = merged_diet_all['RecipeId'].map(map_servings)\n",
    "merged_diet_all['RecipeYield'] = merged_diet_all['RecipeId'].map(map_yield)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:29:01.977560Z",
     "start_time": "2024-01-28T18:29:01.182914Z"
    }
   },
   "id": "374829871d19a91",
   "execution_count": 35
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CHECK IF IT WORKS**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce4bfb36b4247f4a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     0.0  False        NaN   \n1       1000216B  Vegetarian   78    189335     0.0  False        NaN   \n2       1000221A  Vegetarian   25     17444     0.0  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     0.0  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     0.0    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...           0   \n1       1199.549763           1.0  Indifferent  ...           0   \n2       3899.147999           1.0          Yes  ...           0   \n3        362.152341           0.0          Yes  ...           0   \n4       1198.957497           0.0          Yes  ...           0   \n...             ...           ...          ...  ...         ...   \n140190  2400.009731           1.0  Indifferent  ...           0   \n140191   480.233207           1.0          Yes  ...           0   \n140192  5998.670408           1.0  Indifferent  ...           0   \n140193  3600.387748           0.0  Indifferent  ...           0   \n140194  7199.509521           0.0          Yes  ...           0   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_diet_all['Rating'] = merged_diet_all['Rating'].fillna(0)\n",
    "merged_diet_all['TestSetId'] = merged_diet_all['TestSetId']\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T19:21:45.061720Z",
     "start_time": "2024-01-28T19:21:44.923861Z"
    }
   },
   "id": "61303a62f5e8933d",
   "execution_count": 74
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Like\n",
      "True     0.5\n",
      "False    0.5\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df = merged_diet_all\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "proportion_true = df['Like'].mean()\n",
    "proportion_false = 1 - proportion_true\n",
    "\n",
    "# Identify the indices of false values\n",
    "false_indices = df[df['Like'] == False].index\n",
    "\n",
    "# Randomly sample false indices to achieve a balanced proportion\n",
    "num_false_to_sample = int(df['Like'].value_counts()[True] / proportion_true) - df['Like'].value_counts()[False]\n",
    "indices_to_sample = np.random.choice(false_indices, size=num_false_to_sample, replace=False)\n",
    "\n",
    "# Create a new DataFrame with sampled false values\n",
    "df_balanced = pd.concat([df[df['Like'] == True], df.loc[indices_to_sample]])\n",
    "\n",
    "# Shuffle the new DataFrame to randomize the order\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the proportion of true and false values in the balanced DataFrame\n",
    "print(df_balanced['Like'].value_counts(normalize=True))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T19:43:26.910592Z",
     "start_time": "2024-01-28T19:43:26.709608Z"
    }
   },
   "id": "6f323506d35210a8",
   "execution_count": 91
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0      2000505765C  Vegetarian   44    439034     0.0   True        NaN   \n1         2419620E       Vegan   31    208619     0.0   True        NaN   \n2         2655564E  Vegetarian   25     45557     0.0  False        NaN   \n3      2000324201C  Vegetarian   62      1481     2.0   True        NaN   \n4      2002752875E  Vegetarian   54    178401     0.0  False        NaN   \n...            ...         ...  ...       ...     ...    ...        ...   \n25751  1803316815C  Vegetarian   56    209347     0.0  False        NaN   \n25752  2001055509B  Vegetarian   66     18510     2.0   True        NaN   \n25753     1184634D  Vegetarian   68     43522     0.0   True        NaN   \n25754  2000760057B  Vegetarian   65    193732     0.0  False        NaN   \n25755      604831D  Vegetarian   19    467509     2.0  False        NaN   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0       1199.936304           0.0  Indifferent  ...           0   \n1       1199.524490           1.0          Yes  ...           0   \n2       2699.697526           1.0  Indifferent  ...           0   \n3       4801.663258           0.0  Indifferent  ...           1   \n4      10800.160212           0.0  Indifferent  ...           0   \n...             ...           ...          ...  ...         ...   \n25751   4200.410191           1.0  Indifferent  ...           1   \n25752    119.221052           0.0          Yes  ...           0   \n25753   3599.134079           1.0  Indifferent  ...           0   \n25754   6301.568932           0.0          Yes  ...           0   \n25755    901.782911           1.0          Yes  ...           0   \n\n      SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                     0.7                61.6         579.6   \n1                    27.1                29.4         134.2   \n2                     4.5                53.4         294.0   \n3                     0.4                 0.0           3.9   \n4                     4.7                92.8         702.3   \n...                   ...                 ...           ...   \n25751                 0.4                65.8          75.7   \n25752                 9.9               216.5         439.8   \n25753                25.8               194.3         668.9   \n25754                 7.8                36.7         297.3   \n25755                 1.4                 0.0        3027.1   \n\n       CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                     14.0           1.4          3.1           19.6   \n1                    112.5           8.6         76.5           18.5   \n2                     43.9           0.6         32.0            3.3   \n3                      8.3           1.6          4.2            1.3   \n4                     28.5           0.5         22.5           30.5   \n...                    ...           ...          ...            ...   \n25751                  1.0           0.0          0.3           26.2   \n25752                  9.0           7.7          0.6           11.5   \n25753                102.7           3.3         60.7           11.3   \n25754                  3.6           0.4          1.2            7.7   \n25755                  9.2           0.6          3.7           15.9   \n\n      RecipeServings          RecipeYield  \n0                4.0                  NaN  \n1                NaN                  NaN  \n2               18.0                  NaN  \n3                NaN            1 platter  \n4                NaN                  NaN  \n...              ...                  ...  \n25751            4.0                  NaN  \n25752            1.0  1 1 Bun or 2 slices  \n25753            6.0               1 cake  \n25754            NaN                  NaN  \n25755            2.0                  NaN  \n\n[25756 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2000505765C</td>\n      <td>Vegetarian</td>\n      <td>44</td>\n      <td>439034</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>1199.936304</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.7</td>\n      <td>61.6</td>\n      <td>579.6</td>\n      <td>14.0</td>\n      <td>1.4</td>\n      <td>3.1</td>\n      <td>19.6</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2419620E</td>\n      <td>Vegan</td>\n      <td>31</td>\n      <td>208619</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>1199.524490</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>27.1</td>\n      <td>29.4</td>\n      <td>134.2</td>\n      <td>112.5</td>\n      <td>8.6</td>\n      <td>76.5</td>\n      <td>18.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2655564E</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>45557</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2699.697526</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.5</td>\n      <td>53.4</td>\n      <td>294.0</td>\n      <td>43.9</td>\n      <td>0.6</td>\n      <td>32.0</td>\n      <td>3.3</td>\n      <td>18.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2000324201C</td>\n      <td>Vegetarian</td>\n      <td>62</td>\n      <td>1481</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>4801.663258</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.4</td>\n      <td>0.0</td>\n      <td>3.9</td>\n      <td>8.3</td>\n      <td>1.6</td>\n      <td>4.2</td>\n      <td>1.3</td>\n      <td>NaN</td>\n      <td>1 platter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2002752875E</td>\n      <td>Vegetarian</td>\n      <td>54</td>\n      <td>178401</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>10800.160212</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.7</td>\n      <td>92.8</td>\n      <td>702.3</td>\n      <td>28.5</td>\n      <td>0.5</td>\n      <td>22.5</td>\n      <td>30.5</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>25751</th>\n      <td>1803316815C</td>\n      <td>Vegetarian</td>\n      <td>56</td>\n      <td>209347</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>4200.410191</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.4</td>\n      <td>65.8</td>\n      <td>75.7</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.3</td>\n      <td>26.2</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25752</th>\n      <td>2001055509B</td>\n      <td>Vegetarian</td>\n      <td>66</td>\n      <td>18510</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>119.221052</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>9.9</td>\n      <td>216.5</td>\n      <td>439.8</td>\n      <td>9.0</td>\n      <td>7.7</td>\n      <td>0.6</td>\n      <td>11.5</td>\n      <td>1.0</td>\n      <td>1 1 Bun or 2 slices</td>\n    </tr>\n    <tr>\n      <th>25753</th>\n      <td>1184634D</td>\n      <td>Vegetarian</td>\n      <td>68</td>\n      <td>43522</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>3599.134079</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>25.8</td>\n      <td>194.3</td>\n      <td>668.9</td>\n      <td>102.7</td>\n      <td>3.3</td>\n      <td>60.7</td>\n      <td>11.3</td>\n      <td>6.0</td>\n      <td>1 cake</td>\n    </tr>\n    <tr>\n      <th>25754</th>\n      <td>2000760057B</td>\n      <td>Vegetarian</td>\n      <td>65</td>\n      <td>193732</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>6301.568932</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7.8</td>\n      <td>36.7</td>\n      <td>297.3</td>\n      <td>3.6</td>\n      <td>0.4</td>\n      <td>1.2</td>\n      <td>7.7</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>25755</th>\n      <td>604831D</td>\n      <td>Vegetarian</td>\n      <td>19</td>\n      <td>467509</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>901.782911</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1.4</td>\n      <td>0.0</td>\n      <td>3027.1</td>\n      <td>9.2</td>\n      <td>0.6</td>\n      <td>3.7</td>\n      <td>15.9</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>25756 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T19:43:30.234978Z",
     "start_time": "2024-01-28T19:43:30.126525Z"
    }
   },
   "id": "20638952b41becd7",
   "execution_count": 92
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# final_data = merged_diet_all\n",
    "# final_data['AuthorId'], unique_authorids = pd.factorize(final_data['AuthorId'])\n",
    "# \n",
    "# final_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:16:42.298529Z",
     "start_time": "2024-01-28T18:16:42.201932Z"
    }
   },
   "id": "8c5c389a74943244",
   "execution_count": 37
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId Diet  Age  RecipeId  Rating   Like  TestSetId         Time  \\\n0       1000036C    2   50    320576     0.0  False        NaN   119.024930   \n1       1000216B    2   78    189335     0.0  False        NaN  1199.549763   \n2       1000221A    2   25     17444     0.0  False        NaN  3899.147999   \n3       1000221A    2   25    133043     2.0  False        NaN   362.152341   \n4       1000221A    2   25     90537     2.0  False        NaN  1198.957497   \n...          ...  ...  ...       ...     ...    ...        ...          ...   \n140190   999774A    2   57     29002     2.0  False        NaN  2400.009731   \n140191   999774A    2   57      1171     2.0   True        NaN   480.233207   \n140192   999774A    2   57    159252     0.0  False        NaN  5998.670408   \n140193   999917E    2   28    169413     2.0  False        NaN  3600.387748   \n140194    99994A    2   18    373964     0.0    NaN     7555.0  7199.509521   \n\n        HighCalories  HighProtein  ...  FatContent  SaturatedFatContent  \\\n0                0.0            0  ...           0                  0.0   \n1                1.0            0  ...           0                  4.5   \n2                1.0            1  ...           0                  6.0   \n3                0.0            1  ...           0                  1.9   \n4                0.0            1  ...           0                  7.2   \n...              ...          ...  ...         ...                  ...   \n140190           1.0            0  ...           0                  8.5   \n140191           1.0            1  ...           0                 12.2   \n140192           1.0            0  ...           0                  0.1   \n140193           0.0            0  ...           0                  4.7   \n140194           0.0            1  ...           0                  0.0   \n\n        CholesterolContent SodiumContent  CarbohydrateContent  FiberContent  \\\n0                      0.0           0.6                  0.0           0.0   \n1                     33.9         714.2                 38.0           0.8   \n2                     36.6         119.8                 13.7           1.0   \n3                      0.0           0.6                  1.9           0.4   \n4                      0.0         115.8                241.7          69.4   \n...                    ...           ...                  ...           ...   \n140190                33.2         318.2                107.7          10.3   \n140191                68.3         247.4                 87.5           4.0   \n140192                 0.0           6.8                240.4           7.0   \n140193                66.5         521.9                 24.8           1.7   \n140194                 0.0           5.6                 36.2           0.2   \n\n       SugarContent ProteinContent RecipeServings  RecipeYield  \n0               0.0            0.0            1.0          NaN  \n1               4.3           16.3            8.0          NaN  \n2               1.0            8.7           12.0          NaN  \n3               0.4            0.2            NaN     4 ounces  \n4              15.7           68.9            1.0          NaN  \n...             ...            ...            ...          ...  \n140190         13.5           32.0            4.0          NaN  \n140191         57.8           18.2            1.0       2 mugs  \n140192        229.8            1.1            NaN       4 cups  \n140193          3.4            5.6            8.0          NaN  \n140194         33.6            0.2           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>2</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>2</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>2</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>2</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# diet_mapping = {'Vegan': 1, 'Vegetarian': 2, 'Omnivore': 3}\n",
    "# protien_mapping = {'Yes': 1, 'Indifferent': 0}\n",
    "# sugar_mapping = { 'Indifferent': 1,'0':0}\n",
    "# # RECIPE CATEGORY TRAINNNNNNNNNNNNN\n",
    "# \n",
    "# # Apply mapping to the 'Diet' column\n",
    "# merged_diet_all['Diet'] = merged_diet_all['Diet'].map(diet_mapping)\n",
    "# merged_diet_all['HighProtein'] = merged_diet_all['HighProtein'].map(protien_mapping)\n",
    "# merged_diet_all['LowSugar'] = merged_diet_all['LowSugar'].map(sugar_mapping)\n",
    "# \n",
    "# merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:16:43.435276Z",
     "start_time": "2024-01-28T18:16:43.319304Z"
    }
   },
   "id": "e843108e538c4558",
   "execution_count": 38
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Function to clean the the strings\n",
    "# import pandas as pd\n",
    "# \n",
    "# # Updated clean_string function\n",
    "# def clean_string(string):\n",
    "#     # Remove 'c(' and ')' and replace escaped backslashes and double quotes\n",
    "#     cleaned_string = string.replace('c(', '').replace(')', '').replace('\\\\', '').replace('\\\"', '')\n",
    "# \n",
    "#     # Split the cleaned string by commas and remove extra spaces\n",
    "#     parsed_string = [val.strip() for val in cleaned_string.split(',')]\n",
    "# \n",
    "#     # Convert string elements to int\n",
    "#     parsed_string = [int(val) if val.isdigit() else val for val in parsed_string]\n",
    "# \n",
    "#     return parsed_string\n",
    "# \n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('recipes.csv')\n",
    "# \n",
    "# # Apply the updated clean_string function to the RecipeIngredientQuantities column\n",
    "# df['RecipeIngredientQuantities'] = df['RecipeIngredientQuantities'].apply(clean_string)\n",
    "# df['RecipeIngredientParts'] = df['RecipeIngredientParts'].apply(clean_string)\n",
    "# \n",
    "# #Display the DataFrame with updated and cleaned values\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:16:47.501679Z",
     "start_time": "2024-01-28T18:16:47.457140Z"
    }
   },
   "id": "a656f7439b5dc632",
   "execution_count": 39
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Function to calculate RecipeServings based on quantities\n",
    "# def calculate_servings(quantities):\n",
    "#     try:\n",
    "#         # Sum up the quantities to get the total amount of ingredients\n",
    "#         total_quantity = sum(eval(quantities))\n",
    "# \n",
    "#         # Assuming a base serving size, you can adjust this based on your data\n",
    "#         base_serving_size = 1\n",
    "# \n",
    "#         # Calculate the servings based on the total quantity and the base serving size\n",
    "#         servings = total_quantity / base_serving_size\n",
    "#         return servings\n",
    "#     except (ValueError, SyntaxError) as e:\n",
    "#         # Handle the case where the calculation fails\n",
    "#         print(f\"Error calculating servings: {e}\")\n",
    "#         return None\n",
    "# \n",
    "# # Apply the function to calculate RecipeServings\n",
    "# df['RecipeServings'] = df['RecipeIngredientQuantities'].apply(calculate_servings)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:16:48.313631Z",
     "start_time": "2024-01-28T18:16:48.273743Z"
    }
   },
   "id": "3cc2759b5afea205",
   "execution_count": 40
  },
  {
   "cell_type": "markdown",
   "source": [
    "Export data frame to csv file to train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4db8bf23cd2172e"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeServings', 'RecipeYield', 'RecipeName', 'RecipeCategory'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyError\u001B[0m                                  Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[50], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m columns_to_drop \u001B[38;5;241m=\u001B[39m [\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeIngredientQuantities\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeIngredientParts\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeServings\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeYield\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeName\u001B[39m\u001B[38;5;124m'\u001B[39m, \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mRecipeCategory\u001B[39m\u001B[38;5;124m'\u001B[39m]\n\u001B[0;32m----> 2\u001B[0m merged_diet_all \u001B[38;5;241m=\u001B[39m merged_diet_all\u001B[38;5;241m.\u001B[39mdrop(columns_to_drop, axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# final_data.to_csv('final_data.csv', index=False)\u001B[39;00m\n\u001B[1;32m      5\u001B[0m merged_diet_all\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/frame.py:5347\u001B[0m, in \u001B[0;36mDataFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   5199\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdrop\u001B[39m(\n\u001B[1;32m   5200\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m   5201\u001B[0m     labels: IndexLabel \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5208\u001B[0m     errors: IgnoreRaise \u001B[38;5;241m=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mraise\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[1;32m   5209\u001B[0m ) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m DataFrame \u001B[38;5;241m|\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m   5210\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m   5211\u001B[0m \u001B[38;5;124;03m    Drop specified labels from rows or columns.\u001B[39;00m\n\u001B[1;32m   5212\u001B[0m \n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   5345\u001B[0m \u001B[38;5;124;03m            weight  1.0     0.8\u001B[39;00m\n\u001B[1;32m   5346\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 5347\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mdrop(\n\u001B[1;32m   5348\u001B[0m         labels\u001B[38;5;241m=\u001B[39mlabels,\n\u001B[1;32m   5349\u001B[0m         axis\u001B[38;5;241m=\u001B[39maxis,\n\u001B[1;32m   5350\u001B[0m         index\u001B[38;5;241m=\u001B[39mindex,\n\u001B[1;32m   5351\u001B[0m         columns\u001B[38;5;241m=\u001B[39mcolumns,\n\u001B[1;32m   5352\u001B[0m         level\u001B[38;5;241m=\u001B[39mlevel,\n\u001B[1;32m   5353\u001B[0m         inplace\u001B[38;5;241m=\u001B[39minplace,\n\u001B[1;32m   5354\u001B[0m         errors\u001B[38;5;241m=\u001B[39merrors,\n\u001B[1;32m   5355\u001B[0m     )\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4711\u001B[0m, in \u001B[0;36mNDFrame.drop\u001B[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001B[0m\n\u001B[1;32m   4709\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m axis, labels \u001B[38;5;129;01min\u001B[39;00m axes\u001B[38;5;241m.\u001B[39mitems():\n\u001B[1;32m   4710\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m labels \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[0;32m-> 4711\u001B[0m         obj \u001B[38;5;241m=\u001B[39m obj\u001B[38;5;241m.\u001B[39m_drop_axis(labels, axis, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4713\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m inplace:\n\u001B[1;32m   4714\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_update_inplace(obj)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/generic.py:4753\u001B[0m, in \u001B[0;36mNDFrame._drop_axis\u001B[0;34m(self, labels, axis, level, errors, only_slice)\u001B[0m\n\u001B[1;32m   4751\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, level\u001B[38;5;241m=\u001B[39mlevel, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4752\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m-> 4753\u001B[0m         new_axis \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mdrop(labels, errors\u001B[38;5;241m=\u001B[39merrors)\n\u001B[1;32m   4754\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m axis\u001B[38;5;241m.\u001B[39mget_indexer(new_axis)\n\u001B[1;32m   4756\u001B[0m \u001B[38;5;66;03m# Case for non-unique axis\u001B[39;00m\n\u001B[1;32m   4757\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/pandas/core/indexes/base.py:6992\u001B[0m, in \u001B[0;36mIndex.drop\u001B[0;34m(self, labels, errors)\u001B[0m\n\u001B[1;32m   6990\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m mask\u001B[38;5;241m.\u001B[39many():\n\u001B[1;32m   6991\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m errors \u001B[38;5;241m!=\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mignore\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n\u001B[0;32m-> 6992\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mKeyError\u001B[39;00m(\u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;132;01m{\u001B[39;00mlabels[mask]\u001B[38;5;241m.\u001B[39mtolist()\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m not found in axis\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m   6993\u001B[0m     indexer \u001B[38;5;241m=\u001B[39m indexer[\u001B[38;5;241m~\u001B[39mmask]\n\u001B[1;32m   6994\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdelete(indexer)\n",
      "\u001B[0;31mKeyError\u001B[0m: \"['RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeServings', 'RecipeYield', 'RecipeName', 'RecipeCategory'] not found in axis\""
     ]
    }
   ],
   "source": [
    "columns_to_drop = ['RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeServings', 'RecipeYield', 'RecipeName', 'RecipeCategory']\n",
    "merged_diet_all = merged_diet_all.drop(columns_to_drop, axis=1)\n",
    "\n",
    "# final_data.to_csv('final_data.csv', index=False)\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:27:53.469891Z",
     "start_time": "2024-01-28T18:27:51.884712Z"
    }
   },
   "id": "85175a133583aa46",
   "execution_count": 50
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df = final_data.loc[final_data['CookTime'] <= 7200]\n",
    "# df\n",
    "# final_data.drop(final_data[final_data['CookTime'] > 7200].index, inplace=True)\n",
    "# final_data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "294c454f389425c8",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "Random Forest Classifier"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9773fae63235802f"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Index: 312123 entries, 0 to 362752\n",
      "Data columns (total 19 columns):\n",
      " #   Column               Non-Null Count   Dtype   \n",
      "---  ------               --------------   -----   \n",
      " 0   Diet                 312123 non-null  category\n",
      " 1   Age                  312123 non-null  int64   \n",
      " 2   Like                 90758 non-null   object  \n",
      " 3   TestSetId            312123 non-null  float64 \n",
      " 4   HighCalories         312123 non-null  float64 \n",
      " 5   HighProtein          312123 non-null  int64   \n",
      " 6   LowFat               312123 non-null  int64   \n",
      " 7   LowSugar             312123 non-null  int64   \n",
      " 8   HighFiber            312123 non-null  int64   \n",
      " 9   CookTime             312123 non-null  int64   \n",
      " 10  Calories             312123 non-null  float64 \n",
      " 11  FatContent           312123 non-null  int64   \n",
      " 12  SaturatedFatContent  312123 non-null  float64 \n",
      " 13  CholesterolContent   312123 non-null  float64 \n",
      " 14  SodiumContent        312123 non-null  float64 \n",
      " 15  CarbohydrateContent  312123 non-null  float64 \n",
      " 16  FiberContent         312123 non-null  float64 \n",
      " 17  SugarContent         312123 non-null  float64 \n",
      " 18  ProteinContent       312123 non-null  float64 \n",
      "dtypes: category(1), float64(10), int64(7), object(1)\n",
      "memory usage: 45.5+ MB\n"
     ]
    }
   ],
   "source": [
    "# final_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T17:47:24.437941Z",
     "start_time": "2024-01-28T17:47:24.120153Z"
    }
   },
   "id": "e0509756395100fc",
   "execution_count": 93
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId Diet  Age  RecipeId  Rating   Like         Time  \\\n0       1000036C    2   50    320576     0.0  False   119.024930   \n1       1000216B    2   78    189335     0.0  False  1199.549763   \n2       1000221A    2   25     17444     0.0  False  3899.147999   \n3       1000221A    2   25    133043     2.0  False   362.152341   \n4       1000221A    2   25     90537     2.0  False  1198.957497   \n...          ...  ...  ...       ...     ...    ...          ...   \n140189   999595E    2   31    338070     2.0  False  3899.421310   \n140190   999774A    2   57     29002     2.0  False  2400.009731   \n140191   999774A    2   57      1171     2.0   True   480.233207   \n140192   999774A    2   57    159252     0.0  False  5998.670408   \n140193   999917E    2   28    169413     2.0  False  3600.387748   \n\n        HighCalories  HighProtein  LowFat  ...  PrepTime  Calories  \\\n0                0.0            0       0  ...       120     138.7   \n1                1.0            0       0  ...       600     395.7   \n2                1.0            1       0  ...      2100     181.7   \n3                0.0            1       0  ...       300     125.6   \n4                0.0            1       0  ...      1200    1590.1   \n...              ...          ...     ...  ...       ...       ...   \n140189           0.0            0       1  ...       900     464.3   \n140190           1.0            0       0  ...      1200     838.5   \n140191           1.0            1       0  ...       120     665.9   \n140192           1.0            0       0  ...      1200     928.0   \n140193           0.0            0       0  ...       900     194.8   \n\n        FatContent  SaturatedFatContent  CholesterolContent  SodiumContent  \\\n0                0                  0.0                 0.0            0.6   \n1                0                  4.5                33.9          714.2   \n2                0                  6.0                36.6          119.8   \n3                0                  1.9                 0.0            0.6   \n4                0                  7.2                 0.0          115.8   \n...            ...                  ...                 ...            ...   \n140189           1                 15.0                99.8          391.7   \n140190           0                  8.5                33.2          318.2   \n140191           0                 12.2                68.3          247.4   \n140192           0                  0.1                 0.0            6.8   \n140193           0                  4.7                66.5          521.9   \n\n        CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \n0                       0.0           0.0           0.0             0.0  \n1                      38.0           0.8           4.3            16.3  \n2                      13.7           1.0           1.0             8.7  \n3                       1.9           0.4           0.4             0.2  \n4                     241.7          69.4          15.7            68.9  \n...                     ...           ...           ...             ...  \n140189                 43.1           1.4          27.3             5.2  \n140190                107.7          10.3          13.5            32.0  \n140191                 87.5           4.0          57.8            18.2  \n140192                240.4           7.0         229.8             1.1  \n140193                 24.8           1.7           3.4             5.6  \n\n[97381 rows x 23 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>...</th>\n      <th>PrepTime</th>\n      <th>Calories</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>2</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>120</td>\n      <td>138.7</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>2</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>600</td>\n      <td>395.7</td>\n      <td>0</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>2100</td>\n      <td>181.7</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>300</td>\n      <td>125.6</td>\n      <td>0</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>2</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1200</td>\n      <td>1590.1</td>\n      <td>0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140189</th>\n      <td>999595E</td>\n      <td>2</td>\n      <td>31</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>3899.421310</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>...</td>\n      <td>900</td>\n      <td>464.3</td>\n      <td>1</td>\n      <td>15.0</td>\n      <td>99.8</td>\n      <td>391.7</td>\n      <td>43.1</td>\n      <td>1.4</td>\n      <td>27.3</td>\n      <td>5.2</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1200</td>\n      <td>838.5</td>\n      <td>0</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>120</td>\n      <td>665.9</td>\n      <td>0</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>2</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>1200</td>\n      <td>928.0</td>\n      <td>0</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>2</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>900</td>\n      <td>194.8</td>\n      <td>0</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n    </tr>\n  </tbody>\n</table>\n<p>97381 rows × 23 columns</p>\n</div>"
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# df = merged_diet_all.copy()\n",
    "# \n",
    "# \n",
    "# \n",
    "# # Drop rows with NaN values in the target column ('Like') for training set\n",
    "# train_data = df[df['TestSetId'].isna()]\n",
    "# train_data = train_data.drop('TestSetId', axis=1)\n",
    "# train_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:17:41.779769Z",
     "start_time": "2024-01-28T18:17:41.659936Z"
    }
   },
   "id": "c0a797c0d6d47b22",
   "execution_count": 42
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'final_data' has features and the target variable 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') for training set\n",
    "train_data = df_balanced.dropna(subset=['Like'])\n",
    "\n",
    "# Assuming 'X' contains features and 'y' is the target variable\n",
    "X = train_data.drop(columns=['Like'])\n",
    "y = train_data['Like']\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T17:47:24.686617Z",
     "start_time": "2024-01-28T17:47:24.288164Z"
    }
   },
   "id": "2043d31ecfbc21a9",
   "execution_count": 95
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "### data wrangling\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "\n",
    "transform_scaler = StandardScaler()\n",
    "\n",
    "# dimensionality reduction\n",
    "transform_pca = PCA()\n",
    "\n",
    "# value imputing\n",
    "\n",
    "# outlier detection/removal"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:08:10.940947Z",
     "start_time": "2024-01-28T18:08:10.894384Z"
    }
   },
   "id": "4214a65ef5ae9f00",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.series.Series'>\n",
      "Index: 63530 entries, 116252 to 287567\n",
      "Series name: Like\n",
      "Non-Null Count  Dtype\n",
      "--------------  -----\n",
      "63530 non-null  bool \n",
      "dtypes: bool(1)\n",
      "memory usage: 558.4 KB\n"
     ]
    }
   ],
   "source": [
    "# # split data into learning and test sets\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# X_train, X_test, y_train, y_test = \\\n",
    "#     train_test_split(final_data.iloc[:, :-1], train_data.iloc[:, -1:],\n",
    "#                      test_size=0.3,\n",
    "#                      shuffle=True,\n",
    "#                      random_state=3)\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Assuming 'final_data' has features and the target variable 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') for training set\n",
    "train_data = final_data.dropna(subset=['Like'])\n",
    "\n",
    "# Assuming 'X' contains features and 'y' is the target variable\n",
    "X = train_data.drop(columns=['Like'])\n",
    "y = train_data['Like'].astype(bool)\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=3)\n",
    "y_train.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:08:11.793335Z",
     "start_time": "2024-01-28T18:08:11.723668Z"
    }
   },
   "id": "985c0b1799e68dbc",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T18:08:14.359992Z",
     "start_time": "2024-01-28T18:08:14.321386Z"
    }
   },
   "id": "8a4919dcb33ec0f6",
   "execution_count": 117
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# Here, you want to find the best classifier. As candidates, consider\n",
    "#   1. LogisticRegression\n",
    "#   2. RandomForestClassifier\n",
    "#   3. other algorithms from sklearn (easy to add)\n",
    "#   4. custom algorithms (more difficult to implement)\n",
    "# \n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.ensemble import RandomForestClassifier\n",
    "# from sklearn.ensemble import GradientBoostingClassifier\n",
    "# \n",
    "# from sklearn.pipeline import Pipeline\n",
    "# from sklearn.model_selection import GridSearchCV\n",
    "# \n",
    "# model_logistic_regression = LogisticRegression(max_iter=30)\n",
    "# model_random_forest = RandomForestClassifier()\n",
    "# model_gradient_boosting = GradientBoostingClassifier()\n",
    "# \n",
    "# # train the models\n",
    "# pipeline = Pipeline(steps=[(\"scaler\", transform_scaler),\n",
    "#                            (\"pca\", transform_pca),\n",
    "#                            (\"model\", None)])\n",
    "# \n",
    "# parameter_grid_preprocessing = {\n",
    "#     \"pca__n_components\" : [1, 2, 3, 4],\n",
    "# }\n",
    "# \n",
    "# parameter_grid_logistic_regression = {\n",
    "#     \"model\" : [model_logistic_regression],\n",
    "#     \"model__C\" : [0.1, 1, 10],  # inverse regularization strength\n",
    "# }\n",
    "# \n",
    "# parameter_grid_gradient_boosting = {\n",
    "#     \"model\" : [model_gradient_boosting],\n",
    "#     \"model__n_estimators\" : [10, 20, 30]\n",
    "# }\n",
    "# \n",
    "# parameter_grid_random_forest = {\n",
    "#     \"model\" : [model_random_forest],\n",
    "#     \"model__n_estimators\" : [10, 20, 50],  # number of max trees in the forest\n",
    "#     \"model__max_depth\" : [2, 3, 4],\n",
    "# }\n",
    "# \n",
    "# meta_parameter_grid = [parameter_grid_logistic_regression,\n",
    "#                        parameter_grid_random_forest,\n",
    "#                        parameter_grid_gradient_boosting]\n",
    "# \n",
    "# meta_parameter_grid = [{**parameter_grid_preprocessing, **model_grid}\n",
    "#                        for model_grid in meta_parameter_grid]\n",
    "# \n",
    "# search = GridSearchCV(pipeline,\n",
    "#                       meta_parameter_grid,\n",
    "#                       scoring=\"balanced_accuracy\",\n",
    "#                       n_jobs=2,\n",
    "#                       cv=5,  # number of folds for cross-validation \n",
    "#                       error_score=\"raise\"\n",
    "#                       )\n",
    "# \n",
    "# # here, the actual training and grid search happens\n",
    "# search.fit(X_train, y_train.values.ravel())\n",
    "# \n",
    "# print(\"best parameter:\", search.best_params_ ,\"(CV score=%0.3f)\" % search.best_score_)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c1ce30f036a7032",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'search' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[99], line 2\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# evaluate performance of model on test set\u001B[39;00m\n\u001B[0;32m----> 2\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mScore on test set:\u001B[39m\u001B[38;5;124m\"\u001B[39m, \u001B[43msearch\u001B[49m\u001B[38;5;241m.\u001B[39mscore(X_test, y_test\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel()))\n\u001B[1;32m      4\u001B[0m \u001B[38;5;66;03m# contingency table\u001B[39;00m\n\u001B[1;32m      5\u001B[0m ct \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mcrosstab(search\u001B[38;5;241m.\u001B[39mbest_estimator_\u001B[38;5;241m.\u001B[39mpredict(X_test), y_test\u001B[38;5;241m.\u001B[39mvalues\u001B[38;5;241m.\u001B[39mravel(),\n\u001B[1;32m      6\u001B[0m                  rownames\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mpred\u001B[39m\u001B[38;5;124m\"\u001B[39m], colnames\u001B[38;5;241m=\u001B[39m[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mtrue\u001B[39m\u001B[38;5;124m\"\u001B[39m])\n",
      "\u001B[0;31mNameError\u001B[0m: name 'search' is not defined"
     ]
    }
   ],
   "source": [
    "# # evaluate performance of model on test set\n",
    "# print(\"Score on test set:\", search.score(X_test, y_test.values.ravel()))\n",
    "# \n",
    "# # contingency table\n",
    "# ct = pd.crosstab(search.best_estimator_.predict(X_test), y_test.values.ravel(),\n",
    "#                  rownames=[\"pred\"], colnames=[\"true\"])\n",
    "# print(ct)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T17:47:25.208003Z",
     "start_time": "2024-01-28T17:47:24.462406Z"
    }
   },
   "id": "67e6db7e13182404",
   "execution_count": 99
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# (optional, if you're curious) \n",
    "# for a detailed look on the performance of the different models\n",
    "# def get_search_score_overview():\n",
    "#     for c,s in zip(search.cv_results_[\"params\"],search.cv_results_[\"mean_test_score\"]):\n",
    "#         print(c, s)\n",
    "# \n",
    "# print(get_search_score_overview())"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.536112Z"
    }
   },
   "id": "3b0fd1a06c3bcd50",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# assume random forest model\n",
    "# model = RandomForestClassifier(n_estimators=10, random_state=seed)\n",
    "# model.fit(X_train, y_train.values.ravel())\n",
    "# \n",
    "# # compute shapley values\n",
    "# explainer = shap.TreeExplainer(model)\n",
    "# shap_values = explainer.shap_values(X_train)\n",
    "# shap_interaction_values = explainer.shap_interaction_values(X_train)\n",
    "# \n",
    "# expected_value = explainer.expected_value\n",
    "# print(expected_value)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.540353Z"
    }
   },
   "id": "b2499fa8ed64b814"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # class dependent plots of shapley values for each feature\n",
    "# for i,c in enumerate(final_data.variety.unique()):\n",
    "#     shap.summary_plot(shap_values[i], X_train, show=False)\n",
    "#     plt.title(\"Shapley values for \"+str(c))\n",
    "#     plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.544734Z"
    }
   },
   "id": "a7b6fb6b97e97e7d"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# def micro_service_classify_iris(datapoint):\n",
    "# \n",
    "#     # make sure the provided datapoints adhere to the correct format for model input\n",
    "# \n",
    "#     # fetch your trained model\n",
    "#     model = search.best_estimator_\n",
    "# \n",
    "#     # make prediction with the model\n",
    "#     prediction = model.predict(datapoint)\n",
    "# \n",
    "#     return prediction\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.549589Z"
    }
   },
   "id": "e01de7a0365c5936"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # hypothetical new batch of flowers arrives\n",
    "# from scipy.stats import norm\n",
    "# \n",
    "# amount_of_new_flowers = 9\n",
    "# df_flowers = pd.DataFrame(columns=df.columns.drop(\"variety\"), index=range(1, amount_of_new_flowers+1))\n",
    "# \n",
    "# for i in df_flowers.index:\n",
    "#     df_flowers.loc[i, \"sepal.length\"] = norm(loc=6, scale=2).rvs()\n",
    "#     df_flowers.loc[i, \"sepal.width\"] = norm(loc=3, scale=1).rvs()\n",
    "#     df_flowers.loc[i, \"petal.length\"] = norm(loc=3, scale=5).rvs()\n",
    "#     df_flowers.loc[i, \"petal.width\"] = norm(loc=2, scale=2).rvs()\n",
    "# \n",
    "# # customer uses your micro service to determine the varieties\n",
    "# df_flowers[\"variety\"] = micro_service_classify_iris(df_flowers)\n",
    "# print(df_flowers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.556792Z"
    }
   },
   "id": "d49897f0c5228c92"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "51dcaf840e3524c0"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Let's assume that our id column is the index of the dataframe\n",
    "# output = pd.DataFrame(df_flowers.variety)\n",
    "# output['id'] = df_flowers.index\n",
    "# output = output.rename(columns={'variety': 'prediction'})\n",
    "# output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "# output.to_csv('iris_prediction.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.560239Z"
    }
   },
   "id": "88d780bd7eed1f88"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 25756 entries, 0 to 25755\n",
      "Data columns (total 30 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   AuthorId                    25756 non-null  object  \n",
      " 1   Diet                        25756 non-null  category\n",
      " 2   Age                         25756 non-null  int64   \n",
      " 3   RecipeId                    25756 non-null  int64   \n",
      " 4   Rating                      25756 non-null  float64 \n",
      " 5   Like                        25756 non-null  object  \n",
      " 6   TestSetId                   0 non-null      float64 \n",
      " 7   Time                        25756 non-null  float64 \n",
      " 8   HighCalories                25756 non-null  float64 \n",
      " 9   HighProtein                 25756 non-null  object  \n",
      " 10  LowFat                      25756 non-null  int64   \n",
      " 11  LowSugar                    25756 non-null  object  \n",
      " 12  HighFiber                   25756 non-null  int64   \n",
      " 13  RecipeName                  25756 non-null  object  \n",
      " 14  CookTime                    25756 non-null  int64   \n",
      " 15  PrepTime                    25756 non-null  int64   \n",
      " 16  RecipeCategory              25756 non-null  object  \n",
      " 17  RecipeIngredientQuantities  25756 non-null  object  \n",
      " 18  RecipeIngredientParts       25756 non-null  object  \n",
      " 19  Calories                    25756 non-null  float64 \n",
      " 20  FatContent                  25756 non-null  int64   \n",
      " 21  SaturatedFatContent         25756 non-null  float64 \n",
      " 22  CholesterolContent          25756 non-null  float64 \n",
      " 23  SodiumContent               25756 non-null  float64 \n",
      " 24  CarbohydrateContent         25756 non-null  float64 \n",
      " 25  FiberContent                25756 non-null  float64 \n",
      " 26  SugarContent                25756 non-null  float64 \n",
      " 27  ProteinContent              25756 non-null  float64 \n",
      " 28  RecipeServings              16016 non-null  float64 \n",
      " 29  RecipeYield                 8904 non-null   object  \n",
      "dtypes: category(1), float64(13), int64(7), object(9)\n",
      "memory usage: 5.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T19:51:38.550217Z",
     "start_time": "2024-01-28T19:51:38.433879Z"
    }
   },
   "id": "146a249323574db9",
   "execution_count": 99
  },
  {
   "cell_type": "markdown",
   "source": [
    "OUR CODE "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c7912e964783fd6"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce7e4e8ea2cdbc87"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.9982\n",
      "Balanced Accuracy on Testing Set: 0.7091\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,  # You can adjust this\n",
    "    random_state=42,\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,  # You can adjust this\n",
    "    max_features='log2'\n",
    ")\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:33:06.401924Z",
     "start_time": "2024-01-28T20:33:00.346523Z"
    }
   },
   "id": "1bcaf8cb7721628b",
   "execution_count": 120
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.9982\n",
      "Precision on Training Set: 0.9980\n",
      "Recall on Training Set: 0.9983\n",
      "F1 Score on Training Set: 0.9982\n",
      "Confusion Matrix on Training Set:\n",
      "[[10298    21]\n",
      " [   17 10268]]\n",
      "Balanced Accuracy on Testing Set: 0.7098\n",
      "Precision on Testing Set: 0.7115\n",
      "Recall on Testing Set: 0.7123\n",
      "F1 Score on Testing Set: 0.7119\n",
      "Confusion Matrix on Testing Set:\n",
      "[[1810  749]\n",
      " [ 746 1847]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Print metrics for the training set\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "print(f\"Precision on Training Set: {precision_train:.4f}\")\n",
    "print(f\"Recall on Training Set: {recall_train:.4f}\")\n",
    "print(f\"F1 Score on Training Set: {f1_train:.4f}\")\n",
    "print(f\"Confusion Matrix on Training Set:\\n{conf_matrix_train}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics for the testing set\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n",
    "print(f\"Precision on Testing Set: {precision_test:.4f}\")\n",
    "print(f\"Recall on Testing Set: {recall_test:.4f}\")\n",
    "print(f\"F1 Score on Testing Set: {f1_test:.4f}\")\n",
    "print(f\"Confusion Matrix on Testing Set:\\n{conf_matrix_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T19:57:39.229839Z",
     "start_time": "2024-01-28T19:57:38.850995Z"
    }
   },
   "id": "2a8408aba0fa2e44",
   "execution_count": 101
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.6850\n",
      "Balanced Accuracy on Testing Set: 0.6697\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for the training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "# Increase max_iter and use the 'lbfgs' solver\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    solver='lbfgs',  # You can adjust this\n",
    "    max_iter=1000,    # You can adjust this\n",
    "    C=1.0,            # You can adjust this\n",
    "    penalty='l2',     # You can adjust this\n",
    "    class_weight=None  # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the scaled training set\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the scaled training set\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the scaled testing set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:20:14.231877Z",
     "start_time": "2024-01-28T20:20:13.187753Z"
    }
   },
   "id": "313e8a6d2454e723",
   "execution_count": 114
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.7381\n",
      "Balanced Accuracy on Testing Set: 0.7105\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Neural Network model\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # You can adjust this\n",
    "    max_iter=500,                 # You can adjust this\n",
    "    random_state=42,\n",
    "    activation='relu',           # You can adjust this\n",
    "    alpha=0.0001,                 # You can adjust this\n",
    "    solver='adam',               # You can adjust this\n",
    "    learning_rate='constant'      # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the scaled training set\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the scaled training set\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the scaled testing set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:22:20.244810Z",
     "start_time": "2024-01-28T20:21:56.862366Z"
    }
   },
   "id": "ae54540e1d2a8e21",
   "execution_count": 115
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.7392\n",
      "Balanced Accuracy on Testing Set: 0.7123\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "model = GradientBoostingClassifier(\n",
    "    n_estimators=100,     # You can adjust this\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,    # You can adjust this\n",
    "    max_depth=3,          # You can adjust this\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,   # You can adjust this\n",
    "    subsample=1.0         # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:23:14.578468Z",
     "start_time": "2024-01-28T20:23:06.313534Z"
    }
   },
   "id": "fda34e9945aded03",
   "execution_count": 116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[118], line 42\u001B[0m\n\u001B[1;32m     39\u001B[0m model\u001B[38;5;241m.\u001B[39mfit(X_train, y_train)\n\u001B[1;32m     41\u001B[0m \u001B[38;5;66;03m# Evaluate the model on the training set\u001B[39;00m\n\u001B[0;32m---> 42\u001B[0m y_train_pred \u001B[38;5;241m=\u001B[39m model\u001B[38;5;241m.\u001B[39mpredict(X_train)\n\u001B[1;32m     44\u001B[0m \u001B[38;5;66;03m# Compute balanced accuracy for the training set\u001B[39;00m\n\u001B[1;32m     45\u001B[0m balanced_accuracy_train \u001B[38;5;241m=\u001B[39m balanced_accuracy_score(y_train, y_train_pred)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:818\u001B[0m, in \u001B[0;36mBaseSVC.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    816\u001B[0m     y \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39margmax(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdecision_function(X), axis\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m)\n\u001B[1;32m    817\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 818\u001B[0m     y \u001B[38;5;241m=\u001B[39m \u001B[38;5;28msuper\u001B[39m()\u001B[38;5;241m.\u001B[39mpredict(X)\n\u001B[1;32m    819\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mclasses_\u001B[38;5;241m.\u001B[39mtake(np\u001B[38;5;241m.\u001B[39masarray(y, dtype\u001B[38;5;241m=\u001B[39mnp\u001B[38;5;241m.\u001B[39mintp))\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:433\u001B[0m, in \u001B[0;36mBaseLibSVM.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    431\u001B[0m X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_validate_for_predict(X)\n\u001B[1;32m    432\u001B[0m predict \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse_predict \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sparse \u001B[38;5;28;01melse\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dense_predict\n\u001B[0;32m--> 433\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m predict(X)\n",
      "File \u001B[0;32m~/anaconda3/lib/python3.11/site-packages/sklearn/svm/_base.py:452\u001B[0m, in \u001B[0;36mBaseLibSVM._dense_predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m    444\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    445\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mX.shape[1] = \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m should be equal to \u001B[39m\u001B[38;5;132;01m%d\u001B[39;00m\u001B[38;5;124m, \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    446\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mthe number of samples at training time\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    447\u001B[0m             \u001B[38;5;241m%\u001B[39m (X\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m], \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mshape_fit_[\u001B[38;5;241m0\u001B[39m])\n\u001B[1;32m    448\u001B[0m         )\n\u001B[1;32m    450\u001B[0m svm_type \u001B[38;5;241m=\u001B[39m LIBSVM_IMPL\u001B[38;5;241m.\u001B[39mindex(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_impl)\n\u001B[0;32m--> 452\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m libsvm\u001B[38;5;241m.\u001B[39mpredict(\n\u001B[1;32m    453\u001B[0m     X,\n\u001B[1;32m    454\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_,\n\u001B[1;32m    455\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39msupport_vectors_,\n\u001B[1;32m    456\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_n_support,\n\u001B[1;32m    457\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dual_coef_,\n\u001B[1;32m    458\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_intercept_,\n\u001B[1;32m    459\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probA,\n\u001B[1;32m    460\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_probB,\n\u001B[1;32m    461\u001B[0m     svm_type\u001B[38;5;241m=\u001B[39msvm_type,\n\u001B[1;32m    462\u001B[0m     kernel\u001B[38;5;241m=\u001B[39mkernel,\n\u001B[1;32m    463\u001B[0m     degree\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdegree,\n\u001B[1;32m    464\u001B[0m     coef0\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcoef0,\n\u001B[1;32m    465\u001B[0m     gamma\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_gamma,\n\u001B[1;32m    466\u001B[0m     cache_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mcache_size,\n\u001B[1;32m    467\u001B[0m )\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Support Vector Machine (SVM) model with adjusted parameters\n",
    "model = SVC(\n",
    "    C=1.0,            # You can adjust this\n",
    "    kernel='rbf',     # You can adjust this\n",
    "    degree=3,         # You can adjust this\n",
    "    gamma='scale',    # You can adjust this\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:28:34.777364Z",
     "start_time": "2024-01-28T20:25:45.464513Z"
    }
   },
   "id": "725470cb7bf23045",
   "execution_count": 118
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.9329\n",
      "Balanced Accuracy on Testing Set: 0.6737\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the individual models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "svm_model = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', random_state=42)\n",
    "\n",
    "# Initialize the StackingClassifier with the individual models\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('svm', svm_model)],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit the StackingClassifier on the training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the StackingClassifier on the training set\n",
    "y_train_pred = stacking_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the StackingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:51:59.695001Z",
     "start_time": "2024-01-28T20:49:33.438234Z"
    }
   },
   "id": "eee92a49cb6e25a2",
   "execution_count": 128
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.7866\n",
      "Balanced Accuracy on Testing Set: 0.6787\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the individual models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# Initialize the StackingClassifier with the individual models\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('gb', gb_model)],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit the StackingClassifier on the training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the StackingClassifier on the training set\n",
    "y_train_pred = stacking_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the StackingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:30:03.082106Z",
     "start_time": "2024-01-28T20:28:59.503475Z"
    }
   },
   "id": "8a6cec64bbe63bfb",
   "execution_count": 119
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.7876\n",
      "Precision on Training Set: 0.7664\n",
      "Recall on Training Set: 0.8263\n",
      "F1 Score on Training Set: 0.7952\n",
      "Confusion Matrix on Training Set:\n",
      "[[7728 2591]\n",
      " [1786 8499]]\n",
      "Balanced Accuracy on Testing Set: 0.7119\n",
      "Precision on Testing Set: 0.7026\n",
      "Recall on Testing Set: 0.7424\n",
      "F1 Score on Testing Set: 0.7219\n",
      "Confusion Matrix on Testing Set:\n",
      "[[1744  815]\n",
      " [ 668 1925]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Random Forest model with hyperparameter tuning\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=150,\n",
    "    random_state=42,\n",
    "    max_depth=10,  # Limiting the depth of the tree to make the model simpler\n",
    "    min_samples_split=5,  # Minimum number of samples required to split an internal node\n",
    "    min_samples_leaf=4,  # Minimum number of samples required to be at a leaf node\n",
    "    max_features='sqrt'  # Number of features to consider when looking for the best split\n",
    ")\n",
    "\n",
    "# Optional: Implement GridSearchCV for further hyperparameter tuning\n",
    "# parameter_grid = {\n",
    "#     'n_estimators': [100, 200],\n",
    "#     'max_depth': [10, 20, None],\n",
    "#     'min_samples_split': [2, 5, 10],\n",
    "#     'min_samples_leaf': [1, 2, 4],\n",
    "#     'max_features': ['sqrt', 'log2']\n",
    "# }\n",
    "# grid_search = GridSearchCV(model, parameter_grid, cv=5, scoring='balanced_accuracy', n_jobs=-1)\n",
    "# grid_search.fit(X_train, y_train)\n",
    "# model = grid_search.best_estimator_\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute metrics for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Print metrics for the training set\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "print(f\"Precision on Training Set: {precision_train:.4f}\")\n",
    "print(f\"Recall on Training Set: {recall_train:.4f}\")\n",
    "print(f\"F1 Score on Training Set: {f1_train:.4f}\")\n",
    "print(f\"Confusion Matrix on Training Set:\\n{conf_matrix_train}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics for the testing set\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n",
    "print(f\"Precision on Testing Set: {precision_test:.4f}\")\n",
    "print(f\"Recall on Testing Set: {recall_test:.4f}\")\n",
    "print(f\"F1 Score on Testing Set: {f1_test:.4f}\")\n",
    "print(f\"Confusion Matrix on Testing Set:\\n{conf_matrix_test}\")\n",
    "\n",
    "# Optional: Print best parameters found by GridSearchCV\n",
    "# print(\"Best parameters found by GridSearchCV:\")\n",
    "# print(grid_search.best_params_)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-28T20:38:49.928072Z",
     "start_time": "2024-01-28T20:38:43.122428Z"
    }
   },
   "id": "ffbb5d82bd3429bc",
   "execution_count": 124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the base model (Random Forest)\n",
    "base_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,     # You can adjust this\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,    # You can adjust this\n",
    "    max_depth=3,          # You can adjust this\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,   # You can adjust this\n",
    "    subsample=1.0         # You can adjust this\n",
    ")\n",
    "\n",
    "# Initialize the BaggingClassifier\n",
    "bagging_model = BaggingClassifier(\n",
    "    base_model,\n",
    "    n_estimators=50,  # You can adjust this\n",
    "    max_samples=1.0,  # You can adjust this\n",
    "    max_features=1.0,  # You can adjust this\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the BaggingClassifier on the training set\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the BaggingClassifier on the training set\n",
    "y_train_pred = bagging_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Evaluate the BaggingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "is_executing": true,
    "ExecuteTime": {
     "start_time": "2024-01-28T21:00:58.592431Z"
    }
   },
   "id": "640a3035a0fc3dc5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "b67f1f474def6986"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from xgboost import XGBClassifier\n",
    "# from sklearn.metrics import balanced_accuracy_score\n",
    "# \n",
    "# # Load your data\n",
    "# df = pd.read_csv('final_data.csv')\n",
    "# \n",
    "# # Define features (X) and target variable (y)\n",
    "# features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar',\n",
    "#             'HighFiber', 'CookTime', 'PrepTime', 'RecipeCategory']\n",
    "# target = 'Like'\n",
    "# \n",
    "# # Drop rows with NaN values in the target column ('Like') for training set\n",
    "# train_data = df.dropna(subset=[target]).copy()  # Create a copy to avoid the warning\n",
    "# \n",
    "# # Use bootstrapping to split the training data\n",
    "# # Assuming 'Like' column is boolean (True/False)\n",
    "# train_data['Like'] = train_data['Like'].astype(bool)\n",
    "# \n",
    "# # Split the data into features (X) and target variable (y) for training set\n",
    "# X_train = pd.get_dummies(train_data[features])\n",
    "# y_train = train_data['Like']\n",
    "# \n",
    "# # Use bootstrapping to create a balanced sample\n",
    "# # This is just an example, you may want to adjust the sample size based on your needs\n",
    "# positive_samples = train_data[train_data['Like'] == True]\n",
    "# negative_samples = train_data[train_data['Like'] == False]\n",
    "# num_samples = min(len(positive_samples), len(negative_samples))\n",
    "# balanced_sample = pd.concat([positive_samples.sample(num_samples), negative_samples.sample(num_samples)])\n",
    "# \n",
    "# # Split the balanced sample into features (X) and target variable (y) for training set\n",
    "# X_balanced = pd.get_dummies(balanced_sample[features])\n",
    "# y_balanced = balanced_sample['Like']\n",
    "# \n",
    "# # Initialize the XGBoost model\n",
    "# model = XGBClassifier()\n",
    "# \n",
    "# # Fit the model on the balanced sample\n",
    "# model.fit(X_balanced, y_balanced)\n",
    "# \n",
    "# # Predictions on the original training set\n",
    "# y_train_pred = model.predict(X_train)\n",
    "# \n",
    "# # Compute balanced accuracy for the training set\n",
    "# balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "# \n",
    "# print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.590584Z"
    }
   },
   "id": "dffeb3526e2b1c2c",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Assuming you have already trained the model and made predictions on the test set\n",
    "# # (Make sure that the 'Like' column in the test set is still NaN)\n",
    "# \n",
    "# # Predict the 'Like' column for the testing set\n",
    "# X_test = pd.get_dummies(df[df[target].isnull()][features])\n",
    "# # Predict the 'Like' column for the testing set\n",
    "# predictions = model.predict(X_test)\n",
    "# \n",
    "# # Filter out rows where the true labels are known (not NaN)\n",
    "# known_labels_mask = ~df[target].isnull()\n",
    "# \n",
    "# # Filter out the true labels for known labels\n",
    "# true_labels = df.loc[known_labels_mask, target]\n",
    "# print(true_labels)\n",
    "# # Convert true_labels to boolean (if not already)\n",
    "# true_labels = true_labels.astype(bool)\n",
    "# \n",
    "# # Filter out NaN values from the predictions\n",
    "# predictions = predictions[:len(true_labels)]  # Ensure predictions and true_labels have the same length\n",
    "# print(predictions)\n",
    "# # Compute balanced accuracy for the testing set\n",
    "# balanced_accuracy_test = balanced_accuracy_score(true_labels, predictions)\n",
    "# \n",
    "# print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.593159Z"
    }
   },
   "id": "4190596fd6960feb",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sklearn.model_selection import train_test_split\n",
    "# from sklearn.linear_model import LogisticRegression\n",
    "# from sklearn.metrics import balanced_accuracy_score\n",
    "# \n",
    "# # Load your data\n",
    "# df = pd.read_csv('final_data.csv')\n",
    "# \n",
    "# # Define features (X) and target variable (y)\n",
    "# features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar',\n",
    "#             'HighFiber', 'CookTime', 'PrepTime', 'RecipeCategory']\n",
    "# target = 'Like'\n",
    "# \n",
    "# # Drop rows with NaN values in the target column ('Like') for training set\n",
    "# train_data = df.dropna(subset=[target]).copy()  # Create a copy to avoid the warning\n",
    "# # Convert 'Like' column to boolean (if not already)\n",
    "# train_data['Like'] = train_data['Like'].astype(bool)\n",
    "# \n",
    "# # Split the data into features (X) and target variable (y) for training set\n",
    "# X_train = pd.get_dummies(train_data[features])\n",
    "# y_train = train_data['Like']\n",
    "# \n",
    "# # Use bootstrapping to create a balanced sample\n",
    "# # This is just an example, you may want to adjust the sample size based on your needs\n",
    "# positive_samples = train_data[train_data['Like'] == True]\n",
    "# negative_samples = train_data[train_data['Like'] == False]\n",
    "# num_samples = min(len(positive_samples), len(negative_samples))\n",
    "# balanced_sample = pd.concat([positive_samples.sample(num_samples), negative_samples.sample(num_samples)])\n",
    "# \n",
    "# # Split the balanced sample into features (X) and target variable (y) for training set\n",
    "# X_balanced = pd.get_dummies(balanced_sample[features])\n",
    "# y_balanced = balanced_sample['Like']\n",
    "# \n",
    "# # Initialize the Logistic Regression model\n",
    "# model = LogisticRegression()\n",
    "# \n",
    "# # Fit the model on the balanced sample\n",
    "# model.fit(X_balanced, y_balanced)\n",
    "# \n",
    "# # Predictions on the original training set\n",
    "# y_train_pred = model.predict(X_train)\n",
    "# \n",
    "# # Compute balanced accuracy for the training set\n",
    "# balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "# print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.595772Z"
    }
   },
   "id": "432ffe4253a5f9a6",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-28T17:47:24.598069Z"
    }
   },
   "id": "538ab0631b643977",
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
