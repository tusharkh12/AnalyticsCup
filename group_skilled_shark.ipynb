{
 "cells": [
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Note: The following do not work with Python 3.12\n",
    "import shap\n",
    "# from ydata_profiling import ProfileReport\n",
    "import sweetviz as sv"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.447022Z",
     "start_time": "2024-01-29T03:21:58.789554Z"
    }
   },
   "id": "initial_id",
   "execution_count": 1102
  },
  {
   "cell_type": "markdown",
   "source": [
    "Reproducibility:"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4e58ef72dfbe19d"
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "outputs": [],
   "source": [
    "seed = 2024\n",
    "\n",
    "# pandas, statsmodels, matplotlib and y_data_profiling rely on numpy's random generator, and thus, we need to set the seed in numpy\n",
    "np.random.seed(seed)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.534920Z",
     "start_time": "2024-01-29T03:21:59.448486Z"
    }
   },
   "id": "1046a21be556037"
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "outputs": [
    {
     "data": {
      "text/plain": "         AuthorId        Diet  Age\n0       10000120E  Vegetarian   46\n1        1000014D       Vegan   18\n2        1000015A  Vegetarian   58\n3        1000016E  Vegetarian   32\n4        1000027E       Vegan   61\n...           ...         ...  ...\n271902    999917E  Vegetarian   28\n271903    999936C    Omnivore   22\n271904     99993D  Vegetarian   58\n271905     99994A  Vegetarian   18\n271906    999991A  Vegetarian   21\n\n[271907 rows x 3 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>10000120E</td>\n      <td>Vegetarian</td>\n      <td>46</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000014D</td>\n      <td>Vegan</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000015A</td>\n      <td>Vegetarian</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000016E</td>\n      <td>Vegetarian</td>\n      <td>32</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000027E</td>\n      <td>Vegan</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>271902</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n    </tr>\n    <tr>\n      <th>271903</th>\n      <td>999936C</td>\n      <td>Omnivore</td>\n      <td>22</td>\n    </tr>\n    <tr>\n      <th>271904</th>\n      <td>99993D</td>\n      <td>Vegetarian</td>\n      <td>58</td>\n    </tr>\n    <tr>\n      <th>271905</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n    </tr>\n    <tr>\n      <th>271906</th>\n      <td>999991A</td>\n      <td>Vegetarian</td>\n      <td>21</td>\n    </tr>\n  </tbody>\n</table>\n<p>271907 rows × 3 columns</p>\n</div>"
     },
     "execution_count": 1104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "diet = pd.read_csv('diet.csv', low_memory=False)\n",
    "diet['Diet'] = diet['Diet'].astype('category')\n",
    "diet"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.819155Z",
     "start_time": "2024-01-29T03:21:59.524062Z"
    }
   },
   "id": "945414f010f9c610"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Understanding"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "10e110bb2f216c3f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# user_count= diet['AuthorId']\n",
    "# print(f'The number of author ids is: {user_count.size}')\n",
    "# print(f'The number of unique author ids is: {user_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.822303Z",
     "start_time": "2024-01-29T03:21:59.742471Z"
    }
   },
   "id": "94617de5539d6697",
   "execution_count": 1105
  },
  {
   "cell_type": "markdown",
   "source": [
    "Different Graphs of Diet.csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18fb5bbc6a2f6bf2"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Histogram of Ages\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# plt.hist(diet['Age'], bins=20, color='skyblue', edgecolor='black')\n",
    "# plt.title('Distribution of Ages')\n",
    "# plt.xlabel('Age')\n",
    "# plt.ylabel('Frequency')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.832980Z",
     "start_time": "2024-01-29T03:21:59.746400Z"
    }
   },
   "id": "1f921f7de9376fa6",
   "execution_count": 1106
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Box Plot of Ages by Diet: Explore relationships between numerical variables (Age) using a pair plot.\n",
    "# plt.figure(figsize=(12, 8))\n",
    "# sns.boxplot(x='Diet', y='Age', data=diet, palette='pastel')\n",
    "# plt.title('Box Plot of Ages by Diet')\n",
    "# plt.xlabel('Diet')\n",
    "# plt.ylabel('Age')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.836951Z",
     "start_time": "2024-01-29T03:21:59.751640Z"
    }
   },
   "id": "996d3a7dd0ba77e7",
   "execution_count": 1107
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# #Count Plot of Diets: Show the count of each diet category using a count plot.\n",
    "# plt.figure(figsize=(10, 6))\n",
    "# sns.countplot(x='Diet', data=diet, palette='viridis')\n",
    "# plt.title('Count of Diets')\n",
    "# plt.xlabel('Diet')\n",
    "# plt.ylabel('Count')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:21:59.875583Z",
     "start_time": "2024-01-29T03:21:59.799329Z"
    }
   },
   "id": "61aafe5aac5297f0",
   "execution_count": 1108
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId          Time  HighCalories  HighProtein  \\\n0       2001012259B     73440   1799.950949           0.0  Indifferent   \n1           437641B    365718   4201.820980           0.0          Yes   \n2       1803340263D    141757   6299.861496           0.0  Indifferent   \n3           854048B    280351  19801.365796           0.0          Yes   \n4          2277685E    180505   5400.093457           0.0  Indifferent   \n...             ...       ...           ...           ...          ...   \n140190      163793B     78171   1560.649725           0.0  Indifferent   \n140191       33888B    333262   1502.011466           1.0  Indifferent   \n140192      401942C     49200   5999.274269           0.0  Indifferent   \n140193      346866B    214815    899.523513           0.0          Yes   \n140194     1786859E    117923   7199.637837           1.0  Indifferent   \n\n        LowFat     LowSugar  HighFiber  \n0            0            0          0  \n1            0  Indifferent          1  \n2            1  Indifferent          0  \n3            1            0          1  \n4            0            0          0  \n...        ...          ...        ...  \n140190       0            0          1  \n140191       1            0          0  \n140192       0            0          1  \n140193       1  Indifferent          1  \n140194       0            0          1  \n\n[140195 rows x 8 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001012259B</td>\n      <td>73440</td>\n      <td>1799.950949</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>437641B</td>\n      <td>365718</td>\n      <td>4201.820980</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1803340263D</td>\n      <td>141757</td>\n      <td>6299.861496</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>854048B</td>\n      <td>280351</td>\n      <td>19801.365796</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2277685E</td>\n      <td>180505</td>\n      <td>5400.093457</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>163793B</td>\n      <td>78171</td>\n      <td>1560.649725</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>33888B</td>\n      <td>333262</td>\n      <td>1502.011466</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>401942C</td>\n      <td>49200</td>\n      <td>5999.274269</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>346866B</td>\n      <td>214815</td>\n      <td>899.523513</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>1786859E</td>\n      <td>117923</td>\n      <td>7199.637837</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 8 columns</p>\n</div>"
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "requests = pd.read_csv('requests.csv', low_memory=False)\n",
    "requests['HighProtein'] = requests['HighProtein'].astype('category')\n",
    "requests['LowSugar'] = requests['LowSugar'].astype('category')\n",
    "requests"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.122682Z",
     "start_time": "2024-01-29T03:21:59.799567Z"
    }
   },
   "id": "fc76e88ae8ccd753",
   "execution_count": 1109
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "outputs": [],
   "source": [
    "user_count= requests['AuthorId']\n",
    "print(\"Author Id \")\n",
    "print(f'The number of author ids is: {user_count.size}')\n",
    "print(f'The number of unique author ids is: {user_count.unique().size}')\n",
    "print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "recipe_count= requests['RecipeId']\n",
    "print(\"Recipe Id \")\n",
    "print(f'The number of recipe ids is: {recipe_count.size}')\n",
    "print(f'The number of unique recipe ids is: {recipe_count.unique().size}')\n",
    "print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.143675Z",
     "start_time": "2024-01-29T03:21:59.980550Z"
    }
   },
   "id": "5c77ab769db421af"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Correlation Heatmap: Visualize the correlation between numerical variables.\n",
    "# Exclude non-numeric columns\n",
    "numeric_columns = requests[['Time', 'HighCalories', 'LowFat', 'HighFiber']]\n",
    "correlation_matrix = numeric_columns.corr()\n",
    "\n",
    "# Plot the heatmap\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Heatmap for Request Variables')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.147445Z",
     "start_time": "2024-01-29T03:21:59.984534Z"
    }
   },
   "id": "4d0d1773c42484e",
   "execution_count": 1111
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Bar Plot of HighProtein Requests: Visualize the count of HighProtein requests.\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='HighProtein', data=requests, palette='Set2')\n",
    "plt.title('Count of HighProtein Requests')\n",
    "plt.xlabel('HighProtein')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.219758Z",
     "start_time": "2024-01-29T03:22:00.125582Z"
    }
   },
   "id": "9ebc67dff1ce7cca",
   "execution_count": 1112
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Bar Plot of LowSugar Requests: Visualize the count of LowSugar requests.\n",
    "plt.figure(figsize=(8, 5))\n",
    "sns.countplot(x='LowSugar', data=requests, palette='pastel')\n",
    "plt.title('Count of LowSugar Requests')\n",
    "plt.xlabel('LowSugar')\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.278366Z",
     "start_time": "2024-01-29T03:22:00.196854Z"
    }
   },
   "id": "cf37bff55cb522ff",
   "execution_count": 1113
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating   Like  TestSetId\n0          2492191A     33671     2.0    NaN        1.0\n1       2002019979A     92647     2.0    NaN        2.0\n2           408594E    161770     NaN    NaN        3.0\n3       2001625557E    108231     2.0    NaN        4.0\n4       2001427116E     71109     NaN    NaN        5.0\n...             ...       ...     ...    ...        ...\n140190      999595E    338070     2.0  False        NaN\n140191      999774A     29002     2.0  False        NaN\n140192      999774A    159252     NaN  False        NaN\n140193      999774A      1171     2.0   True        NaN\n140194      999917E    169413     2.0  False        NaN\n\n[140195 rows x 5 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2492191A</td>\n      <td>33671</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2002019979A</td>\n      <td>92647</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408594E</td>\n      <td>161770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001625557E</td>\n      <td>108231</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001427116E</td>\n      <td>71109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 5 columns</p>\n</div>"
     },
     "execution_count": 1114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv('reviews.csv', low_memory=False)\n",
    "reviews"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.399452Z",
     "start_time": "2024-01-29T03:22:00.279577Z"
    }
   },
   "id": "bec20eb4f25cd1d0",
   "execution_count": 1114
  },
  {
   "cell_type": "code",
   "execution_count": 1115,
   "outputs": [],
   "source": [
    "user1_count= reviews['AuthorId']\n",
    "print(\"Author Id \")\n",
    "print(f'The number of author ids is: {user1_count.size}')\n",
    "print(f'The number of unique author ids is: {user1_count.unique().size}')\n",
    "print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "recipe1_count= reviews['RecipeId']\n",
    "print(\"Recipe Id \")\n",
    "print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')\n",
    "print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.416006Z",
     "start_time": "2024-01-29T03:22:00.367055Z"
    }
   },
   "id": "5c37873ec50ba36f"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Scatter Plot of Rating vs Like:Investigate the relationship between ratings and likes using a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(reviews['Rating'], reviews['Like'], alpha=0.5, color='green')\n",
    "plt.title('Scatter Plot of Rating vs Like')\n",
    "plt.xlabel('Rating')\n",
    "plt.ylabel('Like')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:00.461332Z",
     "start_time": "2024-01-29T03:22:00.401494Z"
    }
   },
   "id": "f659099f3e911f4b",
   "execution_count": 1116
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "       RecipeId                                      RecipeName  CookTime  \\\n0         73440                    Bow Ties With Broccoli Pesto         0   \n1        365718                             Cashew-chutney Rice      3600   \n2        141757        Copycat Taco Bell Nacho Fries BellGrande      3600   \n3        280351        Slow Cooker Jalapeno Cheddar Cheese Soup     18000   \n4        180505                 Cool & Crisp Citrus Chiffon Pie      3600   \n...         ...                                             ...       ...   \n75599    253577  Frijoles Negros- Crock Pot Mexican Black Beans     43200   \n75600    267827                                  Moose Moussaka      3600   \n75601    266983        Cantonese Pepper Steak for Two (Or More)      1800   \n75602    253739                            Coconut Cream Cooler       300   \n75603     78171                                 Cheater Risotto       960   \n\n       PrepTime RecipeCategory  \\\n0          1800          Other   \n1           600          Other   \n2          2700          Other   \n3          1800          Other   \n4          1800          Other   \n...         ...            ...   \n75599     28800          Other   \n75600      2700          Other   \n75601       900          Other   \n75602       120          Other   \n75603       600          Other   \n\n                              RecipeIngredientQuantities  \\\n0      c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...   \n1      c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...   \n2      c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...   \n3      c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...   \n4      c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...   \n...                                                  ...   \n75599  c(\"\\\"2\\\"\", \"\\\"6 -8\\\"\", \"\\\"5\\\"\", \"\\\"1/2\\\"\", \"\\\"...   \n75600  c(\"\\\"1\\\"\", \"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1/2\\\"...   \n75601  c(\"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1/8\\\"\", \"\\\"1/8\\\"\", \"\\...   \n75602  c(\"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"7 1/2\\\"\", \"\\\"1...   \n75603  c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"4\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"...   \n\n                                   RecipeIngredientParts  Calories  \\\n0      c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...     241.3   \n1      c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...     370.8   \n2      c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...     377.6   \n3      c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...     282.8   \n4      c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...     257.5   \n...                                                  ...       ...   \n75599  c(\"\\\"black beans\\\"\", \"\\\"water\\\"\", \"\\\"bay leave...     121.5   \n75600  c(\"\\\"onion\\\"\", \"\\\"garlic cloves\\\"\", \"\\\"olive o...     652.2   \n75601  c(\"\\\"top round steak\\\"\", \"\\\"cornstarch\\\"\", \"\\\"...     223.9   \n75602             c(\"\\\"cream of coconut\\\"\", \"\\\"water\\\"\")    2229.8   \n75603  c(\"\\\"arborio rice\\\"\", \"\\\"white wine\\\"\", \"\\\"gar...     654.1   \n\n       FatContent  SaturatedFatContent  CholesterolContent  SodiumContent  \\\n0            10.1                  1.2                 0.0           13.1   \n1            17.5                  7.2                22.9          553.3   \n2            20.9                 10.5                45.7         1501.8   \n3            16.5                 10.3                50.5          630.2   \n4             8.6                  2.4               110.7          160.9   \n...           ...                  ...                 ...            ...   \n75599         0.5                  0.1                 0.0         1175.1   \n75600        25.8                 10.7               197.9          435.5   \n75601         9.2                  3.6                78.3          725.9   \n75602        80.3                 69.3                 0.0          294.7   \n75603        13.8                  6.9                34.6         1114.0   \n\n       CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n0                     31.8           2.3           1.4             6.7   \n1                     44.3           1.6           2.2             9.4   \n2                     36.6           3.8           6.1            12.9   \n3                     22.8           2.3           2.7            11.7   \n4                     39.8           0.4          30.2             6.3   \n...                    ...           ...           ...             ...   \n75599                 22.2           7.8           0.6             7.9   \n75600                 51.9           7.5           7.2            50.1   \n75601                  7.3           1.1           1.7            26.7   \n75602                369.0          15.7         317.9            26.7   \n75603                 92.2           3.9           4.2            21.8   \n\n       RecipeServings RecipeYield  \n0                 9.0         NaN  \n1                 8.0         NaN  \n2                 8.0         NaN  \n3                 6.0         NaN  \n4                 6.0         NaN  \n...               ...         ...  \n75599             NaN         NaN  \n75600             NaN         NaN  \n75601             2.0         NaN  \n75602             NaN    1 gallon  \n75603             NaN  2 1/2 cups  \n\n[75604 rows x 18 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>RecipeId</th>\n      <th>RecipeName</th>\n      <th>CookTime</th>\n      <th>PrepTime</th>\n      <th>RecipeCategory</th>\n      <th>RecipeIngredientQuantities</th>\n      <th>RecipeIngredientParts</th>\n      <th>Calories</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>73440</td>\n      <td>Bow Ties With Broccoli Pesto</td>\n      <td>0</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"1 1/2\\\"\", \"\\\"1/4\\\"\", \"\\...</td>\n      <td>c(\"\\\"hazelnuts\\\"\", \"\\\"broccoli florets\\\"\", \"\\\"...</td>\n      <td>241.3</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>365718</td>\n      <td>Cashew-chutney Rice</td>\n      <td>3600</td>\n      <td>600</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"6\\\"\", \"\\\"5\\\"\", \"\\\"2\\\"...</td>\n      <td>c(\"\\\"celery\\\"\", \"\\\"onion\\\"\", \"\\\"butter\\\"\", \"\\\"...</td>\n      <td>370.8</td>\n      <td>17.5</td>\n      <td>7.2</td>\n      <td>22.9</td>\n      <td>553.3</td>\n      <td>44.3</td>\n      <td>1.6</td>\n      <td>2.2</td>\n      <td>9.4</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>141757</td>\n      <td>Copycat Taco Bell Nacho Fries BellGrande</td>\n      <td>3600</td>\n      <td>2700</td>\n      <td>Other</td>\n      <td>c(\"\\\"3\\\"\", \"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"3\\\"...</td>\n      <td>c(\"\\\"Copycat Taco Bell Seasoned Beef\\\"\", \"\\\"ye...</td>\n      <td>377.6</td>\n      <td>20.9</td>\n      <td>10.5</td>\n      <td>45.7</td>\n      <td>1501.8</td>\n      <td>36.6</td>\n      <td>3.8</td>\n      <td>6.1</td>\n      <td>12.9</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>280351</td>\n      <td>Slow Cooker Jalapeno Cheddar Cheese Soup</td>\n      <td>18000</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"2\\\"\", \"\\\"1\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1\\\"\",...</td>\n      <td>c(\"\\\"unsalted butter\\\"\", \"\\\"yellow onion\\\"\", \"...</td>\n      <td>282.8</td>\n      <td>16.5</td>\n      <td>10.3</td>\n      <td>50.5</td>\n      <td>630.2</td>\n      <td>22.8</td>\n      <td>2.3</td>\n      <td>2.7</td>\n      <td>11.7</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>180505</td>\n      <td>Cool &amp; Crisp Citrus Chiffon Pie</td>\n      <td>3600</td>\n      <td>1800</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"1/4\\\"\", \"\\\"1/2\\\"\", \"\\\"1/2\\\"\", \"\\...</td>\n      <td>c(\"\\\"unflavored gelatin\\\"\", \"\\\"water\\\"\", \"\\\"su...</td>\n      <td>257.5</td>\n      <td>8.6</td>\n      <td>2.4</td>\n      <td>110.7</td>\n      <td>160.9</td>\n      <td>39.8</td>\n      <td>0.4</td>\n      <td>30.2</td>\n      <td>6.3</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>75599</th>\n      <td>253577</td>\n      <td>Frijoles Negros- Crock Pot Mexican Black Beans</td>\n      <td>43200</td>\n      <td>28800</td>\n      <td>Other</td>\n      <td>c(\"\\\"2\\\"\", \"\\\"6 -8\\\"\", \"\\\"5\\\"\", \"\\\"1/2\\\"\", \"\\\"...</td>\n      <td>c(\"\\\"black beans\\\"\", \"\\\"water\\\"\", \"\\\"bay leave...</td>\n      <td>121.5</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1175.1</td>\n      <td>22.2</td>\n      <td>7.8</td>\n      <td>0.6</td>\n      <td>7.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75600</th>\n      <td>267827</td>\n      <td>Moose Moussaka</td>\n      <td>3600</td>\n      <td>2700</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"6\\\"\", \"\\\"2\\\"\", \"\\\"2\\\"\", \"\\\"1/2\\\"...</td>\n      <td>c(\"\\\"onion\\\"\", \"\\\"garlic cloves\\\"\", \"\\\"olive o...</td>\n      <td>652.2</td>\n      <td>25.8</td>\n      <td>10.7</td>\n      <td>197.9</td>\n      <td>435.5</td>\n      <td>51.9</td>\n      <td>7.5</td>\n      <td>7.2</td>\n      <td>50.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75601</th>\n      <td>266983</td>\n      <td>Cantonese Pepper Steak for Two (Or More)</td>\n      <td>1800</td>\n      <td>900</td>\n      <td>Other</td>\n      <td>c(\"\\\"1/2\\\"\", \"\\\"1\\\"\", \"\\\"1/8\\\"\", \"\\\"1/8\\\"\", \"\\...</td>\n      <td>c(\"\\\"top round steak\\\"\", \"\\\"cornstarch\\\"\", \"\\\"...</td>\n      <td>223.9</td>\n      <td>9.2</td>\n      <td>3.6</td>\n      <td>78.3</td>\n      <td>725.9</td>\n      <td>7.3</td>\n      <td>1.1</td>\n      <td>1.7</td>\n      <td>26.7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>75602</th>\n      <td>253739</td>\n      <td>Coconut Cream Cooler</td>\n      <td>300</td>\n      <td>120</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"\", \"\\\"7 1/2\\\"\", \"\\\"1...</td>\n      <td>c(\"\\\"cream of coconut\\\"\", \"\\\"water\\\"\")</td>\n      <td>2229.8</td>\n      <td>80.3</td>\n      <td>69.3</td>\n      <td>0.0</td>\n      <td>294.7</td>\n      <td>369.0</td>\n      <td>15.7</td>\n      <td>317.9</td>\n      <td>26.7</td>\n      <td>NaN</td>\n      <td>1 gallon</td>\n    </tr>\n    <tr>\n      <th>75603</th>\n      <td>78171</td>\n      <td>Cheater Risotto</td>\n      <td>960</td>\n      <td>600</td>\n      <td>Other</td>\n      <td>c(\"\\\"1\\\"\", \"\\\"3/4\\\"\", \"\\\"4\\\"\", \"\\\"1\\\"\", \"\\\"1\\\"...</td>\n      <td>c(\"\\\"arborio rice\\\"\", \"\\\"white wine\\\"\", \"\\\"gar...</td>\n      <td>654.1</td>\n      <td>13.8</td>\n      <td>6.9</td>\n      <td>34.6</td>\n      <td>1114.0</td>\n      <td>92.2</td>\n      <td>3.9</td>\n      <td>4.2</td>\n      <td>21.8</td>\n      <td>NaN</td>\n      <td>2 1/2 cups</td>\n    </tr>\n  </tbody>\n</table>\n<p>75604 rows × 18 columns</p>\n</div>"
     },
     "execution_count": 1117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recipes = pd.read_csv('recipes.csv', low_memory=False)\n",
    "recipes.rename(columns={\n",
    "    'Name': 'RecipeName'\n",
    "}, inplace=True)\n",
    "recipes"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.175551Z",
     "start_time": "2024-01-29T03:22:00.445159Z"
    }
   },
   "id": "2b093a7364ade8b9",
   "execution_count": 1117
  },
  {
   "cell_type": "code",
   "execution_count": 1118,
   "outputs": [],
   "source": [
    "recipe1_count= recipes['RecipeId']\n",
    "print(\"Recipe Id \")\n",
    "print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.187088Z",
     "start_time": "2024-01-29T03:22:01.133429Z"
    }
   },
   "id": "df4ba00a84909f35"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Pair Plot for Nutritional Content:Explore relationships between nutritional content variables using a pair plot.\n",
    "nutritional_content = recipes[['Calories', 'FatContent', 'CarbohydrateContent', 'ProteinContent']]\n",
    "sns.pairplot(nutritional_content)\n",
    "plt.suptitle('Pair Plot of Nutritional Content', y=1.02)\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.190062Z",
     "start_time": "2024-01-29T03:22:01.139751Z"
    }
   },
   "id": "6ed6bee69604e265",
   "execution_count": 1119
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Histogram for Calories:Explore the distribution of calories in recipes using a histogram.\n",
    "custom_bins = np.arange(0, 5100, 200)  # Adjust the range and interval as needed\n",
    "\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.hist(recipes['Calories'], bins=custom_bins, color='skyblue', edgecolor='black')\n",
    "plt.title('Distribution of Calories in Recipes')\n",
    "plt.xlabel('Calories')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Set x-axis labels\n",
    "plt.xticks(custom_bins)\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.193438Z",
     "start_time": "2024-01-29T03:22:01.143172Z"
    }
   },
   "id": "9df39c8c2f993cc5",
   "execution_count": 1120
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#Bar Plot for Recipe Categories: Visualize the distribution of recipes across different categories using a bar plot.\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.boxplot(x='RecipeCategory', y='CookTime', data=recipes, palette='Set2')\n",
    "plt.title('Box Plot of Cook Time by Recipe Category')\n",
    "plt.xlabel('Recipe Category')\n",
    "plt.ylabel('Cook Time')\n",
    "plt.xticks(rotation=45, ha='right')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.196224Z",
     "start_time": "2024-01-29T03:22:01.147461Z"
    }
   },
   "id": "e11c74d0824455cf",
   "execution_count": 1121
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 8))\n",
    "sns.countplot(x='RecipeCategory', data=recipes, palette='viridis', order=recipes['RecipeCategory'].value_counts().index)\n",
    "plt.title('Distribution of Recipes across Categories')\n",
    "plt.xlabel('Recipe Category')\n",
    "plt.ylabel('Count')\n",
    "plt.xticks(rotation=45, ha='right')  # Rotate x-axis labels for better readability\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.198977Z",
     "start_time": "2024-01-29T03:22:01.151301Z"
    }
   },
   "id": "438ceb8863a29b9a",
   "execution_count": 1122
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating   Like  TestSetId         Time  \\\n0          2492191A     33671     2.0    NaN        1.0  2698.714376   \n1       2002019979A     92647     2.0    NaN        2.0  2399.694583   \n2           408594E    161770     NaN    NaN        3.0  2099.113170   \n3       2001625557E    108231     2.0    NaN        4.0  1199.645575   \n4       2001427116E     71109     NaN    NaN        5.0  2341.181827   \n...             ...       ...     ...    ...        ...          ...   \n140190      999595E    338070     2.0  False        NaN  3899.421310   \n140191      999774A     29002     2.0  False        NaN  2402.372535   \n140192      999774A    159252     NaN  False        NaN  5999.598903   \n140193      999774A      1171     2.0   True        NaN   480.233207   \n140194      999917E    169413     2.0  False        NaN  3600.387748   \n\n        HighCalories  HighProtein  LowFat     LowSugar  HighFiber  \n0                0.0  Indifferent       1            0          1  \n1                1.0  Indifferent       0  Indifferent          1  \n2                1.0  Indifferent       0            0          1  \n3                1.0          Yes       0            0          1  \n4                1.0  Indifferent       0            0          1  \n...              ...          ...     ...          ...        ...  \n140190           0.0  Indifferent       1  Indifferent          0  \n140191           0.0  Indifferent       0  Indifferent          0  \n140192           0.0          Yes       0            0          0  \n140193           1.0          Yes       0            0          0  \n140194           0.0  Indifferent       0  Indifferent          0  \n\n[140195 rows x 11 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2492191A</td>\n      <td>33671</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>1.0</td>\n      <td>2698.714376</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2002019979A</td>\n      <td>92647</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2.0</td>\n      <td>2399.694583</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>408594E</td>\n      <td>161770</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3.0</td>\n      <td>2099.113170</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001625557E</td>\n      <td>108231</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>4.0</td>\n      <td>1199.645575</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>2001427116E</td>\n      <td>71109</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>5.0</td>\n      <td>2341.181827</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999595E</td>\n      <td>338070</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.421310</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999774A</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>999917E</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 11 columns</p>\n</div>"
     },
     "execution_count": 1123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_request_review = pd.merge(reviews,requests,on=['AuthorId','RecipeId'])\n",
    "merged_request_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.323984Z",
     "start_time": "2024-01-29T03:22:01.158365Z"
    }
   },
   "id": "ae2ed40a9bf4da80",
   "execution_count": 1123
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "user1_count= merged_request_review['AuthorId']\n",
    "print(\"Author Id \")\n",
    "print(f'The number of author ids is: {user1_count.size}')\n",
    "print(f'The number of unique author ids is: {user1_count.unique().size}')\n",
    "print(f'Author Diff: {user_count.size-user_count.unique().size}')\n",
    "recipe1_count= merged_request_review['RecipeId']\n",
    "print(\"Recipe Id \")\n",
    "print(f'The number of recipe ids is: {recipe1_count.size}')\n",
    "print(f'The number of unique recipe ids is: {recipe1_count.unique().size}')\n",
    "print(f'Recipe Diff: {recipe_count.size-recipe_count.unique().size}')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.327174Z",
     "start_time": "2024-01-29T03:22:01.236567Z"
    }
   },
   "id": "40fe2c30f2a496a5",
   "execution_count": 1124
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "#eatmap for Correlation: Visualize the correlation between numerical variables.\n",
    "correlation_matrix = merged_request_review[['Rating', 'Like', 'Time', 'HighCalories', 'LowFat', 'HighFiber']].corr()\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.heatmap(correlation_matrix, annot=True, cmap='coolwarm', linewidths=.5)\n",
    "plt.title('Correlation Heatmap for Merged Data')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.333991Z",
     "start_time": "2024-01-29T03:22:01.238794Z"
    }
   },
   "id": "f54f70b1a088f1fe",
   "execution_count": 1125
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 5))\n",
    "sns.barplot(x='HighProtein', y='Rating', data=merged_request_review, palette='Set2')\n",
    "plt.title('Average Rating for Recipes with and without High Protein')\n",
    "plt.xlabel('HighProtein')\n",
    "plt.ylabel('Average Rating')\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.336762Z",
     "start_time": "2024-01-29T03:22:01.244960Z"
    }
   },
   "id": "249933b68ff314eb",
   "execution_count": 1126
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(x='HighCalories', y='Like', data=merged_request_review, palette='pastel')\n",
    "plt.title('Box Plot of Likes for Recipes with and without High Calories')\n",
    "plt.xlabel('HighCalories')\n",
    "plt.ylabel('Like')\n",
    "plt.show() \n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.356805Z",
     "start_time": "2024-01-29T03:22:01.247802Z"
    }
   },
   "id": "683a1e26a75c70bd",
   "execution_count": 1127
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "sns.pairplot(merged_request_review[['Like', 'Time', 'HighCalories', 'HighProtein', 'LowFat', 'LowSugar', 'HighFiber']])\n",
    "plt.suptitle('Pair Plot of Merged Data', y=1.02)\n",
    "plt.show()\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.359676Z",
     "start_time": "2024-01-29T03:22:01.250622Z"
    }
   },
   "id": "ab723ac6ab1b8e0",
   "execution_count": 1128
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CHECK** If a following recipe id exists and how many times and if the Recipe Id is mapped to the unique AuthorId "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a2170603a82612"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "recipe_id_to_check = merged_request_review['RecipeId'].value_counts().idxmax()\n",
    "\n",
    "# Display the result\n",
    "recipe_exists = merged_request_review['RecipeId'].isin([recipe_id_to_check])\n",
    "\n",
    "# Display the result\n",
    "if recipe_exists.any():\n",
    "    # print(f\"Recipe with RecipeId {recipe_id_to_check} exists.\")\n",
    "    recipe_count = merged_request_review['RecipeId'].value_counts().get(recipe_id_to_check, 0)\n",
    "    print(f\"Recipe with RecipeId {recipe_id_to_check} repeats {recipe_count} times.\")\n",
    "    # Get the table of corresponding AuthorId values for the given RecipeId\n",
    "    author_id_table = merged_request_review.loc[merged_request_review['RecipeId'] == recipe_id_to_check, ['AuthorId','RecipeId']]\n",
    "    print(\"Table of AuthorId values for RecipeId\", recipe_id_to_check)\n",
    "    print()\n",
    "\n",
    "else:\n",
    "    print(f\"Recipe with RecipeId {recipe_id_to_check} does not exist.\")\n",
    "\n",
    "author_id_table    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.375293Z",
     "start_time": "2024-01-29T03:22:01.254322Z"
    }
   },
   "id": "4563c515c8335bba",
   "execution_count": 1129
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "unique_recipe_ids_from_merge = merged_request_review['RecipeId'].unique()\n",
    "unique_recipe_ids_from_recipes = recipes['RecipeId'].unique()\n",
    "are_ids_equal = set(unique_recipe_ids_from_recipes) == set(unique_recipe_ids_from_merge)\n",
    "\n",
    "if are_ids_equal:\n",
    "    print(\"The unique RecipeId values are the same in both DataFrames.\")\n",
    "else:\n",
    "    print(\"The unique RecipeId values are not the same in both DataFrames.\")\n",
    "\n",
    "# # Assuming merged_request_review is the result of merging reviews and requests DataFrames\n",
    "# # using pd.merge(reviews, requests, on=['AuthorId', 'RecipeId'])\n",
    "# \n",
    "# # Get the unique RecipeId values\n",
    "# unique_recipe_ids = merged_request_review['RecipeId'].unique()\n",
    "# \n",
    "# # Initialize a list to store the uniqueness result for each RecipeId\n",
    "# uniqueness_results = []\n",
    "# \n",
    "# # Iterate over unique RecipeId values\n",
    "# for recipe_id in unique_recipe_ids:\n",
    "#     # Get the table of corresponding AuthorId values for the given RecipeId\n",
    "#     author_id_table = merged_request_review.loc[merged_request_review['RecipeId'] == recipe_id, ['AuthorId', 'RecipeId']]\n",
    "# \n",
    "#     # Check if the mapped AuthorId values are unique\n",
    "#     is_author_id_unique = ~author_id_table['AuthorId'].duplicated().any()\n",
    "# \n",
    "#     uniqueness_results.append((recipe_id, is_author_id_unique))\n",
    "# \n",
    "# # Create a DataFrame from the results\n",
    "# uniqueness_df = pd.DataFrame(uniqueness_results, columns=['RecipeId', 'IsAuthorIdUnique'])\n",
    "# \n",
    "# # Display the DataFrame\n",
    "# print(uniqueness_df)\n",
    "# # \n",
    "# # Visualization: Bar plot of unique AuthorId counts for each RecipeId\n",
    "# uniqueness_df.set_index('RecipeId')['IsAuthorIdUnique'].astype(int).plot(kind='bar', xlabel='RecipeId', ylabel='IsAuthorIdUnique (1: True, 0: False)', title='Uniqueness of AuthorId for Each RecipeId')\n",
    "# plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.490979Z",
     "start_time": "2024-01-29T03:22:01.257844Z"
    }
   },
   "id": "d305ac55a6901072",
   "execution_count": 1130
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "           AuthorId  RecipeId  Rating  Like  TestSetId          Time  \\\n0           914496A     73440     NaN   NaN     1548.0   1800.709345   \n1          2668181C     73440     2.0   NaN     2069.0   1797.825626   \n2       2000237272A     73440     2.0   NaN     2152.0   1800.440504   \n3       2001895110E     73440     NaN   NaN     3293.0   1799.437007   \n4       1800347124D     73440     NaN   NaN     4621.0   1801.007172   \n...             ...       ...     ...   ...        ...           ...   \n140190     1677720D    253577     2.0  True        NaN  71998.977353   \n140191      853126B    267827     NaN   NaN     7148.0   6299.278484   \n140192  2000154789A    266983     2.0  True        NaN   2700.812133   \n140193      499207A    253739     2.0  True        NaN    419.558713   \n140194      163793B     78171     NaN  True        NaN   1560.649725   \n\n        HighCalories  HighProtein  LowFat     LowSugar  ...  FatContent  \\\n0                0.0  Indifferent       0            0  ...        10.1   \n1                0.0          Yes       0  Indifferent  ...        10.1   \n2                1.0  Indifferent       0            0  ...        10.1   \n3                0.0  Indifferent       0            0  ...        10.1   \n4                1.0          Yes       0            0  ...        10.1   \n...              ...          ...     ...          ...  ...         ...   \n140190           0.0  Indifferent       1  Indifferent  ...         0.5   \n140191           0.0          Yes       1            0  ...        25.8   \n140192           0.0          Yes       0            0  ...         9.2   \n140193           1.0  Indifferent       0  Indifferent  ...        80.3   \n140194           0.0  Indifferent       0            0  ...        13.8   \n\n       SaturatedFatContent  CholesterolContent  SodiumContent  \\\n0                      1.2                 0.0           13.1   \n1                      1.2                 0.0           13.1   \n2                      1.2                 0.0           13.1   \n3                      1.2                 0.0           13.1   \n4                      1.2                 0.0           13.1   \n...                    ...                 ...            ...   \n140190                 0.1                 0.0         1175.1   \n140191                10.7               197.9          435.5   \n140192                 3.6                78.3          725.9   \n140193                69.3                 0.0          294.7   \n140194                 6.9                34.6         1114.0   \n\n       CarbohydrateContent FiberContent SugarContent  ProteinContent  \\\n0                     31.8          2.3          1.4             6.7   \n1                     31.8          2.3          1.4             6.7   \n2                     31.8          2.3          1.4             6.7   \n3                     31.8          2.3          1.4             6.7   \n4                     31.8          2.3          1.4             6.7   \n...                    ...          ...          ...             ...   \n140190                22.2          7.8          0.6             7.9   \n140191                51.9          7.5          7.2            50.1   \n140192                 7.3          1.1          1.7            26.7   \n140193               369.0         15.7        317.9            26.7   \n140194                92.2          3.9          4.2            21.8   \n\n        RecipeServings  RecipeYield  \n0                  9.0          NaN  \n1                  9.0          NaN  \n2                  9.0          NaN  \n3                  9.0          NaN  \n4                  9.0          NaN  \n...                ...          ...  \n140190             NaN          NaN  \n140191             NaN          NaN  \n140192             2.0          NaN  \n140193             NaN     1 gallon  \n140194             NaN   2 1/2 cups  \n\n[140195 rows x 28 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>914496A</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>1548.0</td>\n      <td>1800.709345</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2668181C</td>\n      <td>73440</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2069.0</td>\n      <td>1797.825626</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2000237272A</td>\n      <td>73440</td>\n      <td>2.0</td>\n      <td>NaN</td>\n      <td>2152.0</td>\n      <td>1800.440504</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>2001895110E</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>3293.0</td>\n      <td>1799.437007</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1800347124D</td>\n      <td>73440</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>4621.0</td>\n      <td>1801.007172</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>10.1</td>\n      <td>1.2</td>\n      <td>0.0</td>\n      <td>13.1</td>\n      <td>31.8</td>\n      <td>2.3</td>\n      <td>1.4</td>\n      <td>6.7</td>\n      <td>9.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>1677720D</td>\n      <td>253577</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>71998.977353</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>1175.1</td>\n      <td>22.2</td>\n      <td>7.8</td>\n      <td>0.6</td>\n      <td>7.9</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>853126B</td>\n      <td>267827</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7148.0</td>\n      <td>6299.278484</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>...</td>\n      <td>25.8</td>\n      <td>10.7</td>\n      <td>197.9</td>\n      <td>435.5</td>\n      <td>51.9</td>\n      <td>7.5</td>\n      <td>7.2</td>\n      <td>50.1</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>2000154789A</td>\n      <td>266983</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>2700.812133</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>9.2</td>\n      <td>3.6</td>\n      <td>78.3</td>\n      <td>725.9</td>\n      <td>7.3</td>\n      <td>1.1</td>\n      <td>1.7</td>\n      <td>26.7</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>499207A</td>\n      <td>253739</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>419.558713</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>80.3</td>\n      <td>69.3</td>\n      <td>0.0</td>\n      <td>294.7</td>\n      <td>369.0</td>\n      <td>15.7</td>\n      <td>317.9</td>\n      <td>26.7</td>\n      <td>NaN</td>\n      <td>1 gallon</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>163793B</td>\n      <td>78171</td>\n      <td>NaN</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>1560.649725</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>13.8</td>\n      <td>6.9</td>\n      <td>34.6</td>\n      <td>1114.0</td>\n      <td>92.2</td>\n      <td>3.9</td>\n      <td>4.2</td>\n      <td>21.8</td>\n      <td>NaN</td>\n      <td>2 1/2 cups</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 28 columns</p>\n</div>"
     },
     "execution_count": 1131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_recipes_req_review= pd.merge(merged_request_review,recipes,on=['RecipeId'],how='right')\n",
    "merged_recipes_req_review"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.708226Z",
     "start_time": "2024-01-29T03:22:01.260981Z"
    }
   },
   "id": "a09bd1c03e12ce80",
   "execution_count": 1131
  },
  {
   "cell_type": "markdown",
   "source": [
    "Changing the object data types"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f8738647b7b81bc"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Data Joining using common attributes"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "de61709106b4c884"
  },
  {
   "cell_type": "code",
   "execution_count": 1132,
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.386790           0.0          Yes  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2402.372535           0.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5999.598903           0.0          Yes  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.386790</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 1132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "author_ID = 'AuthorId'\n",
    "merged_diet_all = pd.merge(diet, merged_recipes_req_review, on=author_ID)\n",
    "# merged_request_recipes = pd.merge(requests, recipes, on='RecipeId', how='left')\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:01.949824Z",
     "start_time": "2024-01-29T03:22:01.384982Z"
    }
   },
   "id": "b4f7cfcbad4cda38"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Plot graphs of the data frames"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1caafd20b94c3350"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute the missing values"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9062a6a8aa6efd46"
  },
  {
   "cell_type": "code",
   "execution_count": 1133,
   "outputs": [],
   "source": [
    "\n",
    "# 1 value missing in diet column. Filled with most occuring value.\n",
    "merged_diet_all['Diet'] = merged_diet_all['Diet'].fillna('Vegetarian')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:02.034132Z",
     "start_time": "2024-01-29T03:22:01.681228Z"
    }
   },
   "id": "c3518f9894f574d0"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default of observed=False is deprecated and will be changed to True in a future version of pandas. Pass observed=False to retain current behavior or observed=True to adopt the future default and silence this warning.\n"
     ]
    },
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.386790           0.0          Yes  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2402.372535           0.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5999.598903           0.0          Yes  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.386790</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2402.372535</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5999.598903</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 1134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#impute the values for all dietary preferences for all ages with the most frequent RecipeId for that age in that category\n",
    "helper_df = merged_diet_all.groupby(['Age', 'Diet'])['RecipeId'].agg(lambda x: x.mode()[0]).reset_index()\n",
    "helper_df.columns = ['Age', 'Diet', 'Most Common Recipe']\n",
    "def impute_recipe(row):\n",
    "    if pd.isnull(row['RecipeId']):\n",
    "        return helper_df[(helper_df['Age'] == row['Age']) & (helper_df['Diet'] == row['Diet'])]['Most Common Recipe'].values[0]\n",
    "    else:\n",
    "        return row['RecipeId']\n",
    "merged_diet_all['RecipeId'] = merged_diet_all.apply(impute_recipe, axis=1)\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:03.999932Z",
     "start_time": "2024-01-29T03:22:01.698627Z"
    }
   },
   "id": "d11e460c388617a3",
   "execution_count": 1134
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     NaN  False        NaN   \n1       1000216B  Vegetarian   78    189335     NaN  False        NaN   \n2       1000221A  Vegetarian   25     17444     NaN  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     NaN  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     NaN    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...         0.0   \n1       1199.549763           1.0  Indifferent  ...        19.2   \n2       3899.147999           1.0          Yes  ...        10.3   \n3        362.152341           0.0          Yes  ...        13.5   \n4       1198.957497           0.0          Yes  ...        49.0   \n...             ...           ...          ...  ...         ...   \n140190  2400.009731           1.0  Indifferent  ...        33.3   \n140191   480.233207           1.0          Yes  ...        19.8   \n140192  5998.670408           1.0  Indifferent  ...         0.6   \n140193  3600.387748           0.0  Indifferent  ...         8.6   \n140194  7199.509521           0.0          Yes  ...         0.2   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>19.2</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>10.3</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>13.5</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>49.0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>33.3</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>19.8</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>NaN</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0.6</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>8.6</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>NaN</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0.2</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 1135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fill the rest of the missing values in the merged_diet_all by mapping them from requests.csv with RecipeId as key \n",
    "# Create mapping DataFrames from `requests`\n",
    "map_time = requests.set_index('RecipeId')['Time'].to_dict()\n",
    "map_calories = requests.set_index('RecipeId')['HighCalories'].to_dict()\n",
    "map_protein = requests.set_index('RecipeId')['HighProtein'].to_dict()\n",
    "map_fat = requests.set_index('RecipeId')['LowFat'].to_dict()\n",
    "map_sugar = requests.set_index('RecipeId')['LowSugar'].to_dict()\n",
    "map_fiber = requests.set_index('RecipeId')['HighFiber'].to_dict()\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['Time'] = merged_diet_all['RecipeId'].map(map_time)\n",
    "merged_diet_all['HighCalories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['HighProtein'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['LowFat'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['LowSugar'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['HighFiber'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:05.438706Z",
     "start_time": "2024-01-29T03:22:03.961697Z"
    }
   },
   "id": "dfc5cbaa679201ad",
   "execution_count": 1135
  },
  {
   "cell_type": "markdown",
   "source": [
    "Impute value from recipe.csv"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "23c0a1c86901f370"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "map_name = recipes.set_index('RecipeId')['RecipeName'].to_dict()\n",
    "map_cook_time = recipes.set_index('RecipeId')['CookTime'].to_dict()\n",
    "map_prep_time = recipes.set_index('RecipeId')['PrepTime'].to_dict()\n",
    "map_category = recipes.set_index('RecipeId')['RecipeCategory'].to_dict()\n",
    "map_quantities = recipes.set_index('RecipeId')['RecipeIngredientQuantities'].to_dict()\n",
    "map_parts = recipes.set_index('RecipeId')['RecipeIngredientParts'].to_dict()\n",
    "map_calories = recipes.set_index('RecipeId')['Calories'].to_dict()\n",
    "map_fat_content = recipes.set_index('RecipeId')['FatContent'].to_dict()\n",
    "map_saturated_content = recipes.set_index('RecipeId')['SaturatedFatContent'].to_dict()\n",
    "map_cholesterol = recipes.set_index('RecipeId')['CholesterolContent'].to_dict()\n",
    "map_sodium = recipes.set_index('RecipeId')['SodiumContent'].to_dict()\n",
    "map_carbohydrate = recipes.set_index('RecipeId')['CarbohydrateContent'].to_dict()\n",
    "map_fiber = recipes.set_index('RecipeId')['FiberContent'].to_dict()\n",
    "map_sugar = recipes.set_index('RecipeId')['SugarContent'].to_dict()\n",
    "map_protein = recipes.set_index('RecipeId')['ProteinContent'].to_dict()\n",
    "map_servings = recipes.set_index('RecipeId')['RecipeServings'].to_dict()\n",
    "map_yield = recipes.set_index('RecipeId')['RecipeYield'].to_dict()\n",
    "\n",
    "\n",
    "# Apply mapping to `merged_diet_all`\n",
    "merged_diet_all['RecipeName'] = merged_diet_all['RecipeId'].map(map_name)\n",
    "merged_diet_all['CookTime'] = merged_diet_all['RecipeId'].map(map_cook_time)\n",
    "merged_diet_all['PrepTime'] = merged_diet_all['RecipeId'].map(map_prep_time)\n",
    "merged_diet_all['RecipeCategory'] = merged_diet_all['RecipeId'].map(map_category)\n",
    "merged_diet_all['RecipeIngredientQuantities'] = merged_diet_all['RecipeId'].map(map_quantities)\n",
    "merged_diet_all['RecipeIngredientParts'] = merged_diet_all['RecipeId'].map(map_parts)\n",
    "merged_diet_all['Calories'] = merged_diet_all['RecipeId'].map(map_calories)\n",
    "merged_diet_all['FatContent'] = merged_diet_all['RecipeId'].map(map_fat)\n",
    "merged_diet_all['SaturatedFatContent'] = merged_diet_all['RecipeId'].map(map_saturated_content)\n",
    "merged_diet_all['CholesterolContent'] = merged_diet_all['RecipeId'].map(map_cholesterol)\n",
    "merged_diet_all['SodiumContent'] = merged_diet_all['RecipeId'].map(map_sodium)\n",
    "merged_diet_all['CarbohydrateContent'] = merged_diet_all['RecipeId'].map(map_carbohydrate)\n",
    "merged_diet_all['FiberContent'] = merged_diet_all['RecipeId'].map(map_fiber)\n",
    "merged_diet_all['SugarContent'] = merged_diet_all['RecipeId'].map(map_sugar)\n",
    "merged_diet_all['ProteinContent'] = merged_diet_all['RecipeId'].map(map_protein)\n",
    "merged_diet_all['RecipeServings'] = merged_diet_all['RecipeId'].map(map_servings)\n",
    "merged_diet_all['RecipeYield'] = merged_diet_all['RecipeId'].map(map_yield)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:08.385530Z",
     "start_time": "2024-01-29T03:22:05.336156Z"
    }
   },
   "id": "374829871d19a91",
   "execution_count": 1136
  },
  {
   "cell_type": "markdown",
   "source": [
    "**CHECK IF IT WORKS**"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ce4bfb36b4247f4a"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "        AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0       1000036C  Vegetarian   50    320576     0.0  False        NaN   \n1       1000216B  Vegetarian   78    189335     0.0  False        NaN   \n2       1000221A  Vegetarian   25     17444     0.0  False        NaN   \n3       1000221A  Vegetarian   25    133043     2.0  False        NaN   \n4       1000221A  Vegetarian   25     90537     2.0  False        NaN   \n...          ...         ...  ...       ...     ...    ...        ...   \n140190   999774A  Vegetarian   57     29002     2.0  False        NaN   \n140191   999774A  Vegetarian   57      1171     2.0   True        NaN   \n140192   999774A  Vegetarian   57    159252     0.0  False        NaN   \n140193   999917E  Vegetarian   28    169413     2.0  False        NaN   \n140194    99994A  Vegetarian   18    373964     0.0    NaN     7555.0   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0        119.024930           0.0  Indifferent  ...           0   \n1       1199.549763           1.0  Indifferent  ...           0   \n2       3899.147999           1.0          Yes  ...           0   \n3        362.152341           0.0          Yes  ...           0   \n4       1198.957497           0.0          Yes  ...           0   \n...             ...           ...          ...  ...         ...   \n140190  2400.009731           1.0  Indifferent  ...           0   \n140191   480.233207           1.0          Yes  ...           0   \n140192  5998.670408           1.0  Indifferent  ...           0   \n140193  3600.387748           0.0  Indifferent  ...           0   \n140194  7199.509521           0.0          Yes  ...           0   \n\n       SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                      0.0                 0.0           0.6   \n1                      4.5                33.9         714.2   \n2                      6.0                36.6         119.8   \n3                      1.9                 0.0           0.6   \n4                      7.2                 0.0         115.8   \n...                    ...                 ...           ...   \n140190                 8.5                33.2         318.2   \n140191                12.2                68.3         247.4   \n140192                 0.1                 0.0           6.8   \n140193                 4.7                66.5         521.9   \n140194                 0.0                 0.0           5.6   \n\n        CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                       0.0           0.0          0.0            0.0   \n1                      38.0           0.8          4.3           16.3   \n2                      13.7           1.0          1.0            8.7   \n3                       1.9           0.4          0.4            0.2   \n4                     241.7          69.4         15.7           68.9   \n...                     ...           ...          ...            ...   \n140190                107.7          10.3         13.5           32.0   \n140191                 87.5           4.0         57.8           18.2   \n140192                240.4           7.0        229.8            1.1   \n140193                 24.8           1.7          3.4            5.6   \n140194                 36.2           0.2         33.6            0.2   \n\n       RecipeServings  RecipeYield  \n0                 1.0          NaN  \n1                 8.0          NaN  \n2                12.0          NaN  \n3                 NaN     4 ounces  \n4                 1.0          NaN  \n...               ...          ...  \n140190            4.0          NaN  \n140191            1.0       2 mugs  \n140192            NaN       4 cups  \n140193            8.0          NaN  \n140194           16.0     3 quarts  \n\n[140195 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1000036C</td>\n      <td>Vegetarian</td>\n      <td>50</td>\n      <td>320576</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>119.024930</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1000216B</td>\n      <td>Vegetarian</td>\n      <td>78</td>\n      <td>189335</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1199.549763</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.5</td>\n      <td>33.9</td>\n      <td>714.2</td>\n      <td>38.0</td>\n      <td>0.8</td>\n      <td>4.3</td>\n      <td>16.3</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>17444</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3899.147999</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.0</td>\n      <td>36.6</td>\n      <td>119.8</td>\n      <td>13.7</td>\n      <td>1.0</td>\n      <td>1.0</td>\n      <td>8.7</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>133043</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>362.152341</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>1.9</td>\n      <td>0.0</td>\n      <td>0.6</td>\n      <td>1.9</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>NaN</td>\n      <td>4 ounces</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>1000221A</td>\n      <td>Vegetarian</td>\n      <td>25</td>\n      <td>90537</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1198.957497</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>7.2</td>\n      <td>0.0</td>\n      <td>115.8</td>\n      <td>241.7</td>\n      <td>69.4</td>\n      <td>15.7</td>\n      <td>68.9</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140190</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>29002</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>2400.009731</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>8.5</td>\n      <td>33.2</td>\n      <td>318.2</td>\n      <td>107.7</td>\n      <td>10.3</td>\n      <td>13.5</td>\n      <td>32.0</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140191</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>1171</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>480.233207</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>12.2</td>\n      <td>68.3</td>\n      <td>247.4</td>\n      <td>87.5</td>\n      <td>4.0</td>\n      <td>57.8</td>\n      <td>18.2</td>\n      <td>1.0</td>\n      <td>2 mugs</td>\n    </tr>\n    <tr>\n      <th>140192</th>\n      <td>999774A</td>\n      <td>Vegetarian</td>\n      <td>57</td>\n      <td>159252</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5998.670408</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>6.8</td>\n      <td>240.4</td>\n      <td>7.0</td>\n      <td>229.8</td>\n      <td>1.1</td>\n      <td>NaN</td>\n      <td>4 cups</td>\n    </tr>\n    <tr>\n      <th>140193</th>\n      <td>999917E</td>\n      <td>Vegetarian</td>\n      <td>28</td>\n      <td>169413</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>3600.387748</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.7</td>\n      <td>66.5</td>\n      <td>521.9</td>\n      <td>24.8</td>\n      <td>1.7</td>\n      <td>3.4</td>\n      <td>5.6</td>\n      <td>8.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>99994A</td>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>373964</td>\n      <td>0.0</td>\n      <td>NaN</td>\n      <td>7555.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>16.0</td>\n      <td>3 quarts</td>\n    </tr>\n  </tbody>\n</table>\n<p>140195 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 1137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_diet_all['Rating'] = merged_diet_all['Rating'].fillna(0)\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:08.696204Z",
     "start_time": "2024-01-29T03:22:08.384937Z"
    }
   },
   "id": "61303a62f5e8933d",
   "execution_count": 1137
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "          AuthorId        Diet  Age  RecipeId  Rating   Like  TestSetId  \\\n0      2001911204C  Vegetarian   42     43068     2.0  False        NaN   \n1      2001297108C  Vegetarian   71    454938     2.0  False        NaN   \n2          329166A  Vegetarian   24     61946     2.0  False        NaN   \n3          683746A  Vegetarian   48     62513     2.0   True        NaN   \n4          873768E  Vegetarian   53     78122     0.0  False        NaN   \n...            ...         ...  ...       ...     ...    ...        ...   \n27251     1316717E  Vegetarian   36     89007     2.0  False        NaN   \n27252  2001055509B  Vegetarian   66     18510     2.0   True        NaN   \n27253     1184634D  Vegetarian   68     43522     0.0   True        NaN   \n27254      250354B  Vegetarian   37    374962     2.0  False        NaN   \n27255  2001279035D  Vegetarian   26    245689     0.0  False        NaN   \n\n               Time  HighCalories  HighProtein  ...  FatContent  \\\n0       4500.293015           0.0  Indifferent  ...           0   \n1       1800.982212           0.0          Yes  ...           0   \n2        301.977468           1.0  Indifferent  ...           1   \n3       2701.732287           0.0  Indifferent  ...           1   \n4       5100.747231           0.0  Indifferent  ...           0   \n...             ...           ...          ...  ...         ...   \n27251  25801.104361           0.0          Yes  ...           1   \n27252    119.221052           0.0          Yes  ...           0   \n27253   3599.134079           1.0  Indifferent  ...           0   \n27254   5699.982819           1.0  Indifferent  ...           0   \n27255    599.550510           0.0  Indifferent  ...           0   \n\n      SaturatedFatContent  CholesterolContent SodiumContent  \\\n0                     6.5               149.7         439.6   \n1                     3.0               230.4         693.9   \n2                     0.0                 0.0           4.1   \n3                     2.6                26.9          66.2   \n4                     6.4                64.0         775.7   \n...                   ...                 ...           ...   \n27251                 1.6                94.4         638.9   \n27252                 9.9               216.5         439.8   \n27253                25.8               194.3         668.9   \n27254                 6.1                91.0          71.8   \n27255                 9.7               309.5         212.8   \n\n       CarbohydrateContent  FiberContent SugarContent ProteinContent  \\\n0                     11.7           1.1          7.9           49.3   \n1                      6.2           1.9          1.0           31.6   \n2                      8.8           0.4          0.2            0.2   \n3                     18.3           0.5          9.2            2.0   \n4                     36.1           7.7          4.4           25.7   \n...                    ...           ...          ...            ...   \n27251                 36.8           2.1          4.8           28.8   \n27252                  9.0           7.7          0.6           11.5   \n27253                102.7           3.3         60.7           11.3   \n27254                 24.9           1.4         19.9           10.0   \n27255                  2.0           0.6          0.7           10.0   \n\n      RecipeServings          RecipeYield  \n0                NaN                  NaN  \n1                6.0                  NaN  \n2               32.0                  NaN  \n3               24.0              24 bars  \n4                6.0                  NaN  \n...              ...                  ...  \n27251            NaN        10 sandwiches  \n27252            1.0  1 1 Bun or 2 slices  \n27253            6.0               1 cake  \n27254           12.0                  NaN  \n27255            NaN            2 omelets  \n\n[27256 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>AuthorId</th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>RecipeId</th>\n      <th>Rating</th>\n      <th>Like</th>\n      <th>TestSetId</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>RecipeServings</th>\n      <th>RecipeYield</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>2001911204C</td>\n      <td>Vegetarian</td>\n      <td>42</td>\n      <td>43068</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>4500.293015</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.5</td>\n      <td>149.7</td>\n      <td>439.6</td>\n      <td>11.7</td>\n      <td>1.1</td>\n      <td>7.9</td>\n      <td>49.3</td>\n      <td>NaN</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2001297108C</td>\n      <td>Vegetarian</td>\n      <td>71</td>\n      <td>454938</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>1800.982212</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3.0</td>\n      <td>230.4</td>\n      <td>693.9</td>\n      <td>6.2</td>\n      <td>1.9</td>\n      <td>1.0</td>\n      <td>31.6</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>329166A</td>\n      <td>Vegetarian</td>\n      <td>24</td>\n      <td>61946</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>301.977468</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>1</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>4.1</td>\n      <td>8.8</td>\n      <td>0.4</td>\n      <td>0.2</td>\n      <td>0.2</td>\n      <td>32.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>683746A</td>\n      <td>Vegetarian</td>\n      <td>48</td>\n      <td>62513</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>2701.732287</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>1</td>\n      <td>2.6</td>\n      <td>26.9</td>\n      <td>66.2</td>\n      <td>18.3</td>\n      <td>0.5</td>\n      <td>9.2</td>\n      <td>2.0</td>\n      <td>24.0</td>\n      <td>24 bars</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>873768E</td>\n      <td>Vegetarian</td>\n      <td>53</td>\n      <td>78122</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5100.747231</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.4</td>\n      <td>64.0</td>\n      <td>775.7</td>\n      <td>36.1</td>\n      <td>7.7</td>\n      <td>4.4</td>\n      <td>25.7</td>\n      <td>6.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27251</th>\n      <td>1316717E</td>\n      <td>Vegetarian</td>\n      <td>36</td>\n      <td>89007</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>25801.104361</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1.6</td>\n      <td>94.4</td>\n      <td>638.9</td>\n      <td>36.8</td>\n      <td>2.1</td>\n      <td>4.8</td>\n      <td>28.8</td>\n      <td>NaN</td>\n      <td>10 sandwiches</td>\n    </tr>\n    <tr>\n      <th>27252</th>\n      <td>2001055509B</td>\n      <td>Vegetarian</td>\n      <td>66</td>\n      <td>18510</td>\n      <td>2.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>119.221052</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>...</td>\n      <td>0</td>\n      <td>9.9</td>\n      <td>216.5</td>\n      <td>439.8</td>\n      <td>9.0</td>\n      <td>7.7</td>\n      <td>0.6</td>\n      <td>11.5</td>\n      <td>1.0</td>\n      <td>1 1 Bun or 2 slices</td>\n    </tr>\n    <tr>\n      <th>27253</th>\n      <td>1184634D</td>\n      <td>Vegetarian</td>\n      <td>68</td>\n      <td>43522</td>\n      <td>0.0</td>\n      <td>True</td>\n      <td>NaN</td>\n      <td>3599.134079</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>25.8</td>\n      <td>194.3</td>\n      <td>668.9</td>\n      <td>102.7</td>\n      <td>3.3</td>\n      <td>60.7</td>\n      <td>11.3</td>\n      <td>6.0</td>\n      <td>1 cake</td>\n    </tr>\n    <tr>\n      <th>27254</th>\n      <td>250354B</td>\n      <td>Vegetarian</td>\n      <td>37</td>\n      <td>374962</td>\n      <td>2.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>5699.982819</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.1</td>\n      <td>91.0</td>\n      <td>71.8</td>\n      <td>24.9</td>\n      <td>1.4</td>\n      <td>19.9</td>\n      <td>10.0</td>\n      <td>12.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>27255</th>\n      <td>2001279035D</td>\n      <td>Vegetarian</td>\n      <td>26</td>\n      <td>245689</td>\n      <td>0.0</td>\n      <td>False</td>\n      <td>NaN</td>\n      <td>599.550510</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>...</td>\n      <td>0</td>\n      <td>9.7</td>\n      <td>309.5</td>\n      <td>212.8</td>\n      <td>2.0</td>\n      <td>0.6</td>\n      <td>0.7</td>\n      <td>10.0</td>\n      <td>NaN</td>\n      <td>2 omelets</td>\n    </tr>\n  </tbody>\n</table>\n<p>27256 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 1138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Assuming df is your DataFrame\n",
    "df = merged_diet_all\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Assuming df is your DataFrame\n",
    "# Calculate the proportion of true and false values in the 'Like' column\n",
    "proportion_true = df['Like'].mean()\n",
    "proportion_false = 1 - proportion_true\n",
    "\n",
    "# Identify the indices of false values\n",
    "false_indices = df[df['Like'] == False].index\n",
    "\n",
    "# Randomly sample false indices to achieve a balanced proportion\n",
    "num_false_to_sample = int(df['Like'].value_counts()[True] / proportion_true+1500) - df['Like'].value_counts()[False]\n",
    "indices_to_sample = np.random.choice(false_indices, size=num_false_to_sample, replace=False)\n",
    "\n",
    "# Create a new DataFrame with sampled false values\n",
    "df_balanced = pd.concat([df[df['Like'] == True], df.loc[indices_to_sample]])\n",
    "\n",
    "# Shuffle the new DataFrame to randomize the order\n",
    "df_balanced = df_balanced.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print the proportion of true and false values in the balanced DataFrame\n",
    "# print(df_balanced['Like'].value_counts(normalize=True))\n",
    "df_balanced"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.270954Z",
     "start_time": "2024-01-29T03:22:08.736869Z"
    }
   },
   "id": "6f323506d35210a8",
   "execution_count": 1138
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# df_balanced"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.329086Z",
     "start_time": "2024-01-29T03:22:09.040133Z"
    }
   },
   "id": "20638952b41becd7",
   "execution_count": 1139
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# final_data = merged_diet_all\n",
    "# final_data['AuthorId'], unique_authorids = pd.factorize(final_data['AuthorId'])\n",
    "# \n",
    "# final_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.348311Z",
     "start_time": "2024-01-29T03:22:09.052021Z"
    }
   },
   "id": "8c5c389a74943244",
   "execution_count": 1140
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "diet_mapping = {'Vegan': 1, 'Vegetarian': 2, 'Omnivore': 3}\n",
    "protien_mapping = {'Yes': 1, 'Indifferent': 0}\n",
    "sugar_mapping = { 'Indifferent': 1,'0':0}\n",
    "# RECIPE CATEGORY TRAINNNNNNNNNNNNN\n",
    "\n",
    "# Apply mapping to the 'Diet' column\n",
    "merged_diet_all['Diet'] = merged_diet_all['Diet'].map(diet_mapping)\n",
    "merged_diet_all['HighProtein'] = merged_diet_all['HighProtein'].map(protien_mapping)\n",
    "merged_diet_all['LowSugar'] = merged_diet_all['LowSugar'].map(sugar_mapping)\n",
    "\n",
    "merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.466218Z",
     "start_time": "2024-01-29T03:22:09.066234Z"
    }
   },
   "id": "e843108e538c4558",
   "execution_count": 1141
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Function to clean the the strings\n",
    "# import pandas as pd\n",
    "# \n",
    "# # Updated clean_string function\n",
    "# def clean_string(string):\n",
    "#     # Remove 'c(' and ')' and replace escaped backslashes and double quotes\n",
    "#     cleaned_string = string.replace('c(', '').replace(')', '').replace('\\\\', '').replace('\\\"', '')\n",
    "# \n",
    "#     # Split the cleaned string by commas and remove extra spaces\n",
    "#     parsed_string = [val.strip() for val in cleaned_string.split(',')]\n",
    "# \n",
    "#     # Convert string elements to int\n",
    "#     parsed_string = [int(val) if val.isdigit() else val for val in parsed_string]\n",
    "# \n",
    "#     return parsed_string\n",
    "# \n",
    "# # Read the CSV file into a DataFrame\n",
    "# df = pd.read_csv('recipes.csv')\n",
    "# \n",
    "# # Apply the updated clean_string function to the RecipeIngredientQuantities column\n",
    "# df['RecipeIngredientQuantities'] = df['RecipeIngredientQuantities'].apply(clean_string)\n",
    "# df['RecipeIngredientParts'] = df['RecipeIngredientParts'].apply(clean_string)\n",
    "# \n",
    "# #Display the DataFrame with updated and cleaned values\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.497764Z",
     "start_time": "2024-01-29T03:22:09.084993Z"
    }
   },
   "id": "a656f7439b5dc632",
   "execution_count": 1142
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Function to calculate RecipeServings based on quantities\n",
    "# def calculate_servings(quantities):\n",
    "#     try:\n",
    "#         # Sum up the quantities to get the total amount of ingredients\n",
    "#         total_quantity = sum(eval(quantities))\n",
    "# \n",
    "#         # Assuming a base serving size, you can adjust this based on your data\n",
    "#         base_serving_size = 1\n",
    "# \n",
    "#         # Calculate the servings based on the total quantity and the base serving size\n",
    "#         servings = total_quantity / base_serving_size\n",
    "#         return servings\n",
    "#     except (ValueError, SyntaxError) as e:\n",
    "#         # Handle the case where the calculation fails\n",
    "#         print(f\"Error calculating servings: {e}\")\n",
    "#         return None\n",
    "# \n",
    "# # Apply the function to calculate RecipeServings\n",
    "# df['RecipeServings'] = df['RecipeIngredientQuantities'].apply(calculate_servings)\n",
    "# df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.542006Z",
     "start_time": "2024-01-29T03:22:09.103229Z"
    }
   },
   "id": "3cc2759b5afea205",
   "execution_count": 1143
  },
  {
   "cell_type": "markdown",
   "source": [
    "Export data frame to csv file to train the model"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b4db8bf23cd2172e"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# columns_to_drop = ['RecipeIngredientQuantities', 'RecipeIngredientParts', 'RecipeServings', 'RecipeYield', 'RecipeName','AuthorId']\n",
    "# \n",
    "# \n",
    "# merged_diet_all = merged_diet_all.drop(columns_to_drop, axis=1)\n",
    "# \n",
    "# # final_data.to_csv('final_data.csv', index=False)\n",
    "# merged_diet_all"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.572281Z",
     "start_time": "2024-01-29T03:22:09.120400Z"
    }
   },
   "id": "85175a133583aa46",
   "execution_count": 1144
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              Diet  Age  Rating          Time  HighCalories  HighProtein  \\\n11      Vegetarian   79     2.0  12000.614217           1.0  Indifferent   \n12      Vegetarian   79     2.0   1381.397540           0.0  Indifferent   \n13      Vegetarian   79     2.0   2401.489482           1.0          Yes   \n14      Vegetarian   79     2.0   3001.310835           0.0  Indifferent   \n16      Vegetarian   52     2.0    238.642694           1.0          Yes   \n...            ...  ...     ...           ...           ...          ...   \n140164  Vegetarian   49     2.0   4200.175880           1.0          Yes   \n140173  Vegetarian   74     2.0   1620.542781           1.0          Yes   \n140174  Vegetarian   74     2.0   5280.934504           1.0          Yes   \n140180  Vegetarian   71     2.0   2698.847102           0.0  Indifferent   \n140194  Vegetarian   18     0.0   7199.509521           0.0          Yes   \n\n        LowFat     LowSugar  HighFiber  CookTime  ...  FatContent  \\\n11           0  Indifferent          0      2700  ...           0   \n12           0            0          0      1200  ...           0   \n13           0            0          0      1800  ...           0   \n14           0            0          0      2700  ...           0   \n16           0            0          1       120  ...           0   \n...        ...          ...        ...       ...  ...         ...   \n140164       1  Indifferent          1      3000  ...           1   \n140173       0  Indifferent          0       900  ...           0   \n140174       0            0          1      4800  ...           0   \n140180       1            0          1      1800  ...           1   \n140194       0            0          0      7200  ...           0   \n\n       SaturatedFatContent CholesterolContent  SodiumContent  \\\n11                    19.5              188.2           61.8   \n12                     2.2                0.0           70.8   \n13                    37.7              123.3          911.5   \n14                     5.9               23.5          226.7   \n16                    21.8              123.3          232.1   \n...                    ...                ...            ...   \n140164                 3.1               82.1          245.0   \n140173                 8.9              296.3          854.4   \n140174                 3.5               12.1          215.2   \n140180                 3.8              101.8          686.5   \n140194                 0.0                0.0            5.6   \n\n        CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n11                     34.4           3.5          23.3             8.0   \n12                      9.2           3.8           2.4             8.2   \n13                    130.0           6.5          73.7            13.3   \n14                     39.4           1.1          17.4             3.7   \n16                     39.1           1.1           9.6             3.6   \n...                     ...           ...           ...             ...   \n140164                 69.1           0.7          49.9             6.2   \n140173                 23.3           0.8           1.0            47.5   \n140174                 32.5           8.8          11.2            11.7   \n140180                 12.1           2.1           6.5            38.1   \n140194                 36.2           0.2          33.6             0.2   \n\n        TestSetId  Like  \n11        17738.0   NaN  \n12        17737.0   NaN  \n13        17736.0   NaN  \n14        17739.0   NaN  \n16        41309.0   NaN  \n...           ...   ...  \n140164    40697.0   NaN  \n140173    40678.0   NaN  \n140174    40679.0   NaN  \n140180    18292.0   NaN  \n140194     7555.0   NaN  \n\n[42814 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>Rating</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n      <th>CookTime</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>TestSetId</th>\n      <th>Like</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>11</th>\n      <td>Vegetarian</td>\n      <td>79</td>\n      <td>2.0</td>\n      <td>12000.614217</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>2700</td>\n      <td>...</td>\n      <td>0</td>\n      <td>19.5</td>\n      <td>188.2</td>\n      <td>61.8</td>\n      <td>34.4</td>\n      <td>3.5</td>\n      <td>23.3</td>\n      <td>8.0</td>\n      <td>17738.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12</th>\n      <td>Vegetarian</td>\n      <td>79</td>\n      <td>2.0</td>\n      <td>1381.397540</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>2.2</td>\n      <td>0.0</td>\n      <td>70.8</td>\n      <td>9.2</td>\n      <td>3.8</td>\n      <td>2.4</td>\n      <td>8.2</td>\n      <td>17737.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>13</th>\n      <td>Vegetarian</td>\n      <td>79</td>\n      <td>2.0</td>\n      <td>2401.489482</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>37.7</td>\n      <td>123.3</td>\n      <td>911.5</td>\n      <td>130.0</td>\n      <td>6.5</td>\n      <td>73.7</td>\n      <td>13.3</td>\n      <td>17736.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>14</th>\n      <td>Vegetarian</td>\n      <td>79</td>\n      <td>2.0</td>\n      <td>3001.310835</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2700</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5.9</td>\n      <td>23.5</td>\n      <td>226.7</td>\n      <td>39.4</td>\n      <td>1.1</td>\n      <td>17.4</td>\n      <td>3.7</td>\n      <td>17739.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>16</th>\n      <td>Vegetarian</td>\n      <td>52</td>\n      <td>2.0</td>\n      <td>238.642694</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>120</td>\n      <td>...</td>\n      <td>0</td>\n      <td>21.8</td>\n      <td>123.3</td>\n      <td>232.1</td>\n      <td>39.1</td>\n      <td>1.1</td>\n      <td>9.6</td>\n      <td>3.6</td>\n      <td>41309.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>140164</th>\n      <td>Vegetarian</td>\n      <td>49</td>\n      <td>2.0</td>\n      <td>4200.175880</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>3000</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3.1</td>\n      <td>82.1</td>\n      <td>245.0</td>\n      <td>69.1</td>\n      <td>0.7</td>\n      <td>49.9</td>\n      <td>6.2</td>\n      <td>40697.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140173</th>\n      <td>Vegetarian</td>\n      <td>74</td>\n      <td>2.0</td>\n      <td>1620.542781</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>900</td>\n      <td>...</td>\n      <td>0</td>\n      <td>8.9</td>\n      <td>296.3</td>\n      <td>854.4</td>\n      <td>23.3</td>\n      <td>0.8</td>\n      <td>1.0</td>\n      <td>47.5</td>\n      <td>40678.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140174</th>\n      <td>Vegetarian</td>\n      <td>74</td>\n      <td>2.0</td>\n      <td>5280.934504</td>\n      <td>1.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>4800</td>\n      <td>...</td>\n      <td>0</td>\n      <td>3.5</td>\n      <td>12.1</td>\n      <td>215.2</td>\n      <td>32.5</td>\n      <td>8.8</td>\n      <td>11.2</td>\n      <td>11.7</td>\n      <td>40679.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140180</th>\n      <td>Vegetarian</td>\n      <td>71</td>\n      <td>2.0</td>\n      <td>2698.847102</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1800</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3.8</td>\n      <td>101.8</td>\n      <td>686.5</td>\n      <td>12.1</td>\n      <td>2.1</td>\n      <td>6.5</td>\n      <td>38.1</td>\n      <td>18292.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>140194</th>\n      <td>Vegetarian</td>\n      <td>18</td>\n      <td>0.0</td>\n      <td>7199.509521</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>7200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>5.6</td>\n      <td>36.2</td>\n      <td>0.2</td>\n      <td>33.6</td>\n      <td>0.2</td>\n      <td>7555.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>42814 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 1145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories','HighProtein','LowFat','LowSugar','HighFiber', 'CookTime', 'PrepTime','RecipeCategory', 'RecipeCategory', 'Calories', 'FatContent','SaturatedFatContent', 'CholesterolContent', 'SodiumContent',  'CarbohydrateContent','FiberContent', 'SugarContent', 'ProteinContent','TestSetId', 'Like']\n",
    "\n",
    "df = merged_diet_all[features].copy()\n",
    "\n",
    "# Drop and save testsetid\n",
    "# Drop rows with NaN values in the target column ('Like') for training set\n",
    "predict_data = df[df['Like'].isna()]\n",
    "predict_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.658382Z",
     "start_time": "2024-01-29T03:22:09.153103Z"
    }
   },
   "id": "c0a797c0d6d47b22",
   "execution_count": 1145
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# from sklearn.model_selection import train_test_split\n",
    "# \n",
    "# # Assuming 'final_data' has features and the target variable 'Like'\n",
    "# \n",
    "# # Drop rows with NaN values in the target column ('Like') for training set\n",
    "# train_data = df_balanced.dropna(subset=['Like'])\n",
    "# \n",
    "# # Assuming 'X' contains features and 'y' is the target variable\n",
    "# X = train_data.drop(columns=['Like'])\n",
    "# y = train_data['Like']\n",
    "# \n",
    "# # Split data into training and test sets\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, shuffle=True, random_state=3)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.730494Z",
     "start_time": "2024-01-29T03:22:09.363215Z"
    }
   },
   "id": "2043d31ecfbc21a9",
   "execution_count": 1146
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 27256 entries, 0 to 27255\n",
      "Data columns (total 30 columns):\n",
      " #   Column                      Non-Null Count  Dtype   \n",
      "---  ------                      --------------  -----   \n",
      " 0   AuthorId                    27256 non-null  object  \n",
      " 1   Diet                        27256 non-null  category\n",
      " 2   Age                         27256 non-null  int64   \n",
      " 3   RecipeId                    27256 non-null  int64   \n",
      " 4   Rating                      27256 non-null  float64 \n",
      " 5   Like                        27256 non-null  object  \n",
      " 6   TestSetId                   0 non-null      float64 \n",
      " 7   Time                        27256 non-null  float64 \n",
      " 8   HighCalories                27256 non-null  float64 \n",
      " 9   HighProtein                 27256 non-null  object  \n",
      " 10  LowFat                      27256 non-null  int64   \n",
      " 11  LowSugar                    27256 non-null  object  \n",
      " 12  HighFiber                   27256 non-null  int64   \n",
      " 13  RecipeName                  27256 non-null  object  \n",
      " 14  CookTime                    27256 non-null  int64   \n",
      " 15  PrepTime                    27256 non-null  int64   \n",
      " 16  RecipeCategory              27256 non-null  object  \n",
      " 17  RecipeIngredientQuantities  27256 non-null  object  \n",
      " 18  RecipeIngredientParts       27256 non-null  object  \n",
      " 19  Calories                    27256 non-null  float64 \n",
      " 20  FatContent                  27256 non-null  int64   \n",
      " 21  SaturatedFatContent         27256 non-null  float64 \n",
      " 22  CholesterolContent          27256 non-null  float64 \n",
      " 23  SodiumContent               27256 non-null  float64 \n",
      " 24  CarbohydrateContent         27256 non-null  float64 \n",
      " 25  FiberContent                27256 non-null  float64 \n",
      " 26  SugarContent                27256 non-null  float64 \n",
      " 27  ProteinContent              27256 non-null  float64 \n",
      " 28  RecipeServings              16972 non-null  float64 \n",
      " 29  RecipeYield                 9392 non-null   object  \n",
      "dtypes: category(1), float64(13), int64(7), object(9)\n",
      "memory usage: 6.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df_balanced.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:09.869919Z",
     "start_time": "2024-01-29T03:22:09.372212Z"
    }
   },
   "id": "146a249323574db9",
   "execution_count": 1147
  },
  {
   "cell_type": "markdown",
   "source": [
    "OUR CODE "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c7912e964783fd6"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.9986\n",
      "Balanced Accuracy on Testing Set: 0.7223\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "model = RandomForestClassifier(\n",
    "    n_estimators=100,  # You can adjust this\n",
    "    random_state=42,\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,  # You can adjust this\n",
    "    max_features='log2'\n",
    ")\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.511111Z",
     "start_time": "2024-01-29T03:22:09.483088Z"
    }
   },
   "id": "1bcaf8cb7721628b",
   "execution_count": 1148
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "ce7e4e8ea2cdbc87"
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Support Vector Machine (SVM) model with adjusted parameters\n",
    "model = SVC(\n",
    "    C=1.0,            # You can adjust this\n",
    "    kernel='rbf',     # You can adjust this\n",
    "    degree=3,         # You can adjust this\n",
    "    gamma='scale',    # You can adjust this\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the model on the training set\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.519410Z",
     "start_time": "2024-01-29T03:22:17.504997Z"
    }
   },
   "id": "725470cb7bf23045",
   "execution_count": 1149
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Balanced Accuracy on Training Set: 0.6787\n",
      "Balanced Accuracy on Testing Set: 0.6875\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for the training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale the features using StandardScaler\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Logistic Regression model\n",
    "# Increase max_iter and use the 'lbfgs' solver\n",
    "model = LogisticRegression(\n",
    "    random_state=42,\n",
    "    solver='lbfgs',  # You can adjust this\n",
    "    max_iter=1000,    # You can adjust this\n",
    "    C=1.0,            # You can adjust this\n",
    "    penalty='l2',     # You can adjust this\n",
    "    class_weight=None  # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the scaled training set\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the scaled training set\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the scaled testing set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.754836Z",
     "start_time": "2024-01-29T03:22:17.521523Z"
    }
   },
   "id": "313e8a6d2454e723",
   "execution_count": 1150
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the individual models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "svm_model = SVC(C=1.0, kernel='rbf', degree=3, gamma='scale', random_state=42)\n",
    "\n",
    "# Initialize the StackingClassifier with the individual models\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('svm', svm_model)],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit the StackingClassifier on the training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the StackingClassifier on the training set\n",
    "y_train_pred = stacking_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the StackingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.827514Z",
     "start_time": "2024-01-29T03:22:17.765298Z"
    }
   },
   "id": "eee92a49cb6e25a2",
   "execution_count": 1151
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.ensemble import StackingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'RecipeCategory']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the individual models\n",
    "rf_model = RandomForestClassifier(n_estimators=100, random_state=42, max_depth=20)\n",
    "gb_model = GradientBoostingClassifier(n_estimators=100, random_state=42, learning_rate=0.1, max_depth=3)\n",
    "\n",
    "# Initialize the StackingClassifier with the individual models\n",
    "stacking_model = StackingClassifier(\n",
    "    estimators=[('rf', rf_model), ('gb', gb_model)],\n",
    "    final_estimator=RandomForestClassifier(n_estimators=50, random_state=42)\n",
    ")\n",
    "\n",
    "# Fit the StackingClassifier on the training set\n",
    "stacking_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the StackingClassifier on the training set\n",
    "y_train_pred = stacking_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = stacking_model.predict(X_test)\n",
    "\n",
    "# Evaluate the StackingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.877445Z",
     "start_time": "2024-01-29T03:22:17.832044Z"
    }
   },
   "id": "8a6cec64bbe63bfb",
   "execution_count": 1152
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "precision_train = precision_score(y_train, y_train_pred)\n",
    "recall_train = recall_score(y_train, y_train_pred)\n",
    "f1_train = f1_score(y_train, y_train_pred)\n",
    "conf_matrix_train = confusion_matrix(y_train, y_train_pred)\n",
    "\n",
    "# Print metrics for the training set\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "print(f\"Precision on Training Set: {precision_train:.4f}\")\n",
    "print(f\"Recall on Training Set: {recall_train:.4f}\")\n",
    "print(f\"F1 Score on Training Set: {f1_train:.4f}\")\n",
    "print(f\"Confusion Matrix on Training Set:\\n{conf_matrix_train}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model.predict(X_test)\n",
    "\n",
    "# Compute metrics for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "precision_test = precision_score(y_test, y_test_pred)\n",
    "recall_test = recall_score(y_test, y_test_pred)\n",
    "f1_test = f1_score(y_test, y_test_pred)\n",
    "conf_matrix_test = confusion_matrix(y_test, y_test_pred)\n",
    "\n",
    "# Print metrics for the testing set\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n",
    "print(f\"Precision on Testing Set: {precision_test:.4f}\")\n",
    "print(f\"Recall on Testing Set: {recall_test:.4f}\")\n",
    "print(f\"F1 Score on Testing Set: {f1_test:.4f}\")\n",
    "print(f\"Confusion Matrix on Testing Set:\\n{conf_matrix_test}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:17.943351Z",
     "start_time": "2024-01-29T03:22:17.849121Z"
    }
   },
   "id": "2a8408aba0fa2e44",
   "execution_count": 1153
  },
  {
   "cell_type": "markdown",
   "source": [
    "# 72.7 WITH 2000 ADD\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6d25798abc6f0763"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "22\n",
      "Balanced Accuracy on Training Set: 0.7724\n",
      "Balanced Accuracy on Testing Set: 0.7706\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "# 72.7 WITH 2000 ADD\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories','HighProtein','LowFat','LowSugar','HighFiber', 'CookTime', 'PrepTime','RecipeCategory', 'RecipeCategory', 'Calories', 'FatContent','SaturatedFatContent', 'CholesterolContent', 'SodiumContent',  'CarbohydrateContent','FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the Gradient Boosting model\n",
    "model_gbc = GradientBoostingClassifier(\n",
    "    n_estimators=100,     # You can adjust this\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,    # You can adjust this\n",
    "    max_depth=3,          # You can adjust this\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,   # You can adjust this\n",
    "    subsample=1.0         # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the training set\n",
    "model_gbc.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model on the training set\n",
    "y_train_pred = model_gbc.predict(X_train)\n",
    "\n",
    "# Compute balanced accuracy for the training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = model_gbc.predict(X_test)\n",
    "\n",
    "# Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:24:45.354527Z",
     "start_time": "2024-01-29T03:24:32.977928Z"
    }
   },
   "id": "fda34e9945aded03",
   "execution_count": 1160
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the features\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Initialize the Neural Network model\n",
    "model = MLPClassifier(\n",
    "    hidden_layer_sizes=(100,),  # You can adjust this\n",
    "    max_iter=500,                 # You can adjust this\n",
    "    random_state=42,\n",
    "    activation='relu',           # You can adjust this\n",
    "    alpha=0.0001,                 # You can adjust this\n",
    "    solver='adam',               # You can adjust this\n",
    "    learning_rate='constant'      # You can adjust this\n",
    ")\n",
    "\n",
    "\n",
    "# Fit the model on the scaled training set\n",
    "model.fit(X_train_scaled, y_train)\n",
    "\n",
    "# Evaluate the model on the scaled training set\n",
    "y_train_pred = model.predict(X_train_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled training set\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the scaled testing set\n",
    "y_test_pred = model.predict(X_test_scaled)\n",
    "\n",
    "# Compute balanced accuracy for the scaled testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:22:25.431333Z",
     "start_time": "2024-01-29T03:22:25.426485Z"
    }
   },
   "id": "ae54540e1d2a8e21",
   "execution_count": 1155
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from itertools import combinations\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet','Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent',  'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber', 'HighCalories', 'RecipeCategory', 'HighProtein']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Get all possible combinations of features\n",
    "\n",
    "\n",
    "best_combination = None\n",
    "best_accuracy = 0.0\n",
    "\n",
    "# Iterate over all feature combinations\n",
    " # Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    " # Handle categorical variables using one-hot encodin\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "    # Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "    # Initialize the Random Forest model with hyperparameter tuning\n",
    "model_final_rfc = RandomForestClassifier(\n",
    "        n_estimators=100,\n",
    "        random_state=47,\n",
    "        max_depth=10,\n",
    "        min_samples_split=6,\n",
    "        min_samples_leaf=5,\n",
    "        max_features='sqrt'\n",
    "    )\n",
    "\n",
    "    # Fit the model on the training set\n",
    "model_final_rfc.fit(X_train, y_train)\n",
    "\n",
    "    # Evaluate the model on the testing set\n",
    "y_test_pred = model_final_rfc.predict(X_test)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "    # Compute balanced accuracy for the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "    # Print the feature combination and its balanced accuracy\n",
    "# print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_test:.4f}\")\n",
    "\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:26:28.959788Z",
     "start_time": "2024-01-29T03:26:28.847646Z"
    }
   },
   "id": "ffbb5d82bd3429bc",
   "execution_count": 1163
  },
  {
   "cell_type": "markdown",
   "source": [
    "1500 73.86"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "aece4f59acdd2183"
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "data": {
      "text/plain": "              Diet  Age  Rating         Time  HighCalories  HighProtein  \\\n92733     Omnivore   19     2.0  2700.834797           0.0  Indifferent   \n70540     Omnivore   66     2.0  2401.749707           0.0          Yes   \n110017    Omnivore   35     0.0  2099.113170           1.0  Indifferent   \n64367     Omnivore   76     2.0  1201.730701           0.0          Yes   \n61048     Omnivore   56     0.0  2339.919957           0.0          Yes   \n...            ...  ...     ...          ...           ...          ...   \n48455   Vegetarian   31     0.0  3600.286373           0.0          Yes   \n48454   Vegetarian   31     0.0  3900.828975           1.0  Indifferent   \n100493  Vegetarian   35     2.0  2519.164237           1.0  Indifferent   \n63212   Vegetarian   61     2.0  4199.867547           0.0          Yes   \n12085   Vegetarian   41     2.0  2221.719393           1.0  Indifferent   \n\n        LowFat     LowSugar  HighFiber  CookTime  ...  FatContent  \\\n92733        0  Indifferent          0      1500  ...           0   \n70540        0            0          0      1200  ...           0   \n110017       0            0          1      1200  ...           0   \n64367        0            0          0         0  ...           0   \n61048        1            0          1       840  ...           1   \n...        ...          ...        ...       ...  ...         ...   \n48455        1            0          0      2700  ...           1   \n48454        0  Indifferent          0      3600  ...           0   \n100493       1  Indifferent          1       420  ...           1   \n63212        0            0          0      2400  ...           0   \n12085        0            0          0      1020  ...           0   \n\n       SaturatedFatContent CholesterolContent  SodiumContent  \\\n92733                 17.1               96.6         1280.4   \n70540                  6.1               71.1         1261.7   \n110017                10.6               61.8         1370.2   \n64367                 64.7              320.1          757.9   \n61048                  1.4               68.4          662.4   \n...                    ...                ...            ...   \n48455                 13.2              102.4          220.6   \n48454                  5.6               20.3          348.0   \n100493                 3.7               15.3          195.8   \n63212                  0.9                0.0           47.7   \n12085                  4.8               18.5          435.4   \n\n        CarbohydrateContent  FiberContent  SugarContent  ProteinContent  \\\n92733                  97.1          17.7           9.4            41.0   \n70540                  48.4           9.7           4.4            29.1   \n110017                 11.5           2.6           4.9            23.1   \n64367                  14.6           1.6           8.7            20.6   \n61048                   5.4           1.1           1.9            29.4   \n...                     ...           ...           ...             ...   \n48455                  21.2           0.8          12.4             6.5   \n48454                  47.3           0.7          23.4             2.2   \n100493                  5.5           0.8           1.5             2.0   \n63212                  28.4           2.7           2.6             4.6   \n12085                  21.5           2.9           7.6             3.8   \n\n        TestSetId  Like  \n92733         1.0   NaN  \n70540         2.0   NaN  \n110017        3.0   NaN  \n64367         4.0   NaN  \n61048         5.0   NaN  \n...           ...   ...  \n48455     42810.0   NaN  \n48454     42811.0   NaN  \n100493    42812.0   NaN  \n63212     42813.0   NaN  \n12085     42814.0   NaN  \n\n[42814 rows x 24 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Diet</th>\n      <th>Age</th>\n      <th>Rating</th>\n      <th>Time</th>\n      <th>HighCalories</th>\n      <th>HighProtein</th>\n      <th>LowFat</th>\n      <th>LowSugar</th>\n      <th>HighFiber</th>\n      <th>CookTime</th>\n      <th>...</th>\n      <th>FatContent</th>\n      <th>SaturatedFatContent</th>\n      <th>CholesterolContent</th>\n      <th>SodiumContent</th>\n      <th>CarbohydrateContent</th>\n      <th>FiberContent</th>\n      <th>SugarContent</th>\n      <th>ProteinContent</th>\n      <th>TestSetId</th>\n      <th>Like</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>92733</th>\n      <td>Omnivore</td>\n      <td>19</td>\n      <td>2.0</td>\n      <td>2700.834797</td>\n      <td>0.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>1500</td>\n      <td>...</td>\n      <td>0</td>\n      <td>17.1</td>\n      <td>96.6</td>\n      <td>1280.4</td>\n      <td>97.1</td>\n      <td>17.7</td>\n      <td>9.4</td>\n      <td>41.0</td>\n      <td>1.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>70540</th>\n      <td>Omnivore</td>\n      <td>66</td>\n      <td>2.0</td>\n      <td>2401.749707</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>6.1</td>\n      <td>71.1</td>\n      <td>1261.7</td>\n      <td>48.4</td>\n      <td>9.7</td>\n      <td>4.4</td>\n      <td>29.1</td>\n      <td>2.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>110017</th>\n      <td>Omnivore</td>\n      <td>35</td>\n      <td>0.0</td>\n      <td>2099.113170</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1</td>\n      <td>1200</td>\n      <td>...</td>\n      <td>0</td>\n      <td>10.6</td>\n      <td>61.8</td>\n      <td>1370.2</td>\n      <td>11.5</td>\n      <td>2.6</td>\n      <td>4.9</td>\n      <td>23.1</td>\n      <td>3.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>64367</th>\n      <td>Omnivore</td>\n      <td>76</td>\n      <td>2.0</td>\n      <td>1201.730701</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>...</td>\n      <td>0</td>\n      <td>64.7</td>\n      <td>320.1</td>\n      <td>757.9</td>\n      <td>14.6</td>\n      <td>1.6</td>\n      <td>8.7</td>\n      <td>20.6</td>\n      <td>4.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>61048</th>\n      <td>Omnivore</td>\n      <td>56</td>\n      <td>0.0</td>\n      <td>2339.919957</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>1</td>\n      <td>840</td>\n      <td>...</td>\n      <td>1</td>\n      <td>1.4</td>\n      <td>68.4</td>\n      <td>662.4</td>\n      <td>5.4</td>\n      <td>1.1</td>\n      <td>1.9</td>\n      <td>29.4</td>\n      <td>5.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>48455</th>\n      <td>Vegetarian</td>\n      <td>31</td>\n      <td>0.0</td>\n      <td>3600.286373</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>1</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2700</td>\n      <td>...</td>\n      <td>1</td>\n      <td>13.2</td>\n      <td>102.4</td>\n      <td>220.6</td>\n      <td>21.2</td>\n      <td>0.8</td>\n      <td>12.4</td>\n      <td>6.5</td>\n      <td>42810.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>48454</th>\n      <td>Vegetarian</td>\n      <td>31</td>\n      <td>0.0</td>\n      <td>3900.828975</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>3600</td>\n      <td>...</td>\n      <td>0</td>\n      <td>5.6</td>\n      <td>20.3</td>\n      <td>348.0</td>\n      <td>47.3</td>\n      <td>0.7</td>\n      <td>23.4</td>\n      <td>2.2</td>\n      <td>42811.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>100493</th>\n      <td>Vegetarian</td>\n      <td>35</td>\n      <td>2.0</td>\n      <td>2519.164237</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>Indifferent</td>\n      <td>1</td>\n      <td>420</td>\n      <td>...</td>\n      <td>1</td>\n      <td>3.7</td>\n      <td>15.3</td>\n      <td>195.8</td>\n      <td>5.5</td>\n      <td>0.8</td>\n      <td>1.5</td>\n      <td>2.0</td>\n      <td>42812.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>63212</th>\n      <td>Vegetarian</td>\n      <td>61</td>\n      <td>2.0</td>\n      <td>4199.867547</td>\n      <td>0.0</td>\n      <td>Yes</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>2400</td>\n      <td>...</td>\n      <td>0</td>\n      <td>0.9</td>\n      <td>0.0</td>\n      <td>47.7</td>\n      <td>28.4</td>\n      <td>2.7</td>\n      <td>2.6</td>\n      <td>4.6</td>\n      <td>42813.0</td>\n      <td>NaN</td>\n    </tr>\n    <tr>\n      <th>12085</th>\n      <td>Vegetarian</td>\n      <td>41</td>\n      <td>2.0</td>\n      <td>2221.719393</td>\n      <td>1.0</td>\n      <td>Indifferent</td>\n      <td>0</td>\n      <td>0</td>\n      <td>0</td>\n      <td>1020</td>\n      <td>...</td>\n      <td>0</td>\n      <td>4.8</td>\n      <td>18.5</td>\n      <td>435.4</td>\n      <td>21.5</td>\n      <td>2.9</td>\n      <td>7.6</td>\n      <td>3.8</td>\n      <td>42814.0</td>\n      <td>NaN</td>\n    </tr>\n  </tbody>\n</table>\n<p>42814 rows × 24 columns</p>\n</div>"
     },
     "execution_count": 1164,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict_data = predict_data.sort_values(by='TestSetId', ascending=True)\n",
    "predict_data"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:26:31.175490Z",
     "start_time": "2024-01-29T03:26:31.012263Z"
    }
   },
   "id": "1645c63e2d4a63f4",
   "execution_count": 1164
  },
  {
   "cell_type": "code",
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mValueError\u001B[0m                                Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1166], line 17\u001B[0m\n\u001B[1;32m     14\u001B[0m predict_features_encoded \u001B[38;5;241m=\u001B[39m predict_features_encoded[X_train\u001B[38;5;241m.\u001B[39mcolumns]\n\u001B[1;32m     16\u001B[0m \u001B[38;5;66;03m# 3. Make Predictions Using the Trained Model\u001B[39;00m\n\u001B[0;32m---> 17\u001B[0m predicted_likes \u001B[38;5;241m=\u001B[39m \u001B[43mmodel_gbc\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mpredict\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpredict_features_encoded\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     19\u001B[0m \u001B[38;5;66;03m# Combine Predictions with 'TestSetId'\u001B[39;00m\n\u001B[1;32m     20\u001B[0m results_df \u001B[38;5;241m=\u001B[39m pd\u001B[38;5;241m.\u001B[39mDataFrame({\n\u001B[1;32m     21\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mid\u001B[39m\u001B[38;5;124m'\u001B[39m: predict_data[\u001B[38;5;124m'\u001B[39m\u001B[38;5;124mTestSetId\u001B[39m\u001B[38;5;124m'\u001B[39m],\n\u001B[1;32m     22\u001B[0m     \u001B[38;5;124m'\u001B[39m\u001B[38;5;124mprediction\u001B[39m\u001B[38;5;124m'\u001B[39m: predicted_likes\n\u001B[1;32m     23\u001B[0m })\n",
      "File \u001B[0;32m~/AnalyticsCup_skilledShark/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:1611\u001B[0m, in \u001B[0;36mGradientBoostingClassifier.predict\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1596\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mpredict\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m   1597\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Predict class for X.\u001B[39;00m\n\u001B[1;32m   1598\u001B[0m \n\u001B[1;32m   1599\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1609\u001B[0m \u001B[38;5;124;03m        The predicted values.\u001B[39;00m\n\u001B[1;32m   1610\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1611\u001B[0m     raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdecision_function\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1612\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m raw_predictions\u001B[38;5;241m.\u001B[39mndim \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:  \u001B[38;5;66;03m# decision_function already squeezed it\u001B[39;00m\n\u001B[1;32m   1613\u001B[0m         encoded_classes \u001B[38;5;241m=\u001B[39m (raw_predictions \u001B[38;5;241m>\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m)\u001B[38;5;241m.\u001B[39mastype(\u001B[38;5;28mint\u001B[39m)\n",
      "File \u001B[0;32m~/AnalyticsCup_skilledShark/lib/python3.11/site-packages/sklearn/ensemble/_gb.py:1564\u001B[0m, in \u001B[0;36mGradientBoostingClassifier.decision_function\u001B[0;34m(self, X)\u001B[0m\n\u001B[1;32m   1545\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdecision_function\u001B[39m(\u001B[38;5;28mself\u001B[39m, X):\n\u001B[1;32m   1546\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Compute the decision function of ``X``.\u001B[39;00m\n\u001B[1;32m   1547\u001B[0m \n\u001B[1;32m   1548\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m   1562\u001B[0m \u001B[38;5;124;03m        array of shape (n_samples,).\u001B[39;00m\n\u001B[1;32m   1563\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m-> 1564\u001B[0m     X \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_validate_data\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m   1565\u001B[0m \u001B[43m        \u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mDTYPE\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43morder\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mC\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43maccept_sparse\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[38;5;124;43mcsr\u001B[39;49m\u001B[38;5;124;43m\"\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43;01mFalse\u001B[39;49;00m\n\u001B[1;32m   1566\u001B[0m \u001B[43m    \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m   1567\u001B[0m     raw_predictions \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_raw_predict(X)\n\u001B[1;32m   1568\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m raw_predictions\u001B[38;5;241m.\u001B[39mshape[\u001B[38;5;241m1\u001B[39m] \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m1\u001B[39m:\n",
      "File \u001B[0;32m~/AnalyticsCup_skilledShark/lib/python3.11/site-packages/sklearn/base.py:608\u001B[0m, in \u001B[0;36mBaseEstimator._validate_data\u001B[0;34m(self, X, y, reset, validate_separately, cast_to_ndarray, **check_params)\u001B[0m\n\u001B[1;32m    537\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_validate_data\u001B[39m(\n\u001B[1;32m    538\u001B[0m     \u001B[38;5;28mself\u001B[39m,\n\u001B[1;32m    539\u001B[0m     X\u001B[38;5;241m=\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mno_validation\u001B[39m\u001B[38;5;124m\"\u001B[39m,\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    544\u001B[0m     \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mcheck_params,\n\u001B[1;32m    545\u001B[0m ):\n\u001B[1;32m    546\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124;03m\"\"\"Validate input data and set or check the `n_features_in_` attribute.\u001B[39;00m\n\u001B[1;32m    547\u001B[0m \n\u001B[1;32m    548\u001B[0m \u001B[38;5;124;03m    Parameters\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    606\u001B[0m \u001B[38;5;124;03m        validated.\u001B[39;00m\n\u001B[1;32m    607\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 608\u001B[0m     \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_check_feature_names\u001B[49m\u001B[43m(\u001B[49m\u001B[43mX\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mreset\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mreset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    610\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m y \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_get_tags()[\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires_y\u001B[39m\u001B[38;5;124m\"\u001B[39m]:\n\u001B[1;32m    611\u001B[0m         \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(\n\u001B[1;32m    612\u001B[0m             \u001B[38;5;124mf\u001B[39m\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mThis \u001B[39m\u001B[38;5;132;01m{\u001B[39;00m\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__class__\u001B[39m\u001B[38;5;241m.\u001B[39m\u001B[38;5;18m__name__\u001B[39m\u001B[38;5;132;01m}\u001B[39;00m\u001B[38;5;124m estimator \u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    613\u001B[0m             \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mrequires y to be passed, but the target y is None.\u001B[39m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    614\u001B[0m         )\n",
      "File \u001B[0;32m~/AnalyticsCup_skilledShark/lib/python3.11/site-packages/sklearn/base.py:535\u001B[0m, in \u001B[0;36mBaseEstimator._check_feature_names\u001B[0;34m(self, X, reset)\u001B[0m\n\u001B[1;32m    530\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m missing_names \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m unexpected_names:\n\u001B[1;32m    531\u001B[0m     message \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m (\n\u001B[1;32m    532\u001B[0m         \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mFeature names must be in the same order as they were in fit.\u001B[39m\u001B[38;5;130;01m\\n\u001B[39;00m\u001B[38;5;124m\"\u001B[39m\n\u001B[1;32m    533\u001B[0m     )\n\u001B[0;32m--> 535\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m \u001B[38;5;167;01mValueError\u001B[39;00m(message)\n",
      "\u001B[0;31mValueError\u001B[0m: The feature names should match those that were passed during fit.\nFeature names must be in the same order as they were in fit.\n"
     ]
    }
   ],
   "source": [
    "# 1. One-Hot Encode Categorical Variables in predict_data\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'HighCalories','HighProtein','LowFat','LowSugar','HighFiber', 'CookTime', 'PrepTime','RecipeCategory', 'RecipeCategory', 'Calories', 'FatContent','SaturatedFatContent', 'CholesterolContent', 'SodiumContent',  'CarbohydrateContent','FiberContent', 'SugarContent', 'ProteinContent']\n",
    "\n",
    "predict_features = predict_data[features]  # 'features' list from your model training code\n",
    "predict_features_encoded = pd.get_dummies(predict_features)\n",
    "\n",
    "# 2. Align the Columns of predict_data with X_train\n",
    "# Add missing columns in predict_features_encoded with value equal to 0\n",
    "missing_cols = set(X_train.columns) - set(predict_features_encoded.columns)\n",
    "for c in missing_cols:\n",
    "    predict_features_encoded[c] = 0\n",
    "\n",
    "# Ensure the order of columns in predict_features_encoded matches that of X_train\n",
    "predict_features_encoded = predict_features_encoded[X_train.columns]\n",
    "\n",
    "# 3. Make Predictions Using the Trained Model\n",
    "predicted_likes = model_gbc.predict(predict_features_encoded)\n",
    "\n",
    "# Combine Predictions with 'TestSetId'\n",
    "results_df = pd.DataFrame({\n",
    "    'id': predict_data['TestSetId'],\n",
    "    'prediction': predicted_likes\n",
    "})\n",
    "results_df['id'] = results_df['id'].astype(int)\n",
    "results_df['prediction'] = results_df['prediction'].replace({True: 1, False: 0})\n",
    "\n",
    "\n",
    "# Display the first few rows of the results\n",
    "print(results_df.head())\n",
    "results_df.to_csv('predictions_skilled_shark.csv',index=False)\n",
    "results_df"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-29T03:26:37.024615Z",
     "start_time": "2024-01-29T03:26:36.890019Z"
    }
   },
   "id": "bc026c8711ac734c",
   "execution_count": 1166
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, BaggingClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "\n",
    "# Load your data\n",
    "df = df_balanced\n",
    "\n",
    "# Define features (X) and target variable (y)\n",
    "features = ['Diet', 'Age', 'Rating', 'Time', 'CookTime', 'FiberContent', 'ProteinContent', 'SugarContent', 'PrepTime', 'LowSugar', 'LowFat', 'CarbohydrateContent', 'SodiumContent', 'CholesterolContent', 'SaturatedFatContent', 'FatContent', 'Calories', 'HighFiber','HighCalories','HighProtein']\n",
    "target = 'Like'\n",
    "\n",
    "# Drop rows with NaN values in the target column ('Like') and create a copy for training set\n",
    "train_data = df.dropna(subset=[target]).copy()\n",
    "\n",
    "# Convert 'Like' column to boolean (if not already)\n",
    "train_data['Like'] = train_data['Like'].astype(bool)\n",
    "\n",
    "# Split the data into features (X) and target variable (y)\n",
    "X = train_data[features]\n",
    "y = train_data['Like']\n",
    "\n",
    "# Handle categorical variables using one-hot encoding\n",
    "X = pd.get_dummies(X)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize the base model (Random Forest)\n",
    "base_model = GradientBoostingClassifier(\n",
    "    n_estimators=100,     # You can adjust this\n",
    "    random_state=42,\n",
    "    learning_rate=0.1,    # You can adjust this\n",
    "    max_depth=3,          # You can adjust this\n",
    "    min_samples_split=2,  # You can adjust this\n",
    "    min_samples_leaf=1,   # You can adjust this\n",
    "    subsample=1.0         # You can adjust this\n",
    ")\n",
    "\n",
    "# Initialize the BaggingClassifier\n",
    "bagging_model = BaggingClassifier(\n",
    "    base_model,\n",
    "    n_estimators=50,  # You can adjust this\n",
    "    max_samples=1.0,  # You can adjust this\n",
    "    max_features=1.0,  # You can adjust this\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# Fit the BaggingClassifier on the training set\n",
    "bagging_model.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the BaggingClassifier on the training set\n",
    "y_train_pred = bagging_model.predict(X_train)\n",
    "balanced_accuracy_train = balanced_accuracy_score(y_train, y_train_pred)\n",
    "print(f\"Balanced Accuracy on Training Set: {balanced_accuracy_train:.4f}\")\n",
    "\n",
    "# Predict the 'Like' column for the testing set\n",
    "y_test_pred = bagging_model.predict(X_test)\n",
    "\n",
    "# Evaluate the BaggingClassifier on the testing set\n",
    "balanced_accuracy_test = balanced_accuracy_score(y_test, y_test_pred)\n",
    "print(f\"Balanced Accuracy on Testing Set: {balanced_accuracy_test:.4f}\")\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T03:22:28.516966Z"
    }
   },
   "id": "640a3035a0fc3dc5",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "\n",
    "#     model = bagging_model\n",
    "# \n",
    "#     prediction = model.predict(datapoint)\n",
    "# \n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T03:22:28.519695Z"
    }
   },
   "id": "23d29856ad73d8c8",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # hypothetical new batch of flowers arrives\n",
    "# from scipy.stats import norm\n",
    "# \n",
    "# amount_of_new_flowers = 9\n",
    "# df_flowers = pd.DataFrame(columns=df.columns.drop(\"variety\"), index=range(1, amount_of_new_flowers+1))\n",
    "# \n",
    "# for i in df_flowers.index:\n",
    "#     df_flowers.loc[i, \"sepal.length\"] = norm(loc=6, scale=2).rvs()\n",
    "#     df_flowers.loc[i, \"sepal.width\"] = norm(loc=3, scale=1).rvs()\n",
    "#     df_flowers.loc[i, \"petal.length\"] = norm(loc=3, scale=5).rvs()\n",
    "#     df_flowers.loc[i, \"petal.width\"] = norm(loc=2, scale=2).rvs()\n",
    "# \n",
    "# # customer uses your micro service to determine the varieties\n",
    "# df_flowers[\"variety\"] = micro_service_classify_iris(df_flowers)\n",
    "# print(df_flowers)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T03:22:28.522428Z"
    }
   },
   "id": "11b4ec2d958d41fc",
   "execution_count": null
  },
  {
   "cell_type": "code",
   "outputs": [],
   "source": [
    "# # Let's assume that our id column is the index of the dataframe\n",
    "# output = pd.DataFrame(df_flowers.variety)\n",
    "# output['id'] = df_flowers.index\n",
    "# output = output.rename(columns={'variety': 'prediction'})\n",
    "# output = output.reindex(columns=[\"id\", \"prediction\"])\n",
    "# output.to_csv('prediction_skill_shark.csv', index=False)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-01-29T03:22:28.526110Z"
    }
   },
   "id": "757c583261269968",
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "source": [
    "DONE"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2382c3f663d55ca0"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
